{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Strojenie hiperparametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadania"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Poszukiwanie ręczne"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pobierz zestaw danych Boston Housing:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przygotuj funkcję budującą model według parametrów podanych jako argumenty:\n",
    "- n_hidden – liczba warstw ukrytych,\n",
    "- n_neurons – liczba neuronów na każdej z warstw ukrytych,\n",
    "- optimizer – gradientowy algorytm optymalizacji, funkcja powinna rozumieć wartości: sgd, nesterov, momentum oraz adam,\n",
    "- learning_rate – krok uczenia,\n",
    "- momentum – współczynnik przyspieszenia dla algorytmów z pędem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n        3.96900e+02, 1.87200e+01],\n       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n        3.95380e+02, 3.11000e+00],\n       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n        3.75520e+02, 3.26000e+00],\n       ...,\n       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n        3.62250e+02, 7.83000e+00],\n       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n        2.61950e+02, 1.57900e+01],\n       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n        3.76700e+02, 4.38000e+00]])"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def build_model(optimizer, n_hidden=1, learning_rate=10e-5, n_neurons=25, momentum=0):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=X_train.shape[1:]))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"nesterov\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, nesterov=True)\n",
    "    if optimizer == \"momentum\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przy uczeniu wykorzystaj mechanizm early stopping o cierpliwości równej 10 i minimalnej poprawie\n",
    "funkcji straty równej 1.00, uczenie maksymalnie przez 100 epok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                      min_delta=1.00)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def get_run_logdir(name, value):\n",
    "    import time\n",
    "    import os\n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "    ts = int(time.time())\n",
    "\n",
    "    run_id = str(ts) + \"_\" + name + \"_\" + str(value)\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przed eksperymentami wyczyść sesję TensorFlow i ustal generatory liczb losowych:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "validation_split = .1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "krok uczenia(lr): 10−6, 10−5, 10−4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 117101.7812 - mae: 123.7935 - val_loss: 108.1399 - val_mae: 8.5337\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 163.8253 - mae: 9.5988 - val_loss: 68.6999 - val_mae: 6.7683\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 113.2871 - mae: 7.8936 - val_loss: 49.6265 - val_mae: 5.5180\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 97.5250 - mae: 7.2386 - val_loss: 44.5197 - val_mae: 5.2958\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 91.5391 - mae: 7.0076 - val_loss: 42.7563 - val_mae: 5.2981\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 87.4378 - mae: 7.0010 - val_loss: 42.5495 - val_mae: 5.0830\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 86.9827 - mae: 6.7954 - val_loss: 41.1674 - val_mae: 5.1446\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 85.6662 - mae: 6.7517 - val_loss: 44.3108 - val_mae: 5.4583\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 87.2038 - mae: 6.9364 - val_loss: 40.8578 - val_mae: 5.0159\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 85.3688 - mae: 6.7019 - val_loss: 44.2814 - val_mae: 5.4409\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 86.3176 - mae: 6.8699 - val_loss: 40.8691 - val_mae: 5.1381\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 86.3014 - mae: 6.7988 - val_loss: 46.5182 - val_mae: 5.6370\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 86.0942 - mae: 6.7629 - val_loss: 43.3290 - val_mae: 5.3657\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.8896 - mae: 6.8204 - val_loss: 40.6521 - val_mae: 5.0992\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.5033 - mae: 6.7824 - val_loss: 40.2261 - val_mae: 5.0088\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 85.2646 - mae: 6.7375 - val_loss: 41.3100 - val_mae: 4.9884\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.2253 - mae: 6.5342 - val_loss: 74.1952 - val_mae: 7.3707\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 96.4782 - mae: 8.2673\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 112177.9688 - mae: 125.7833 - val_loss: 512.0265 - val_mae: 21.6644\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 600.7207 - mae: 22.6158 - val_loss: 509.7014 - val_mae: 21.6107\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 598.2958 - mae: 22.5618 - val_loss: 507.3871 - val_mae: 21.5571\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 595.8815 - mae: 22.5082 - val_loss: 505.0604 - val_mae: 21.5030\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 593.4544 - mae: 22.4543 - val_loss: 502.7385 - val_mae: 21.4490\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 591.0327 - mae: 22.3996 - val_loss: 500.4478 - val_mae: 21.3955\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 588.6422 - mae: 22.3469 - val_loss: 498.1533 - val_mae: 21.3418\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 586.2479 - mae: 22.2935 - val_loss: 495.8608 - val_mae: 21.2881\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 583.8570 - mae: 22.2399 - val_loss: 493.6149 - val_mae: 21.2352\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 581.5112 - mae: 22.1868 - val_loss: 491.3393 - val_mae: 21.1816\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 579.1368 - mae: 22.1328 - val_loss: 489.0913 - val_mae: 21.1285\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 576.7904 - mae: 22.0797 - val_loss: 486.8587 - val_mae: 21.0756\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 574.4598 - mae: 22.0273 - val_loss: 484.6459 - val_mae: 21.0230\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 572.1483 - mae: 21.9745 - val_loss: 482.4273 - val_mae: 20.9702\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 569.8316 - mae: 21.9218 - val_loss: 480.2237 - val_mae: 20.9176\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 567.5311 - mae: 21.8694 - val_loss: 478.0438 - val_mae: 20.8654\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 565.2524 - mae: 21.8177 - val_loss: 475.8260 - val_mae: 20.8122\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 562.9380 - mae: 21.7642 - val_loss: 473.6757 - val_mae: 20.7604\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 560.6900 - mae: 21.7123 - val_loss: 471.5013 - val_mae: 20.7080\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 558.4186 - mae: 21.6599 - val_loss: 469.3616 - val_mae: 20.6563\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.1818 - mae: 21.6082 - val_loss: 467.1881 - val_mae: 20.6036\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 553.9112 - mae: 21.5563 - val_loss: 465.0553 - val_mae: 20.5518\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 551.6826 - mae: 21.5042 - val_loss: 462.9467 - val_mae: 20.5004\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 549.4780 - mae: 21.4524 - val_loss: 460.8335 - val_mae: 20.4488\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 547.2690 - mae: 21.4010 - val_loss: 458.7302 - val_mae: 20.3973\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 545.0695 - mae: 21.3495 - val_loss: 456.6427 - val_mae: 20.3461\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 542.8873 - mae: 21.2986 - val_loss: 454.5813 - val_mae: 20.2954\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 540.7307 - mae: 21.2478 - val_loss: 452.4994 - val_mae: 20.2440\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 538.5542 - mae: 21.1963 - val_loss: 450.4464 - val_mae: 20.1932\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 536.4068 - mae: 21.1462 - val_loss: 448.4100 - val_mae: 20.1428\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 534.2756 - mae: 21.0959 - val_loss: 446.3604 - val_mae: 20.0918\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 532.1312 - mae: 21.0448 - val_loss: 444.3350 - val_mae: 20.0413\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 530.0120 - mae: 20.9944 - val_loss: 442.3171 - val_mae: 19.9909\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 527.8992 - mae: 20.9438 - val_loss: 440.2874 - val_mae: 19.9401\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 525.7756 - mae: 20.8930 - val_loss: 438.2812 - val_mae: 19.8897\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 523.6765 - mae: 20.8425 - val_loss: 436.3046 - val_mae: 19.8400\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 521.6061 - mae: 20.7930 - val_loss: 434.3184 - val_mae: 19.7899\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 519.5277 - mae: 20.7427 - val_loss: 432.3637 - val_mae: 19.7404\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 517.4799 - mae: 20.6936 - val_loss: 430.4005 - val_mae: 19.6906\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 515.4249 - mae: 20.6438 - val_loss: 428.4731 - val_mae: 19.6416\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 513.4052 - mae: 20.5944 - val_loss: 426.5143 - val_mae: 19.5917\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 511.3537 - mae: 20.5442 - val_loss: 424.5862 - val_mae: 19.5424\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 509.3336 - mae: 20.4957 - val_loss: 422.6642 - val_mae: 19.4932\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 507.3202 - mae: 20.4470 - val_loss: 420.7590 - val_mae: 19.4443\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 505.3236 - mae: 20.3972 - val_loss: 418.8598 - val_mae: 19.3954\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 503.3339 - mae: 20.3484 - val_loss: 416.9846 - val_mae: 19.3470\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 501.3679 - mae: 20.2999 - val_loss: 415.0927 - val_mae: 19.2980\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 499.3853 - mae: 20.2517 - val_loss: 413.2446 - val_mae: 19.2501\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 497.4474 - mae: 20.2033 - val_loss: 411.3892 - val_mae: 19.2018\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 495.5021 - mae: 20.1557 - val_loss: 409.5348 - val_mae: 19.1535\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 493.5568 - mae: 20.1071 - val_loss: 407.6826 - val_mae: 19.1051\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.6144 - mae: 20.0589 - val_loss: 405.8469 - val_mae: 19.0569\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.6894 - mae: 20.0104 - val_loss: 404.0177 - val_mae: 19.0089\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 487.7704 - mae: 19.9626 - val_loss: 402.1857 - val_mae: 18.9606\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 485.8479 - mae: 19.9140 - val_loss: 400.3729 - val_mae: 18.9128\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 483.9464 - mae: 19.8662 - val_loss: 398.5757 - val_mae: 18.8652\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 482.0597 - mae: 19.8190 - val_loss: 396.7721 - val_mae: 18.8173\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 480.1672 - mae: 19.7710 - val_loss: 394.9947 - val_mae: 18.7701\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 478.3014 - mae: 19.7242 - val_loss: 393.2136 - val_mae: 18.7226\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 476.4312 - mae: 19.6765 - val_loss: 391.4424 - val_mae: 18.6752\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 474.5721 - mae: 19.6293 - val_loss: 389.6817 - val_mae: 18.6280\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 472.7233 - mae: 19.5820 - val_loss: 387.9430 - val_mae: 18.5813\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 470.8971 - mae: 19.5356 - val_loss: 386.1935 - val_mae: 18.5341\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 469.0601 - mae: 19.4880 - val_loss: 384.4696 - val_mae: 18.4876\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.2495 - mae: 19.4414 - val_loss: 382.7586 - val_mae: 18.4412\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.4508 - mae: 19.3955 - val_loss: 381.0303 - val_mae: 18.3943\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 463.6353 - mae: 19.3491 - val_loss: 379.3206 - val_mae: 18.3478\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 461.8382 - mae: 19.3022 - val_loss: 377.6075 - val_mae: 18.3010\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 460.0376 - mae: 19.2554 - val_loss: 375.9084 - val_mae: 18.2546\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 458.2519 - mae: 19.2097 - val_loss: 374.2228 - val_mae: 18.2083\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 456.4803 - mae: 19.1631 - val_loss: 372.5624 - val_mae: 18.1627\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 454.7347 - mae: 19.1169 - val_loss: 370.9090 - val_mae: 18.1171\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 452.9958 - mae: 19.0714 - val_loss: 369.2496 - val_mae: 18.0712\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 451.2508 - mae: 19.0256 - val_loss: 367.6053 - val_mae: 18.0257\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 449.5215 - mae: 18.9802 - val_loss: 365.9727 - val_mae: 17.9804\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.8034 - mae: 18.9349 - val_loss: 364.3339 - val_mae: 17.9347\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 446.0798 - mae: 18.8891 - val_loss: 362.7161 - val_mae: 17.8896\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 444.3771 - mae: 18.8440 - val_loss: 361.0944 - val_mae: 17.8442\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 442.6711 - mae: 18.7993 - val_loss: 359.4981 - val_mae: 17.7994\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 440.9903 - mae: 18.7545 - val_loss: 357.8953 - val_mae: 17.7543\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 439.3030 - mae: 18.7095 - val_loss: 356.2913 - val_mae: 17.7091\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 437.6150 - mae: 18.6642 - val_loss: 354.7058 - val_mae: 17.6643\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 435.9453 - mae: 18.6192 - val_loss: 353.1322 - val_mae: 17.6197\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 434.2880 - mae: 18.5749 - val_loss: 351.5617 - val_mae: 17.5750\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 432.6340 - mae: 18.5303 - val_loss: 349.9906 - val_mae: 17.5303\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 430.9804 - mae: 18.4852 - val_loss: 348.4514 - val_mae: 17.4863\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 429.3579 - mae: 18.4418 - val_loss: 346.9059 - val_mae: 17.4421\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 427.7294 - mae: 18.3973 - val_loss: 345.3674 - val_mae: 17.3979\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.1083 - mae: 18.3533 - val_loss: 343.8438 - val_mae: 17.3541\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 424.5033 - mae: 18.3099 - val_loss: 342.3343 - val_mae: 17.3105\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 422.9113 - mae: 18.2661 - val_loss: 340.8154 - val_mae: 17.2666\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 421.3098 - mae: 18.2220 - val_loss: 339.2952 - val_mae: 17.2225\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 419.7073 - mae: 18.1776 - val_loss: 337.7924 - val_mae: 17.1788\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 418.1237 - mae: 18.1344 - val_loss: 336.3228 - val_mae: 17.1360\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 416.5729 - mae: 18.0914 - val_loss: 334.8378 - val_mae: 17.0926\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 415.0070 - mae: 18.0485 - val_loss: 333.3614 - val_mae: 17.0494\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.4492 - mae: 18.0049 - val_loss: 331.8821 - val_mae: 17.0060\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 411.8880 - mae: 17.9618 - val_loss: 330.3976 - val_mae: 16.9622\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.3225 - mae: 17.9186 - val_loss: 328.9483 - val_mae: 16.9195\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.7923 - mae: 17.8757 - val_loss: 327.4956 - val_mae: 16.8765\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 423.1082 - mae: 18.4354\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1821524754432.0000 - mae: 402203.3750 - val_loss: 76737960.0000 - val_mae: 8760.0166\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 75152000.0000 - mae: 8668.8281 - val_loss: 73138336.0000 - val_mae: 8552.0928\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 71626392.0000 - mae: 8463.0498 - val_loss: 69707576.0000 - val_mae: 8349.1025\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 68266200.0000 - mae: 8262.1523 - val_loss: 66437844.0000 - val_mae: 8150.9390\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 65063696.0000 - mae: 8066.0283 - val_loss: 63321508.0000 - val_mae: 7957.4785\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 62011456.0000 - mae: 7874.5659 - val_loss: 60351296.0000 - val_mae: 7768.6069\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 59102340.0000 - mae: 7687.6313 - val_loss: 57520464.0000 - val_mae: 7584.2217\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 56329748.0000 - mae: 7505.1440 - val_loss: 54822436.0000 - val_mae: 7404.2148\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 53687248.0000 - mae: 7326.9912 - val_loss: 52250888.0000 - val_mae: 7228.4746\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 51168616.0000 - mae: 7153.0635 - val_loss: 49800080.0000 - val_mae: 7056.9141\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 48768256.0000 - mae: 6983.2734 - val_loss: 47464180.0000 - val_mae: 6889.4224\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 46480436.0000 - mae: 6817.5049 - val_loss: 45237836.0000 - val_mae: 6725.9048\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 44299944.0000 - mae: 6655.6680 - val_loss: 43115900.0000 - val_mae: 6566.2666\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 42221708.0000 - mae: 6497.6777 - val_loss: 41093560.0000 - val_mae: 6410.4224\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 40241016.0000 - mae: 6343.4380 - val_loss: 39166072.0000 - val_mae: 6258.2769\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 38353236.0000 - mae: 6192.8569 - val_loss: 37328964.0000 - val_mae: 6109.7397\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 36553980.0000 - mae: 6045.8462 - val_loss: 35578168.0000 - val_mae: 5964.7402\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 34839256.0000 - mae: 5902.3418 - val_loss: 33909328.0000 - val_mae: 5823.1680\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33204824.0000 - mae: 5762.2314 - val_loss: 32318880.0000 - val_mae: 5684.9663\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 31647162.0000 - mae: 5625.4526 - val_loss: 30802976.0000 - val_mae: 5550.0391\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 30162516.0000 - mae: 5491.9155 - val_loss: 29358290.0000 - val_mae: 5418.3257\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 28747620.0000 - mae: 5361.5508 - val_loss: 27981294.0000 - val_mae: 5289.7305\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27399026.0000 - mae: 5234.2837 - val_loss: 26668844.0000 - val_mae: 5164.1851\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 26113662.0000 - mae: 5110.0366 - val_loss: 25418010.0000 - val_mae: 5041.6235\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 24888644.0000 - mae: 4988.7354 - val_loss: 24225838.0000 - val_mae: 4921.9712\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 23721076.0000 - mae: 4870.3159 - val_loss: 23089582.0000 - val_mae: 4805.1577\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 22608282.0000 - mae: 4754.7036 - val_loss: 22006588.0000 - val_mae: 4691.1138\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 21547652.0000 - mae: 4641.8345 - val_loss: 20974460.0000 - val_mae: 4579.7837\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20536840.0000 - mae: 4531.6538 - val_loss: 19990710.0000 - val_mae: 4471.0923\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 19573414.0000 - mae: 4424.0757 - val_loss: 19053090.0000 - val_mae: 4364.9795\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 18655176.0000 - mae: 4319.0537 - val_loss: 18159498.0000 - val_mae: 4261.3911\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17780052.0000 - mae: 4216.5347 - val_loss: 17307788.0000 - val_mae: 4160.2578\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16945956.0000 - mae: 4116.4429 - val_loss: 16496045.0000 - val_mae: 4061.5271\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16150999.0000 - mae: 4018.7310 - val_loss: 15722410.0000 - val_mae: 3965.1440\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 15393369.0000 - mae: 3923.3413 - val_loss: 14985038.0000 - val_mae: 3871.0457\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14671251.0000 - mae: 3830.2131 - val_loss: 14282212.0000 - val_mae: 3779.1760\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13982977.0000 - mae: 3739.2878 - val_loss: 13612393.0000 - val_mae: 3689.4917\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13327027.0000 - mae: 3650.5300 - val_loss: 12973955.0000 - val_mae: 3601.9319\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12701812.0000 - mae: 3563.8684 - val_loss: 12365492.0000 - val_mae: 3516.4543\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12105954.0000 - mae: 3479.2720 - val_loss: 11785525.0000 - val_mae: 3432.9993\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11538008.0000 - mae: 3396.6812 - val_loss: 11232832.0000 - val_mae: 3351.5354\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 10996773.0000 - mae: 3316.0596 - val_loss: 10706028.0000 - val_mae: 3272.0005\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 10480894.0000 - mae: 3237.3362 - val_loss: 10203942.0000 - val_mae: 3194.3545\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9989223.0000 - mae: 3160.4846 - val_loss: 9725391.0000 - val_mae: 3118.5491\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9520603.0000 - mae: 3085.4700 - val_loss: 9269293.0000 - val_mae: 3044.5447\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9073974.0000 - mae: 3012.2268 - val_loss: 8834568.0000 - val_mae: 2972.2927\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8648277.0000 - mae: 2940.7212 - val_loss: 8420271.0000 - val_mae: 2901.7629\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8242585.0000 - mae: 2870.9104 - val_loss: 8025353.5000 - val_mae: 2832.8979\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7855877.5000 - mae: 2802.7603 - val_loss: 7648988.0000 - val_mae: 2765.6726\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7487335.5000 - mae: 2736.2207 - val_loss: 7290285.5000 - val_mae: 2700.0449\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7136093.0000 - mae: 2671.2715 - val_loss: 6948415.0000 - val_mae: 2635.9768\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6801336.0000 - mae: 2607.8613 - val_loss: 6622568.5000 - val_mae: 2573.4268\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6482273.5000 - mae: 2545.9612 - val_loss: 6312009.5000 - val_mae: 2512.3628\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6178182.0000 - mae: 2485.5232 - val_loss: 6016030.5000 - val_mae: 2452.7512\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5888368.0000 - mae: 2426.5291 - val_loss: 5733919.5000 - val_mae: 2394.5515\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5612138.5000 - mae: 2368.9290 - val_loss: 5465034.5000 - val_mae: 2337.7322\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5348862.0000 - mae: 2312.6924 - val_loss: 5208779.5000 - val_mae: 2282.2661\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5097952.5000 - mae: 2257.7988 - val_loss: 4964523.0000 - val_mae: 2228.1116\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4858794.0000 - mae: 2204.1978 - val_loss: 4731736.0000 - val_mae: 2175.2458\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4630870.0000 - mae: 2151.8796 - val_loss: 4509867.0000 - val_mae: 2123.6350\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4413636.0000 - mae: 2100.7988 - val_loss: 4298402.0000 - val_mae: 2073.2488\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4206590.5000 - mae: 2050.9324 - val_loss: 4096839.0000 - val_mae: 2024.0544\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4009244.5000 - mae: 2002.2428 - val_loss: 3904752.5000 - val_mae: 1976.0339\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3821176.5000 - mae: 1954.7222 - val_loss: 3721655.5000 - val_mae: 1929.1482\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3641913.5000 - mae: 1908.3197 - val_loss: 3547141.5000 - val_mae: 1883.3743\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3471056.5000 - mae: 1863.0138 - val_loss: 3380838.7500 - val_mae: 1838.6940\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3308240.0000 - mae: 1818.7885 - val_loss: 3222325.7500 - val_mae: 1795.0718\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3153051.7500 - mae: 1775.6202 - val_loss: 3071257.2500 - val_mae: 1752.4882\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3005153.2500 - mae: 1733.4757 - val_loss: 2927269.0000 - val_mae: 1710.9138\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2864189.2500 - mae: 1692.3218 - val_loss: 2790028.2500 - val_mae: 1670.3248\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2729832.0000 - mae: 1652.1553 - val_loss: 2659209.2500 - val_mae: 1630.6951\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2601764.0000 - mae: 1612.9396 - val_loss: 2534526.2500 - val_mae: 1592.0061\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2479704.7500 - mae: 1574.6494 - val_loss: 2415702.7500 - val_mae: 1554.2394\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2363382.7500 - mae: 1537.2715 - val_loss: 2302445.2500 - val_mae: 1517.3669\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2252512.2500 - mae: 1500.7778 - val_loss: 2194497.2500 - val_mae: 1481.3691\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2146840.7500 - mae: 1465.1500 - val_loss: 2091622.8750 - val_mae: 1446.2296\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2046137.0000 - mae: 1430.3750 - val_loss: 1993562.7500 - val_mae: 1411.9207\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1950148.0000 - mae: 1396.4198 - val_loss: 1900111.6250 - val_mae: 1378.4299\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1858671.2500 - mae: 1363.2668 - val_loss: 1811028.6250 - val_mae: 1345.7288\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1771473.1250 - mae: 1330.9038 - val_loss: 1726134.5000 - val_mae: 1313.8081\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1688376.1250 - mae: 1299.3109 - val_loss: 1645227.8750 - val_mae: 1282.6477\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1609183.0000 - mae: 1268.4724 - val_loss: 1568107.7500 - val_mae: 1252.2240\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1533697.6250 - mae: 1238.3644 - val_loss: 1494600.6250 - val_mae: 1222.5211\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1461750.6250 - mae: 1208.9653 - val_loss: 1424544.2500 - val_mae: 1193.5248\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1393182.6250 - mae: 1180.2681 - val_loss: 1357778.6250 - val_mae: 1165.2192\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1327836.0000 - mae: 1152.2573 - val_loss: 1294127.8750 - val_mae: 1137.5786\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1265539.7500 - mae: 1124.8970 - val_loss: 1233470.5000 - val_mae: 1110.5979\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1206174.3750 - mae: 1098.1969 - val_loss: 1175658.0000 - val_mae: 1084.2581\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1149594.3750 - mae: 1072.1270 - val_loss: 1120552.3750 - val_mae: 1058.5413\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1095664.3750 - mae: 1046.6710 - val_loss: 1068026.2500 - val_mae: 1033.4329\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1044260.8750 - mae: 1021.8245 - val_loss: 1017973.4375 - val_mae: 1008.9255\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 995278.7500 - mae: 997.5714 - val_loss: 970272.7500 - val_mae: 985.0026\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 948598.7500 - mae: 973.8981 - val_loss: 924802.7500 - val_mae: 961.6444\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 904102.8750 - mae: 950.7766 - val_loss: 881450.7500 - val_mae: 938.8333\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 861681.1250 - mae: 928.2028 - val_loss: 840143.4375 - val_mae: 916.5700\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 821261.3125 - mae: 906.1641 - val_loss: 800772.8750 - val_mae: 894.8353\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 782737.3750 - mae: 884.6575 - val_loss: 763253.4375 - val_mae: 873.6193\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 746025.8750 - mae: 863.6573 - val_loss: 727499.0625 - val_mae: 852.9105\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 711042.0000 - mae: 843.1575 - val_loss: 693407.6250 - val_mae: 832.6854\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677686.5000 - mae: 823.1422 - val_loss: 660919.6250 - val_mae: 812.9433\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 658428.0000 - mae: 811.3845\n"
     ]
    }
   ],
   "source": [
    "results_lr = []\n",
    "for lr in (10e-6, 10e-5, 10e-4):\n",
    "    run_logdir = get_run_logdir(\"lr\", lr)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    model = build_model(learning_rate=lr, optimizer=\"sgd\")\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[es, tensorboard])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    results_lr.append((lr, score[0], score[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1e-05, 96.47820281982422, 8.2672700881958),\n (0.0001, 423.1081848144531, 18.43541145324707),\n (0.001, 658428.0, 811.384521484375)]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "liczba warstw ukrytych (hl): od 0 do 3,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 18ms/step - loss: inf - mae: 462933766606063403008.0000 - val_loss: inf - val_mae: 967319372936436208631808.0000\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "4/4 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 25)                350       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 1185043.8750 - mae: 405.3779 - val_loss: 526.3845 - val_mae: 21.9933\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 615.6886 - mae: 22.9444 - val_loss: 523.9895 - val_mae: 21.9388\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 613.1924 - mae: 22.8895 - val_loss: 521.6056 - val_mae: 21.8844\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 610.7071 - mae: 22.8351 - val_loss: 519.2092 - val_mae: 21.8296\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 608.2090 - mae: 22.7804 - val_loss: 516.8179 - val_mae: 21.7747\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 605.7165 - mae: 22.7250 - val_loss: 514.4584 - val_mae: 21.7205\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 603.2559 - mae: 22.6715 - val_loss: 512.0953 - val_mae: 21.6660\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 600.7915 - mae: 22.6173 - val_loss: 509.7344 - val_mae: 21.6115\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 598.3309 - mae: 22.5629 - val_loss: 507.4208 - val_mae: 21.5579\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 595.9161 - mae: 22.5091 - val_loss: 505.0773 - val_mae: 21.5034\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 593.4724 - mae: 22.4543 - val_loss: 502.7621 - val_mae: 21.4495\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 591.0573 - mae: 22.4005 - val_loss: 500.4626 - val_mae: 21.3959\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 588.6585 - mae: 22.3473 - val_loss: 498.1833 - val_mae: 21.3425\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 586.2792 - mae: 22.2937 - val_loss: 495.8984 - val_mae: 21.2889\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 583.8948 - mae: 22.2402 - val_loss: 493.6287 - val_mae: 21.2356\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 581.5269 - mae: 22.1871 - val_loss: 491.3834 - val_mae: 21.1826\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 579.1814 - mae: 22.1346 - val_loss: 489.0997 - val_mae: 21.1287\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 576.7997 - mae: 22.0804 - val_loss: 486.8846 - val_mae: 21.0762\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 574.4857 - mae: 22.0277 - val_loss: 484.6452 - val_mae: 21.0230\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 572.1480 - mae: 21.9746 - val_loss: 482.4413 - val_mae: 20.9705\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 569.8456 - mae: 21.9221 - val_loss: 480.2032 - val_mae: 20.9171\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 567.5090 - mae: 21.8694 - val_loss: 478.0066 - val_mae: 20.8645\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 565.2152 - mae: 21.8166 - val_loss: 475.8347 - val_mae: 20.8124\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 562.9460 - mae: 21.7640 - val_loss: 473.6583 - val_mae: 20.7600\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 560.6725 - mae: 21.7119 - val_loss: 471.4920 - val_mae: 20.7078\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 558.4086 - mae: 21.6596 - val_loss: 469.3419 - val_mae: 20.6558\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.1626 - mae: 21.6080 - val_loss: 467.2185 - val_mae: 20.6043\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 553.9426 - mae: 21.5564 - val_loss: 465.0744 - val_mae: 20.5522\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 551.7026 - mae: 21.5042 - val_loss: 462.9598 - val_mae: 20.5007\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 549.4924 - mae: 21.4534 - val_loss: 460.8622 - val_mae: 20.4495\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 547.2986 - mae: 21.4024 - val_loss: 458.7514 - val_mae: 20.3978\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 545.0916 - mae: 21.3506 - val_loss: 456.6652 - val_mae: 20.3466\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 542.9105 - mae: 21.2994 - val_loss: 454.5868 - val_mae: 20.2955\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 540.7359 - mae: 21.2481 - val_loss: 452.4966 - val_mae: 20.2439\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 538.5503 - mae: 21.1965 - val_loss: 450.4305 - val_mae: 20.1928\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 536.3901 - mae: 21.1453 - val_loss: 448.3943 - val_mae: 20.1424\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 534.2589 - mae: 21.0951 - val_loss: 446.3488 - val_mae: 20.0915\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 532.1198 - mae: 21.0441 - val_loss: 444.3352 - val_mae: 20.0413\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 530.0119 - mae: 20.9943 - val_loss: 442.3132 - val_mae: 19.9908\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 527.8968 - mae: 20.9437 - val_loss: 440.3276 - val_mae: 19.9411\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 525.8176 - mae: 20.8936 - val_loss: 438.3104 - val_mae: 19.8905\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 523.7065 - mae: 20.8427 - val_loss: 436.3245 - val_mae: 19.8405\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 521.6273 - mae: 20.7935 - val_loss: 434.3447 - val_mae: 19.7905\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 519.5547 - mae: 20.7441 - val_loss: 432.3823 - val_mae: 19.7409\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 517.4998 - mae: 20.6935 - val_loss: 430.4261 - val_mae: 19.6913\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 515.4517 - mae: 20.6440 - val_loss: 428.4945 - val_mae: 19.6422\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 513.4278 - mae: 20.5948 - val_loss: 426.5459 - val_mae: 19.5925\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 511.3875 - mae: 20.5459 - val_loss: 424.6419 - val_mae: 19.5439\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 509.3925 - mae: 20.4968 - val_loss: 422.7307 - val_mae: 19.4949\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 507.3901 - mae: 20.4485 - val_loss: 420.8207 - val_mae: 19.4459\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 505.3880 - mae: 20.3992 - val_loss: 418.9129 - val_mae: 19.3967\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 503.3889 - mae: 20.3503 - val_loss: 417.0221 - val_mae: 19.3479\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 501.4074 - mae: 20.3011 - val_loss: 415.1380 - val_mae: 19.2992\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 499.4323 - mae: 20.2526 - val_loss: 413.2513 - val_mae: 19.2502\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 497.4538 - mae: 20.2033 - val_loss: 411.3839 - val_mae: 19.2017\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 495.4966 - mae: 20.1548 - val_loss: 409.5329 - val_mae: 19.1534\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.5546 - mae: 20.1069 - val_loss: 407.6753 - val_mae: 19.1049\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.6070 - mae: 20.0582 - val_loss: 405.8444 - val_mae: 19.0569\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.6864 - mae: 20.0107 - val_loss: 404.0098 - val_mae: 19.0087\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 487.7615 - mae: 19.9623 - val_loss: 402.1856 - val_mae: 18.9606\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 485.8483 - mae: 19.9144 - val_loss: 400.3721 - val_mae: 18.9128\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 483.9453 - mae: 19.8665 - val_loss: 398.5810 - val_mae: 18.8653\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 482.0656 - mae: 19.8194 - val_loss: 396.7790 - val_mae: 18.8175\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 480.1749 - mae: 19.7711 - val_loss: 395.0033 - val_mae: 18.7703\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 478.3113 - mae: 19.7238 - val_loss: 393.2407 - val_mae: 18.7233\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 476.4597 - mae: 19.6772 - val_loss: 391.4607 - val_mae: 18.6757\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 474.5913 - mae: 19.6302 - val_loss: 389.6996 - val_mae: 18.6285\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 472.7417 - mae: 19.5826 - val_loss: 387.9353 - val_mae: 18.5811\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 470.8885 - mae: 19.5351 - val_loss: 386.1853 - val_mae: 18.5339\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 469.0508 - mae: 19.4888 - val_loss: 384.4491 - val_mae: 18.4870\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.2274 - mae: 19.4415 - val_loss: 382.7386 - val_mae: 18.4407\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.4305 - mae: 19.3947 - val_loss: 381.0353 - val_mae: 18.3944\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 463.6405 - mae: 19.3484 - val_loss: 379.3261 - val_mae: 18.3479\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 461.8445 - mae: 19.3020 - val_loss: 377.6324 - val_mae: 18.3017\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 460.0646 - mae: 19.2559 - val_loss: 375.9505 - val_mae: 18.2557\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 458.2962 - mae: 19.2100 - val_loss: 374.2626 - val_mae: 18.2094\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 456.5221 - mae: 19.1635 - val_loss: 372.5960 - val_mae: 18.1636\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 454.7695 - mae: 19.1177 - val_loss: 370.9256 - val_mae: 18.1176\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 453.0135 - mae: 19.0724 - val_loss: 369.2812 - val_mae: 18.0721\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 451.2835 - mae: 19.0269 - val_loss: 367.6302 - val_mae: 18.0264\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 449.5469 - mae: 18.9813 - val_loss: 365.9780 - val_mae: 17.9805\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.8096 - mae: 18.9354 - val_loss: 364.3449 - val_mae: 17.9350\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 446.0911 - mae: 18.8897 - val_loss: 362.7239 - val_mae: 17.8898\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 444.3853 - mae: 18.8447 - val_loss: 361.1063 - val_mae: 17.8445\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 442.6829 - mae: 18.7995 - val_loss: 359.4881 - val_mae: 17.7991\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 440.9810 - mae: 18.7538 - val_loss: 357.9023 - val_mae: 17.7545\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 439.3109 - mae: 18.7097 - val_loss: 356.3104 - val_mae: 17.7096\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 437.6347 - mae: 18.6646 - val_loss: 354.7256 - val_mae: 17.6648\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 435.9662 - mae: 18.6199 - val_loss: 353.1560 - val_mae: 17.6203\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 434.3140 - mae: 18.5759 - val_loss: 351.6009 - val_mae: 17.5762\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 432.6752 - mae: 18.5314 - val_loss: 350.0363 - val_mae: 17.5316\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 431.0270 - mae: 18.4867 - val_loss: 348.4706 - val_mae: 17.4869\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 429.3778 - mae: 18.4417 - val_loss: 346.9225 - val_mae: 17.4426\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 427.7479 - mae: 18.3979 - val_loss: 345.4084 - val_mae: 17.3991\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.1513 - mae: 18.3542 - val_loss: 343.8787 - val_mae: 17.3551\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 424.5396 - mae: 18.3107 - val_loss: 342.3577 - val_mae: 17.3112\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 422.9362 - mae: 18.2664 - val_loss: 340.8340 - val_mae: 17.2671\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 421.3294 - mae: 18.2227 - val_loss: 339.3051 - val_mae: 17.2228\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 419.7183 - mae: 18.1789 - val_loss: 337.8120 - val_mae: 17.1794\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 418.1432 - mae: 18.1353 - val_loss: 336.3156 - val_mae: 17.1358\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 432.7368 - mae: 18.6947\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 25)                350       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,026\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 544738.4375 - mae: 259.5896 - val_loss: 123.9479 - val_mae: 9.4204\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 134.7521 - mae: 8.3755 - val_loss: 49.2889 - val_mae: 5.5455\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 95.1498 - mae: 6.7419 - val_loss: 42.8881 - val_mae: 5.3277\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 90.4687 - mae: 6.6766 - val_loss: 42.9420 - val_mae: 5.3057\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.6869 - mae: 6.7725 - val_loss: 43.5132 - val_mae: 5.3316\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.4447 - mae: 6.8519 - val_loss: 43.1265 - val_mae: 5.3138\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.5031 - mae: 6.7746 - val_loss: 43.5110 - val_mae: 5.3316\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.4867 - mae: 6.8067 - val_loss: 44.0157 - val_mae: 5.3617\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.6460 - mae: 6.8218 - val_loss: 43.4849 - val_mae: 5.3305\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.4599 - mae: 6.8116 - val_loss: 44.0221 - val_mae: 5.3621\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.5693 - mae: 6.8707 - val_loss: 43.5998 - val_mae: 5.3350\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.6552 - mae: 6.8452 - val_loss: 43.4206 - val_mae: 5.3278\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.5942 - mae: 6.7958 - val_loss: 43.4238 - val_mae: 5.3280\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 83.7286 - mae: 6.5323\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,676\n",
      "Trainable params: 1,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 15ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "4/4 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    }
   ],
   "source": [
    "results_hl = []\n",
    "for hl in (0, 1, 2, 3):\n",
    "    run_logdir = get_run_logdir(\"hl\", hl)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    model = build_model(n_hidden=hl, optimizer=\"sgd\")\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[es, tensorboard])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    results_hl.append((hl, score[0], score[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, nan, nan),\n (1, 432.7367858886719, 18.69472885131836),\n (2, 83.7286148071289, 6.532285213470459),\n (3, nan, nan)]"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_hl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "liczba neuronów na warstwę (nn): 5, 25, 125"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_nn = []\n",
    "for nn in (5, 25, 125):\n",
    "    run_logdir = get_run_logdir(\"nn\", nn)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    model = build_model(optimizer=\"sgd\", n_neurons=nn)\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[es, tensorboard])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    results_nn.append((nn, score[0], score[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 5)                 70        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14374.3311 - mae: 54.7305 - val_loss: 500.3336 - val_mae: 21.3929\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 588.5240 - mae: 22.3446 - val_loss: 498.0657 - val_mae: 21.3398\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 586.1573 - mae: 22.2912 - val_loss: 495.8081 - val_mae: 21.2868\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 583.8007 - mae: 22.2382 - val_loss: 493.5380 - val_mae: 21.2334\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 581.4316 - mae: 22.1849 - val_loss: 491.2727 - val_mae: 21.1800\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 579.0675 - mae: 22.1309 - val_loss: 489.0379 - val_mae: 21.1272\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 576.7341 - mae: 22.0789 - val_loss: 486.7993 - val_mae: 21.0741\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 574.3969 - mae: 22.0261 - val_loss: 484.5627 - val_mae: 21.0210\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 572.0629 - mae: 21.9731 - val_loss: 482.3718 - val_mae: 20.9688\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 569.7734 - mae: 21.9207 - val_loss: 480.1514 - val_mae: 20.9158\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 567.4553 - mae: 21.8673 - val_loss: 477.9583 - val_mae: 20.8633\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 565.1649 - mae: 21.8149 - val_loss: 475.7802 - val_mae: 20.8111\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 562.8898 - mae: 21.7631 - val_loss: 473.6216 - val_mae: 20.7591\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 560.6337 - mae: 21.7109 - val_loss: 471.4571 - val_mae: 20.7069\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 558.3721 - mae: 21.6588 - val_loss: 469.3071 - val_mae: 20.6550\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 556.1265 - mae: 21.6071 - val_loss: 467.1807 - val_mae: 20.6034\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 553.9023 - mae: 21.5560 - val_loss: 465.0165 - val_mae: 20.5508\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 551.6427 - mae: 21.5032 - val_loss: 462.9189 - val_mae: 20.4997\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 549.4485 - mae: 21.4519 - val_loss: 460.7974 - val_mae: 20.4479\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 547.2311 - mae: 21.4001 - val_loss: 458.7101 - val_mae: 20.3968\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 545.0478 - mae: 21.3490 - val_loss: 456.5892 - val_mae: 20.3448\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 542.8309 - mae: 21.2977 - val_loss: 454.5085 - val_mae: 20.2936\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 540.6554 - mae: 21.2463 - val_loss: 452.4515 - val_mae: 20.2428\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 538.5036 - mae: 21.1950 - val_loss: 450.3898 - val_mae: 20.1918\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 536.3471 - mae: 21.1443 - val_loss: 448.3377 - val_mae: 20.1410\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 534.1999 - mae: 21.0934 - val_loss: 446.3013 - val_mae: 20.0903\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 532.0699 - mae: 21.0431 - val_loss: 444.2903 - val_mae: 20.0402\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 529.9648 - mae: 20.9929 - val_loss: 442.2591 - val_mae: 19.9895\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 527.8400 - mae: 20.9420 - val_loss: 440.2563 - val_mae: 19.9393\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 525.7440 - mae: 20.8925 - val_loss: 438.2697 - val_mae: 19.8894\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 523.6636 - mae: 20.8429 - val_loss: 436.2700 - val_mae: 19.8391\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 521.5702 - mae: 20.7924 - val_loss: 434.2941 - val_mae: 19.7892\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 519.5016 - mae: 20.7426 - val_loss: 432.3255 - val_mae: 19.7394\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 517.4393 - mae: 20.6926 - val_loss: 430.3450 - val_mae: 19.6892\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 515.3658 - mae: 20.6424 - val_loss: 428.3878 - val_mae: 19.6395\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 513.3168 - mae: 20.5925 - val_loss: 426.4596 - val_mae: 19.5903\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 511.2959 - mae: 20.5436 - val_loss: 424.5218 - val_mae: 19.5408\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 509.2670 - mae: 20.4939 - val_loss: 422.6151 - val_mae: 19.4919\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 507.2682 - mae: 20.4454 - val_loss: 420.6997 - val_mae: 19.4427\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 505.2621 - mae: 20.3962 - val_loss: 418.8197 - val_mae: 19.3943\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 503.2908 - mae: 20.3474 - val_loss: 416.9085 - val_mae: 19.3450\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 501.2881 - mae: 20.2978 - val_loss: 415.0276 - val_mae: 19.2963\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 499.3161 - mae: 20.2499 - val_loss: 413.1524 - val_mae: 19.2477\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 497.3506 - mae: 20.2018 - val_loss: 411.2939 - val_mae: 19.1993\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 495.4018 - mae: 20.1525 - val_loss: 409.4411 - val_mae: 19.1510\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.4595 - mae: 20.1043 - val_loss: 407.6120 - val_mae: 19.1032\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.5405 - mae: 20.0564 - val_loss: 405.7662 - val_mae: 19.0548\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.6051 - mae: 20.0088 - val_loss: 403.9636 - val_mae: 19.0075\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 487.7137 - mae: 19.9609 - val_loss: 402.1537 - val_mae: 18.9598\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 485.8150 - mae: 19.9140 - val_loss: 400.3446 - val_mae: 18.9120\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 483.9162 - mae: 19.8660 - val_loss: 398.5376 - val_mae: 18.8642\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 482.0201 - mae: 19.8183 - val_loss: 396.7469 - val_mae: 18.8167\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 480.1408 - mae: 19.7703 - val_loss: 394.9624 - val_mae: 18.7692\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 478.2678 - mae: 19.7232 - val_loss: 393.1750 - val_mae: 18.7215\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 476.3908 - mae: 19.6752 - val_loss: 391.4065 - val_mae: 18.6742\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 474.5346 - mae: 19.6279 - val_loss: 389.6534 - val_mae: 18.6272\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 472.6930 - mae: 19.5812 - val_loss: 387.8937 - val_mae: 18.5799\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 470.8454 - mae: 19.5339 - val_loss: 386.1599 - val_mae: 18.5332\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 469.0242 - mae: 19.4876 - val_loss: 384.4221 - val_mae: 18.4863\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.1984 - mae: 19.4404 - val_loss: 382.6943 - val_mae: 18.4395\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.3838 - mae: 19.3938 - val_loss: 380.9767 - val_mae: 18.3929\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 463.5789 - mae: 19.3471 - val_loss: 379.2806 - val_mae: 18.3467\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 461.7965 - mae: 19.3012 - val_loss: 377.5737 - val_mae: 18.3001\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 460.0031 - mae: 19.2542 - val_loss: 375.8922 - val_mae: 18.2541\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 458.2358 - mae: 19.2082 - val_loss: 374.2233 - val_mae: 18.2083\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 456.4801 - mae: 19.1628 - val_loss: 372.5370 - val_mae: 18.1620\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 454.7078 - mae: 19.1170 - val_loss: 370.8691 - val_mae: 18.1160\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 452.9535 - mae: 19.0706 - val_loss: 369.1978 - val_mae: 18.0698\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 451.1956 - mae: 19.0244 - val_loss: 367.5402 - val_mae: 18.0239\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 449.4524 - mae: 18.9793 - val_loss: 365.8958 - val_mae: 17.9782\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.7230 - mae: 18.9333 - val_loss: 364.2762 - val_mae: 17.9331\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 446.0191 - mae: 18.8876 - val_loss: 362.6634 - val_mae: 17.8881\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 444.3219 - mae: 18.8426 - val_loss: 361.0446 - val_mae: 17.8428\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 442.6184 - mae: 18.7973 - val_loss: 359.4407 - val_mae: 17.7978\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 440.9305 - mae: 18.7525 - val_loss: 357.8481 - val_mae: 17.7530\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 439.2534 - mae: 18.7078 - val_loss: 356.2493 - val_mae: 17.7079\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 437.5708 - mae: 18.6625 - val_loss: 354.6712 - val_mae: 17.6633\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 435.9088 - mae: 18.6179 - val_loss: 353.0891 - val_mae: 17.6184\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 434.2433 - mae: 18.5738 - val_loss: 351.5321 - val_mae: 17.5742\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 432.6029 - mae: 18.5295 - val_loss: 349.9686 - val_mae: 17.5297\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 430.9558 - mae: 18.4851 - val_loss: 348.4037 - val_mae: 17.4850\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 429.3079 - mae: 18.4404 - val_loss: 346.8571 - val_mae: 17.4407\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 427.6780 - mae: 18.3959 - val_loss: 345.3220 - val_mae: 17.3966\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.0603 - mae: 18.3521 - val_loss: 343.7900 - val_mae: 17.3525\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 424.4457 - mae: 18.3080 - val_loss: 342.2573 - val_mae: 17.3083\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 422.8315 - mae: 18.2635 - val_loss: 340.7560 - val_mae: 17.2649\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 421.2478 - mae: 18.2205 - val_loss: 339.2484 - val_mae: 17.2212\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 419.6581 - mae: 18.1766 - val_loss: 337.7475 - val_mae: 17.1775\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 418.0756 - mae: 18.1331 - val_loss: 336.2614 - val_mae: 17.1342\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 416.5089 - mae: 18.0903 - val_loss: 334.7890 - val_mae: 17.0912\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 414.9551 - mae: 18.0470 - val_loss: 333.3073 - val_mae: 17.0478\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 413.3918 - mae: 18.0035 - val_loss: 331.8243 - val_mae: 17.0043\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 411.8273 - mae: 17.9596 - val_loss: 330.3583 - val_mae: 16.9611\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 410.2815 - mae: 17.9169 - val_loss: 328.9250 - val_mae: 16.9188\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 408.7679 - mae: 17.8744 - val_loss: 327.4764 - val_mae: 16.8759\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 407.2394 - mae: 17.8320 - val_loss: 326.0362 - val_mae: 16.8332\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 405.7188 - mae: 17.7889 - val_loss: 324.5931 - val_mae: 16.7903\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 404.1948 - mae: 17.7463 - val_loss: 323.1448 - val_mae: 16.7471\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.6662 - mae: 17.7036 - val_loss: 321.7311 - val_mae: 16.7048\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 401.1726 - mae: 17.6612 - val_loss: 320.3141 - val_mae: 16.6624\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 415.2590 - mae: 18.2213\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 56667496.0000 - mae: 2238.0610 - val_loss: 742.2400 - val_mae: 26.4492\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 832.8025 - mae: 27.1812 - val_loss: 262.0474 - val_mae: 14.5538\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 814.8817 - mae: 25.9713 - val_loss: 735.8595 - val_mae: 26.3283\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 833.1601 - mae: 27.2745 - val_loss: 732.4161 - val_mae: 26.2628\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 829.5967 - mae: 27.2091 - val_loss: 728.9816 - val_mae: 26.1974\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 826.0424 - mae: 27.1431 - val_loss: 725.5880 - val_mae: 26.1325\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 822.5291 - mae: 27.0790 - val_loss: 722.1928 - val_mae: 26.0675\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 819.0141 - mae: 27.0142 - val_loss: 718.8028 - val_mae: 26.0024\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 815.5061 - mae: 26.9493 - val_loss: 715.4724 - val_mae: 25.9382\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 812.0558 - mae: 26.8849 - val_loss: 712.1086 - val_mae: 25.8733\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 808.5738 - mae: 26.8197 - val_loss: 708.7814 - val_mae: 25.8089\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 805.1284 - mae: 26.7554 - val_loss: 705.4758 - val_mae: 25.7448\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 828.7385 - mae: 27.3037\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 125)               1750      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,876\n",
      "Trainable params: 1,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 37791412.0000 - mae: 1933.2407 - val_loss: 211.2204 - val_mae: 12.4934\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 420.0926 - mae: 17.9638 - val_loss: 354.9820 - val_mae: 17.6726\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 436.4010 - mae: 18.6317 - val_loss: 353.4224 - val_mae: 17.6284\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 434.7579 - mae: 18.5875 - val_loss: 351.8510 - val_mae: 17.5837\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 433.1027 - mae: 18.5430 - val_loss: 350.2821 - val_mae: 17.5391\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 431.4501 - mae: 18.4977 - val_loss: 348.7369 - val_mae: 17.4950\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 429.8217 - mae: 18.4544 - val_loss: 347.1872 - val_mae: 17.4506\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 428.1884 - mae: 18.4102 - val_loss: 345.6377 - val_mae: 17.4062\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.5564 - mae: 18.3659 - val_loss: 344.1245 - val_mae: 17.3626\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 424.9598 - mae: 18.3221 - val_loss: 342.5856 - val_mae: 17.3183\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 423.3382 - mae: 18.2774 - val_loss: 341.0677 - val_mae: 17.2744\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 438.0844 - mae: 18.8372\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "[(5, 415.259033203125, 18.221284866333008),\n (25, 828.7384643554688, 27.303747177124023),\n (125, 438.08441162109375, 18.83722686767578)]"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "algorytm optymalizacji (opt): wszystkie 4 algorytmy (pęd = 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 427640096.0000 - mae: 6068.5132 - val_loss: 50.2310 - val_mae: 5.8455\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 68.1092 - mae: 5.6119 - val_loss: 44.7272 - val_mae: 5.4800\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.9172 - mae: 6.5169 - val_loss: 63.2436 - val_mae: 6.5680\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.1590 - mae: 6.3033 - val_loss: 24.1667 - val_mae: 3.9273\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 72.4588 - mae: 5.7591 - val_loss: 20.9668 - val_mae: 3.7882\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.2368 - mae: 6.3764 - val_loss: 23.6464 - val_mae: 3.8395\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 74.2032 - mae: 5.9708 - val_loss: 57.0141 - val_mae: 6.1931\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 67.9367 - mae: 5.5529 - val_loss: 31.0139 - val_mae: 4.5552\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 75.2416 - mae: 6.0198 - val_loss: 35.7568 - val_mae: 4.8845\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 83.9463 - mae: 6.5886 - val_loss: 65.1463 - val_mae: 6.9203\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 111.5790 - mae: 7.6795 - val_loss: 59.2978 - val_mae: 6.3403\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 77.4788 - mae: 5.8305 - val_loss: 36.5915 - val_mae: 4.9438\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 74.9417 - mae: 6.1343 - val_loss: 74.6826 - val_mae: 7.1379\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 80.0499 - mae: 6.0394 - val_loss: 28.7014 - val_mae: 4.4724\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 71.2392 - mae: 5.7090 - val_loss: 21.0458 - val_mae: 3.7924\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 62.7852 - mae: 5.9250\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 18719734.0000 - mae: 1289.9166 - val_loss: 389.7881 - val_mae: 18.6308\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 472.8355 - mae: 19.5854 - val_loss: 388.0593 - val_mae: 18.5844\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 471.0197 - mae: 19.5386 - val_loss: 386.3384 - val_mae: 18.5380\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 469.2118 - mae: 19.4922 - val_loss: 384.6055 - val_mae: 18.4912\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 467.3916 - mae: 19.4456 - val_loss: 382.8755 - val_mae: 18.4444\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 465.5745 - mae: 19.3982 - val_loss: 381.1711 - val_mae: 18.3981\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 463.7831 - mae: 19.3527 - val_loss: 379.4622 - val_mae: 18.3516\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 461.9870 - mae: 19.3064 - val_loss: 377.7538 - val_mae: 18.3050\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 460.1928 - mae: 19.2599 - val_loss: 376.0840 - val_mae: 18.2594\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 458.4361 - mae: 19.2140 - val_loss: 374.3875 - val_mae: 18.2128\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 456.6534 - mae: 19.1672 - val_loss: 372.7135 - val_mae: 18.1668\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 454.8937 - mae: 19.1212 - val_loss: 371.0515 - val_mae: 18.1210\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 453.1462 - mae: 19.0758 - val_loss: 369.4053 - val_mae: 18.0756\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 451.4140 - mae: 19.0301 - val_loss: 367.7529 - val_mae: 18.0298\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 449.6761 - mae: 18.9844 - val_loss: 366.1121 - val_mae: 17.9842\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.9510 - mae: 18.9392 - val_loss: 364.4906 - val_mae: 17.9391\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 446.2433 - mae: 18.8944 - val_loss: 362.8352 - val_mae: 17.8929\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 444.5035 - mae: 18.8480 - val_loss: 361.2366 - val_mae: 17.8482\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 442.8199 - mae: 18.8031 - val_loss: 359.6162 - val_mae: 17.8027\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 441.1148 - mae: 18.7576 - val_loss: 358.0244 - val_mae: 17.7580\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 439.4385 - mae: 18.7129 - val_loss: 356.4023 - val_mae: 17.7122\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 437.7316 - mae: 18.6679 - val_loss: 354.8141 - val_mae: 17.6673\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 436.0598 - mae: 18.6228 - val_loss: 353.2456 - val_mae: 17.6229\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 434.4078 - mae: 18.5778 - val_loss: 351.6718 - val_mae: 17.5782\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 432.7504 - mae: 18.5334 - val_loss: 350.1055 - val_mae: 17.5336\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 431.1001 - mae: 18.4887 - val_loss: 348.5515 - val_mae: 17.4892\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 429.4637 - mae: 18.4446 - val_loss: 347.0189 - val_mae: 17.4453\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 427.8481 - mae: 18.4007 - val_loss: 345.4674 - val_mae: 17.4008\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.2141 - mae: 18.3560 - val_loss: 343.9397 - val_mae: 17.3568\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 424.6043 - mae: 18.3127 - val_loss: 342.4251 - val_mae: 17.3132\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 423.0070 - mae: 18.2693 - val_loss: 340.8980 - val_mae: 17.2690\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 421.3972 - mae: 18.2250 - val_loss: 339.3907 - val_mae: 17.2253\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 419.8082 - mae: 18.1813 - val_loss: 337.8886 - val_mae: 17.1816\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 418.2235 - mae: 18.1374 - val_loss: 336.3752 - val_mae: 17.1376\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 416.6281 - mae: 18.0933 - val_loss: 334.8811 - val_mae: 17.0939\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 415.0531 - mae: 18.0496 - val_loss: 333.4112 - val_mae: 17.0509\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.5014 - mae: 18.0068 - val_loss: 331.9320 - val_mae: 17.0074\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 411.9418 - mae: 17.9632 - val_loss: 330.4787 - val_mae: 16.9646\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.4075 - mae: 17.9207 - val_loss: 329.0171 - val_mae: 16.9215\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.8659 - mae: 17.8776 - val_loss: 327.5852 - val_mae: 16.8791\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 407.3536 - mae: 17.8348 - val_loss: 326.1252 - val_mae: 16.8358\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 405.8127 - mae: 17.7912 - val_loss: 324.6905 - val_mae: 16.7932\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 404.2979 - mae: 17.7493 - val_loss: 323.2599 - val_mae: 16.7505\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 402.7877 - mae: 17.7072 - val_loss: 321.8428 - val_mae: 16.7082\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 401.2910 - mae: 17.6639 - val_loss: 320.4297 - val_mae: 16.6658\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.7990 - mae: 17.6217 - val_loss: 319.0364 - val_mae: 16.6240\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 398.3266 - mae: 17.5798 - val_loss: 317.6275 - val_mae: 16.5816\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 396.8386 - mae: 17.5381 - val_loss: 316.2552 - val_mae: 16.5401\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 395.3884 - mae: 17.4962 - val_loss: 314.8757 - val_mae: 16.4984\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.9307 - mae: 17.4555 - val_loss: 313.4960 - val_mae: 16.4565\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 392.4717 - mae: 17.4139 - val_loss: 312.1171 - val_mae: 16.4146\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 391.0143 - mae: 17.3726 - val_loss: 310.7515 - val_mae: 16.3729\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 389.5709 - mae: 17.3309 - val_loss: 309.3903 - val_mae: 16.3313\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.1315 - mae: 17.2900 - val_loss: 308.0258 - val_mae: 16.2895\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 386.6879 - mae: 17.2484 - val_loss: 306.6767 - val_mae: 16.2480\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 385.2616 - mae: 17.2074 - val_loss: 305.3402 - val_mae: 16.2068\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 383.8470 - mae: 17.1670 - val_loss: 303.9970 - val_mae: 16.1653\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 382.4264 - mae: 17.1258 - val_loss: 302.6755 - val_mae: 16.1244\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 381.0279 - mae: 17.0858 - val_loss: 301.3496 - val_mae: 16.0832\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 379.6244 - mae: 17.0450 - val_loss: 300.0315 - val_mae: 16.0422\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 378.2298 - mae: 17.0044 - val_loss: 298.7214 - val_mae: 16.0013\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 376.8427 - mae: 16.9638 - val_loss: 297.4291 - val_mae: 15.9609\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 375.4745 - mae: 16.9242 - val_loss: 296.1266 - val_mae: 15.9200\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 374.0956 - mae: 16.8832 - val_loss: 294.8452 - val_mae: 15.8797\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 372.7387 - mae: 16.8435 - val_loss: 293.5739 - val_mae: 15.8396\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 371.3911 - mae: 16.8044 - val_loss: 292.2868 - val_mae: 15.7990\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 370.0279 - mae: 16.7646 - val_loss: 291.0147 - val_mae: 15.7586\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 368.6797 - mae: 16.7243 - val_loss: 289.7387 - val_mae: 15.7181\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 367.3274 - mae: 16.6840 - val_loss: 288.4738 - val_mae: 15.6778\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 365.9872 - mae: 16.6451 - val_loss: 287.2197 - val_mae: 15.6378\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 364.6580 - mae: 16.6051 - val_loss: 285.9862 - val_mae: 15.5983\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 363.3503 - mae: 16.5657 - val_loss: 284.7578 - val_mae: 15.5589\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 362.0476 - mae: 16.5265 - val_loss: 283.5233 - val_mae: 15.5191\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 360.7385 - mae: 16.4872 - val_loss: 282.3009 - val_mae: 15.4797\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 359.4422 - mae: 16.4485 - val_loss: 281.0876 - val_mae: 15.4405\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 358.1545 - mae: 16.4097 - val_loss: 279.8681 - val_mae: 15.4009\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 356.8609 - mae: 16.3704 - val_loss: 278.6657 - val_mae: 15.3618\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 355.5847 - mae: 16.3319 - val_loss: 277.4591 - val_mae: 15.3225\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 354.3046 - mae: 16.2936 - val_loss: 276.2735 - val_mae: 15.2838\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 353.0455 - mae: 16.2553 - val_loss: 275.0814 - val_mae: 15.2447\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 351.7798 - mae: 16.2167 - val_loss: 273.8872 - val_mae: 15.2055\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 350.5125 - mae: 16.1782 - val_loss: 272.7082 - val_mae: 15.1667\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 349.2601 - mae: 16.1397 - val_loss: 271.5385 - val_mae: 15.1281\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 348.0176 - mae: 16.1020 - val_loss: 270.3706 - val_mae: 15.0894\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 346.7770 - mae: 16.0640 - val_loss: 269.2014 - val_mae: 15.0506\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 345.5359 - mae: 16.0254 - val_loss: 268.0586 - val_mae: 15.0126\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 344.3207 - mae: 15.9886 - val_loss: 266.9097 - val_mae: 14.9743\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 343.0994 - mae: 15.9507 - val_loss: 265.7658 - val_mae: 14.9361\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 341.8836 - mae: 15.9132 - val_loss: 264.6339 - val_mae: 14.8981\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 340.6808 - mae: 15.8765 - val_loss: 263.5132 - val_mae: 14.8605\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 339.4886 - mae: 15.8391 - val_loss: 262.3837 - val_mae: 14.8224\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 338.2871 - mae: 15.8015 - val_loss: 261.2522 - val_mae: 14.7842\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 337.0838 - mae: 15.7636 - val_loss: 260.1348 - val_mae: 14.7464\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 335.8961 - mae: 15.7270 - val_loss: 259.0451 - val_mae: 14.7094\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 334.7358 - mae: 15.6902 - val_loss: 257.9414 - val_mae: 14.6718\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.5616 - mae: 15.6537 - val_loss: 256.8441 - val_mae: 14.6344\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 332.3936 - mae: 15.6168 - val_loss: 255.7436 - val_mae: 14.5967\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 331.2218 - mae: 15.5798 - val_loss: 254.6379 - val_mae: 14.5588\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 330.0452 - mae: 15.5430 - val_loss: 253.5614 - val_mae: 14.5218\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 328.8984 - mae: 15.5064 - val_loss: 252.4814 - val_mae: 14.4862\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 340.6363 - mae: 16.0723\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 474553.4375 - mae: 223.2872 - val_loss: 541.5010 - val_mae: 22.3343\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 630.3618 - mae: 23.2623 - val_loss: 536.5930 - val_mae: 22.2242\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 625.2416 - mae: 23.1513 - val_loss: 531.7123 - val_mae: 22.1141\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 620.1628 - mae: 23.0412 - val_loss: 526.8676 - val_mae: 22.0043\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 615.0948 - mae: 22.9311 - val_loss: 522.0208 - val_mae: 21.8939\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 610.0583 - mae: 22.8198 - val_loss: 517.2224 - val_mae: 21.7840\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 605.0963 - mae: 22.7122 - val_loss: 512.5037 - val_mae: 21.6754\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 600.1605 - mae: 22.6036 - val_loss: 507.8075 - val_mae: 21.5668\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 595.2573 - mae: 22.4951 - val_loss: 503.1667 - val_mae: 21.4590\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 590.4595 - mae: 22.3877 - val_loss: 498.5774 - val_mae: 21.3518\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 585.6472 - mae: 22.2791 - val_loss: 493.9842 - val_mae: 21.2439\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 580.8911 - mae: 22.1721 - val_loss: 489.4856 - val_mae: 21.1378\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 576.1969 - mae: 22.0668 - val_loss: 485.0444 - val_mae: 21.0325\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 571.5709 - mae: 21.9611 - val_loss: 480.6178 - val_mae: 20.9270\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 566.9534 - mae: 21.8559 - val_loss: 476.2315 - val_mae: 20.8219\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 562.3851 - mae: 21.7516 - val_loss: 471.9102 - val_mae: 20.7179\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 557.8795 - mae: 21.6486 - val_loss: 467.6181 - val_mae: 20.6140\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 553.3486 - mae: 21.5430 - val_loss: 463.3214 - val_mae: 20.5096\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 548.9353 - mae: 21.4399 - val_loss: 459.1288 - val_mae: 20.4071\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 544.5238 - mae: 21.3367 - val_loss: 454.9473 - val_mae: 20.3044\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 540.1856 - mae: 21.2347 - val_loss: 450.8017 - val_mae: 20.2020\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 535.8134 - mae: 21.1329 - val_loss: 446.6795 - val_mae: 20.0997\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 531.5360 - mae: 21.0308 - val_loss: 442.6246 - val_mae: 19.9986\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 527.3224 - mae: 20.9293 - val_loss: 438.6230 - val_mae: 19.8983\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 523.1281 - mae: 20.8294 - val_loss: 434.6424 - val_mae: 19.7980\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 518.9697 - mae: 20.7291 - val_loss: 430.7028 - val_mae: 19.6983\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 514.8629 - mae: 20.6303 - val_loss: 426.8190 - val_mae: 19.5995\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 510.8167 - mae: 20.5318 - val_loss: 422.9839 - val_mae: 19.5014\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 506.7714 - mae: 20.4326 - val_loss: 419.1390 - val_mae: 19.4026\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 502.7805 - mae: 20.3360 - val_loss: 415.3798 - val_mae: 19.3054\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 498.8437 - mae: 20.2393 - val_loss: 411.6498 - val_mae: 19.2086\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 494.9112 - mae: 20.1415 - val_loss: 407.9231 - val_mae: 19.1113\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 491.0297 - mae: 20.0450 - val_loss: 404.2619 - val_mae: 19.0153\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 487.1891 - mae: 19.9484 - val_loss: 400.6038 - val_mae: 18.9189\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 483.3429 - mae: 19.8516 - val_loss: 396.9799 - val_mae: 18.8229\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 479.5633 - mae: 19.7559 - val_loss: 393.3969 - val_mae: 18.7274\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 475.8387 - mae: 19.6619 - val_loss: 389.8912 - val_mae: 18.6336\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 472.1374 - mae: 19.5670 - val_loss: 386.3900 - val_mae: 18.5394\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 468.4926 - mae: 19.4743 - val_loss: 382.9513 - val_mae: 18.4465\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 464.8655 - mae: 19.3807 - val_loss: 379.5329 - val_mae: 18.3536\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 461.3078 - mae: 19.2878 - val_loss: 376.1527 - val_mae: 18.2612\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 457.7271 - mae: 19.1941 - val_loss: 372.7614 - val_mae: 18.1682\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 454.1973 - mae: 19.1035 - val_loss: 369.4450 - val_mae: 18.0767\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 450.7047 - mae: 19.0128 - val_loss: 366.1638 - val_mae: 17.9857\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.2632 - mae: 18.9201 - val_loss: 362.9000 - val_mae: 17.8947\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 443.8455 - mae: 18.8297 - val_loss: 359.6834 - val_mae: 17.8046\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 440.4827 - mae: 18.7400 - val_loss: 356.5015 - val_mae: 17.7150\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 437.1130 - mae: 18.6512 - val_loss: 353.3495 - val_mae: 17.6258\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 433.8289 - mae: 18.5619 - val_loss: 350.2501 - val_mae: 17.5377\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 430.5529 - mae: 18.4747 - val_loss: 347.1682 - val_mae: 17.4496\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 427.2951 - mae: 18.3858 - val_loss: 344.0888 - val_mae: 17.3611\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 424.0539 - mae: 18.2978 - val_loss: 341.0376 - val_mae: 17.2730\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 420.8567 - mae: 18.2091 - val_loss: 338.0179 - val_mae: 17.1854\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 417.6841 - mae: 18.1224 - val_loss: 335.0220 - val_mae: 17.0980\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 414.5204 - mae: 18.0341 - val_loss: 332.0564 - val_mae: 17.0111\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 411.4047 - mae: 17.9475 - val_loss: 329.1349 - val_mae: 16.9250\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.3310 - mae: 17.8622 - val_loss: 326.2324 - val_mae: 16.8390\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 405.2648 - mae: 17.7759 - val_loss: 323.3515 - val_mae: 16.7533\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.2451 - mae: 17.6916 - val_loss: 320.5321 - val_mae: 16.6689\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.2493 - mae: 17.6062 - val_loss: 317.6999 - val_mae: 16.5837\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 396.2733 - mae: 17.5217 - val_loss: 314.9140 - val_mae: 16.4995\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.3335 - mae: 17.4378 - val_loss: 312.1585 - val_mae: 16.4158\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 390.4409 - mae: 17.3561 - val_loss: 309.4350 - val_mae: 16.3326\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 387.5535 - mae: 17.2724 - val_loss: 306.7169 - val_mae: 16.2492\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 384.7115 - mae: 17.1911 - val_loss: 304.0546 - val_mae: 16.1671\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 381.9027 - mae: 17.1110 - val_loss: 301.4192 - val_mae: 16.0854\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 379.0828 - mae: 17.0302 - val_loss: 298.7942 - val_mae: 16.0036\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 376.3093 - mae: 16.9484 - val_loss: 296.1708 - val_mae: 15.9214\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 373.5367 - mae: 16.8669 - val_loss: 293.5775 - val_mae: 15.8398\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 370.7998 - mae: 16.7881 - val_loss: 291.0225 - val_mae: 15.7589\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 368.1012 - mae: 16.7076 - val_loss: 288.5001 - val_mae: 15.6787\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 365.4545 - mae: 16.6281 - val_loss: 286.0233 - val_mae: 15.5995\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 362.8354 - mae: 16.5495 - val_loss: 283.5547 - val_mae: 15.5201\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 360.2157 - mae: 16.4711 - val_loss: 281.1105 - val_mae: 15.4412\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 357.6317 - mae: 16.3937 - val_loss: 278.6985 - val_mae: 15.3629\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 355.0779 - mae: 16.3163 - val_loss: 276.3024 - val_mae: 15.2847\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 352.5310 - mae: 16.2385 - val_loss: 273.9171 - val_mae: 15.2065\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 350.0198 - mae: 16.1621 - val_loss: 271.5696 - val_mae: 15.1291\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 347.5164 - mae: 16.0871 - val_loss: 269.2562 - val_mae: 15.0525\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 345.0689 - mae: 16.0119 - val_loss: 266.9537 - val_mae: 14.9758\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 342.6175 - mae: 15.9362 - val_loss: 264.6675 - val_mae: 14.8993\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 340.1780 - mae: 15.8607 - val_loss: 262.3981 - val_mae: 14.8229\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 337.7788 - mae: 15.7854 - val_loss: 260.1496 - val_mae: 14.7469\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 335.4051 - mae: 15.7117 - val_loss: 257.9357 - val_mae: 14.6716\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 333.0500 - mae: 15.6376 - val_loss: 255.7332 - val_mae: 14.5964\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 330.7071 - mae: 15.5626 - val_loss: 253.5555 - val_mae: 14.5216\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 328.4178 - mae: 15.4910 - val_loss: 251.4186 - val_mae: 14.4513\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.1334 - mae: 15.4179 - val_loss: 249.2906 - val_mae: 14.3811\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 323.8671 - mae: 15.3454 - val_loss: 247.1928 - val_mae: 14.3115\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.6370 - mae: 15.2749 - val_loss: 245.1228 - val_mae: 14.2425\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 319.4374 - mae: 15.2034 - val_loss: 243.0652 - val_mae: 14.1735\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.2331 - mae: 15.1320 - val_loss: 241.0107 - val_mae: 14.1043\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.0392 - mae: 15.0601 - val_loss: 238.9605 - val_mae: 14.0349\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.8755 - mae: 14.9909 - val_loss: 236.9647 - val_mae: 13.9670\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.7695 - mae: 14.9215 - val_loss: 235.0099 - val_mae: 13.9001\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 308.6602 - mae: 14.8531 - val_loss: 233.0449 - val_mae: 13.8325\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.5668 - mae: 14.7840 - val_loss: 231.0932 - val_mae: 13.7651\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.4766 - mae: 14.7148 - val_loss: 229.1441 - val_mae: 13.6974\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 302.3852 - mae: 14.6464 - val_loss: 227.2293 - val_mae: 13.6305\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 300.3588 - mae: 14.5782 - val_loss: 225.3369 - val_mae: 13.5641\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 310.4692 - mae: 15.1842\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 7793.9702 - mae: 80.3827 - val_loss: 7021.1401 - val_mae: 76.9776\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7026.9209 - mae: 75.8216 - val_loss: 6336.8911 - val_mae: 72.8007\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6335.4224 - mae: 71.4668 - val_loss: 5716.0259 - val_mae: 68.7553\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5704.3315 - mae: 67.1667 - val_loss: 5162.2607 - val_mae: 65.0439\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5151.4082 - mae: 63.2182 - val_loss: 4655.5879 - val_mae: 61.3824\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4647.3389 - mae: 59.4561 - val_loss: 4206.3584 - val_mae: 57.9887\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4202.0078 - mae: 56.1839 - val_loss: 3815.3660 - val_mae: 55.1394\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3813.7156 - mae: 53.4690 - val_loss: 3469.8940 - val_mae: 52.7231\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3470.4558 - mae: 51.1336 - val_loss: 3164.5964 - val_mae: 50.5118\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3174.2180 - mae: 49.1165 - val_loss: 2894.6316 - val_mae: 48.5196\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2911.0662 - mae: 47.2376 - val_loss: 2652.7344 - val_mae: 46.5792\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2683.5388 - mae: 45.5746 - val_loss: 2440.1167 - val_mae: 44.7805\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2475.7434 - mae: 43.7962 - val_loss: 2260.9961 - val_mae: 43.1749\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2300.9944 - mae: 42.2437 - val_loss: 2100.3967 - val_mae: 41.6256\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2144.5518 - mae: 40.7657 - val_loss: 1953.3590 - val_mae: 40.1807\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2001.7534 - mae: 39.3229 - val_loss: 1824.1311 - val_mae: 38.8564\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1878.2531 - mae: 38.0848 - val_loss: 1707.4790 - val_mae: 37.6791\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1766.5720 - mae: 36.9084 - val_loss: 1602.5479 - val_mae: 36.6093\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1668.3187 - mae: 35.8346 - val_loss: 1508.7598 - val_mae: 35.6055\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1577.5916 - mae: 34.8455 - val_loss: 1423.4032 - val_mae: 34.6334\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1496.6237 - mae: 33.9175 - val_loss: 1345.6582 - val_mae: 33.6943\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1421.0187 - mae: 33.0566 - val_loss: 1274.3145 - val_mae: 32.7870\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1353.8337 - mae: 32.2331 - val_loss: 1209.4034 - val_mae: 31.9213\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1293.3370 - mae: 31.4846 - val_loss: 1148.5615 - val_mae: 31.0716\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1233.8311 - mae: 30.7594 - val_loss: 1092.8160 - val_mae: 30.2649\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1179.7134 - mae: 30.0741 - val_loss: 1040.4404 - val_mae: 29.4771\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1128.3610 - mae: 29.4244 - val_loss: 990.5715 - val_mae: 28.6990\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1080.0438 - mae: 28.7923 - val_loss: 943.2673 - val_mae: 27.9387\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1034.5475 - mae: 28.1927 - val_loss: 897.9095 - val_mae: 27.2096\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 990.4178 - mae: 27.5933 - val_loss: 856.2799 - val_mae: 26.5383\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 950.8003 - mae: 27.0376 - val_loss: 815.7426 - val_mae: 25.8819\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 910.8494 - mae: 26.4704 - val_loss: 777.3751 - val_mae: 25.2210\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 872.7269 - mae: 25.9098 - val_loss: 741.8725 - val_mae: 24.6052\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 838.0963 - mae: 25.3757 - val_loss: 706.7032 - val_mae: 23.9727\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 803.3307 - mae: 24.8439 - val_loss: 673.9481 - val_mae: 23.3705\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 771.3572 - mae: 24.3173 - val_loss: 642.2473 - val_mae: 22.7746\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 739.6414 - mae: 23.8022 - val_loss: 612.7393 - val_mae: 22.2040\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 710.6755 - mae: 23.2897 - val_loss: 583.9825 - val_mae: 21.6187\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 681.7645 - mae: 22.7918 - val_loss: 557.2991 - val_mae: 21.0877\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 655.2712 - mae: 22.3083 - val_loss: 531.1753 - val_mae: 20.5633\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 628.8886 - mae: 21.8230 - val_loss: 506.5040 - val_mae: 20.0484\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 604.3976 - mae: 21.3565 - val_loss: 482.7787 - val_mae: 19.5313\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 580.4760 - mae: 20.8864 - val_loss: 460.1606 - val_mae: 19.0382\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 557.5646 - mae: 20.4328 - val_loss: 438.9131 - val_mae: 18.5535\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 535.9130 - mae: 19.9824 - val_loss: 418.6067 - val_mae: 18.0866\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 515.0260 - mae: 19.5434 - val_loss: 398.6575 - val_mae: 17.6319\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 495.1033 - mae: 19.0949 - val_loss: 379.6048 - val_mae: 17.1854\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 476.0299 - mae: 18.6737 - val_loss: 361.6630 - val_mae: 16.7420\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 457.7574 - mae: 18.2488 - val_loss: 344.8990 - val_mae: 16.3197\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 440.8987 - mae: 17.8503 - val_loss: 329.2533 - val_mae: 15.9111\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 425.0519 - mae: 17.4520 - val_loss: 314.3745 - val_mae: 15.5050\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 409.4652 - mae: 17.0744 - val_loss: 300.6523 - val_mae: 15.1098\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 395.2957 - mae: 16.7093 - val_loss: 287.0985 - val_mae: 14.7085\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 381.0864 - mae: 16.3468 - val_loss: 274.9301 - val_mae: 14.3374\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 368.1441 - mae: 16.0044 - val_loss: 262.9276 - val_mae: 13.9552\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 355.7164 - mae: 15.6704 - val_loss: 251.9109 - val_mae: 13.6005\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 343.5641 - mae: 15.3339 - val_loss: 241.4027 - val_mae: 13.2581\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 332.6851 - mae: 15.0259 - val_loss: 231.5267 - val_mae: 12.9162\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 321.9015 - mae: 14.7199 - val_loss: 222.1641 - val_mae: 12.5943\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.9385 - mae: 14.4199 - val_loss: 213.3421 - val_mae: 12.2822\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 302.5380 - mae: 14.1407 - val_loss: 205.1319 - val_mae: 11.9814\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 293.5591 - mae: 13.8721 - val_loss: 197.7036 - val_mae: 11.7011\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 285.3822 - mae: 13.6049 - val_loss: 190.4468 - val_mae: 11.4291\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 277.6581 - mae: 13.3546 - val_loss: 183.6685 - val_mae: 11.1694\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 269.9245 - mae: 13.1109 - val_loss: 177.4445 - val_mae: 10.9211\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 262.8886 - mae: 12.8728 - val_loss: 171.0562 - val_mae: 10.6546\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 255.8658 - mae: 12.6404 - val_loss: 165.4527 - val_mae: 10.4122\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 249.5693 - mae: 12.4329 - val_loss: 160.0944 - val_mae: 10.1823\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 243.4672 - mae: 12.2464 - val_loss: 155.2348 - val_mae: 9.9915\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 237.9176 - mae: 12.0517 - val_loss: 150.3326 - val_mae: 9.7902\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 232.2009 - mae: 11.8587 - val_loss: 146.1746 - val_mae: 9.6137\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 227.2771 - mae: 11.6963 - val_loss: 142.1255 - val_mae: 9.4345\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 222.4419 - mae: 11.5172 - val_loss: 138.0720 - val_mae: 9.2483\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 218.0050 - mae: 11.3563 - val_loss: 134.4905 - val_mae: 9.0780\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 213.7962 - mae: 11.1995 - val_loss: 131.0634 - val_mae: 8.9079\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 209.8887 - mae: 11.0565 - val_loss: 128.0228 - val_mae: 8.7633\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 206.1862 - mae: 10.9277 - val_loss: 125.3797 - val_mae: 8.6310\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 202.6845 - mae: 10.8092 - val_loss: 122.7362 - val_mae: 8.5066\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 199.4203 - mae: 10.6962 - val_loss: 120.0185 - val_mae: 8.3972\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 196.2456 - mae: 10.5749 - val_loss: 117.5619 - val_mae: 8.2936\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 193.1738 - mae: 10.4695 - val_loss: 115.4373 - val_mae: 8.1961\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 190.5029 - mae: 10.3838 - val_loss: 113.4379 - val_mae: 8.1062\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 187.7676 - mae: 10.2821 - val_loss: 111.4850 - val_mae: 8.0206\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 185.1636 - mae: 10.1916 - val_loss: 109.5142 - val_mae: 7.9296\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 182.5680 - mae: 10.1140 - val_loss: 107.9110 - val_mae: 7.8588\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 180.4486 - mae: 10.0604 - val_loss: 106.5831 - val_mae: 7.8096\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 178.0493 - mae: 9.9811 - val_loss: 104.7424 - val_mae: 7.7448\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 175.8976 - mae: 9.9076 - val_loss: 103.1279 - val_mae: 7.6871\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 173.6904 - mae: 9.8402 - val_loss: 101.7028 - val_mae: 7.6339\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 171.7297 - mae: 9.7801 - val_loss: 100.4044 - val_mae: 7.5838\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 170.0922 - mae: 9.7299 - val_loss: 99.0639 - val_mae: 7.5362\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 168.3436 - mae: 9.6868 - val_loss: 98.2851 - val_mae: 7.5077\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 166.6364 - mae: 9.6420 - val_loss: 97.3315 - val_mae: 7.4787\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 165.0614 - mae: 9.5900 - val_loss: 96.1531 - val_mae: 7.4405\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 163.7136 - mae: 9.5452 - val_loss: 94.8980 - val_mae: 7.3991\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 162.0891 - mae: 9.4902 - val_loss: 93.9439 - val_mae: 7.3657\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 160.8691 - mae: 9.4498 - val_loss: 93.0909 - val_mae: 7.3359\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 159.4219 - mae: 9.4104 - val_loss: 92.2424 - val_mae: 7.3049\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 158.2404 - mae: 9.3689 - val_loss: 91.2809 - val_mae: 7.2681\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 156.8911 - mae: 9.3368 - val_loss: 90.7445 - val_mae: 7.2476\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 144.2864 - mae: 9.1756\n"
     ]
    }
   ],
   "source": [
    "results_alg = []\n",
    "for alg in (\"sgd\", \"nesterov\", \"momentum\", \"adam\"):\n",
    "    run_logdir = get_run_logdir(\"alg\", alg)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    model = build_model(optimizer=alg, momentum=.5)\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[es, tensorboard])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    results_alg.append((alg, score[0], score[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "[('sgd', 62.78519821166992, 5.925008773803711),\n ('nesterov', 340.63629150390625, 16.072277069091797),\n ('momentum', 310.46917724609375, 15.184233665466309),\n ('adam', 144.28643798828125, 9.175629615783691)]"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_alg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " pęd (mom): 0.1, 0.5, 0.9 (dla algorytmu momentum)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 18974574.0000 - mae: 1321.2195 - val_loss: 649.2841 - val_mae: 24.6293\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 743.3138 - mae: 25.5749 - val_loss: 645.9587 - val_mae: 24.5617\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 739.8649 - mae: 25.5069 - val_loss: 642.6512 - val_mae: 24.4943\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 736.4330 - mae: 25.4395 - val_loss: 639.3362 - val_mae: 24.4266\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 732.9897 - mae: 25.3718 - val_loss: 636.0274 - val_mae: 24.3587\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 729.5564 - mae: 25.3034 - val_loss: 632.7566 - val_mae: 24.2915\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 726.1654 - mae: 25.2371 - val_loss: 629.4913 - val_mae: 24.2242\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 722.7736 - mae: 25.1700 - val_loss: 626.2313 - val_mae: 24.1568\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 719.3900 - mae: 25.1028 - val_loss: 623.0251 - val_mae: 24.0904\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 716.0658 - mae: 25.0362 - val_loss: 619.7988 - val_mae: 24.0233\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 712.7109 - mae: 24.9686 - val_loss: 616.6000 - val_mae: 23.9566\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 709.3932 - mae: 24.9021 - val_loss: 613.4273 - val_mae: 23.8903\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 706.0992 - mae: 24.8363 - val_loss: 610.2816 - val_mae: 23.8244\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 702.8330 - mae: 24.7701 - val_loss: 607.1364 - val_mae: 23.7583\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.5640 - mae: 24.7041 - val_loss: 604.0098 - val_mae: 23.6924\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 696.3181 - mae: 24.6386 - val_loss: 600.9153 - val_mae: 23.6270\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 693.1029 - mae: 24.5737 - val_loss: 597.7877 - val_mae: 23.5607\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 689.8481 - mae: 24.5070 - val_loss: 594.7281 - val_mae: 23.4957\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 686.6774 - mae: 24.4420 - val_loss: 591.6591 - val_mae: 23.4303\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.4829 - mae: 24.3765 - val_loss: 588.6260 - val_mae: 23.3655\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 680.3336 - mae: 24.3118 - val_loss: 585.5662 - val_mae: 23.2999\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.1469 - mae: 24.2470 - val_loss: 582.5472 - val_mae: 23.2351\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.0146 - mae: 24.1819 - val_loss: 579.5648 - val_mae: 23.1708\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.9160 - mae: 24.1172 - val_loss: 576.5854 - val_mae: 23.1064\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.8157 - mae: 24.0531 - val_loss: 573.6184 - val_mae: 23.0421\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 664.7302 - mae: 23.9887 - val_loss: 570.6738 - val_mae: 22.9781\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 661.6699 - mae: 23.9251 - val_loss: 567.7628 - val_mae: 22.9147\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 658.6436 - mae: 23.8617 - val_loss: 564.8383 - val_mae: 22.8508\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 655.5974 - mae: 23.7975 - val_loss: 561.9435 - val_mae: 22.7874\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 652.5896 - mae: 23.7350 - val_loss: 559.0751 - val_mae: 22.7243\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 649.6050 - mae: 23.6722 - val_loss: 556.1989 - val_mae: 22.6610\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 646.6082 - mae: 23.6086 - val_loss: 553.3488 - val_mae: 22.5980\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 643.6448 - mae: 23.5458 - val_loss: 550.5146 - val_mae: 22.5352\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 640.6934 - mae: 23.4827 - val_loss: 547.6717 - val_mae: 22.4720\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 637.7313 - mae: 23.4195 - val_loss: 544.8552 - val_mae: 22.4093\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 634.8029 - mae: 23.3567 - val_loss: 542.0769 - val_mae: 22.3472\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 631.9126 - mae: 23.2950 - val_loss: 539.2975 - val_mae: 22.2849\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 629.0163 - mae: 23.2325 - val_loss: 536.5524 - val_mae: 22.2232\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 626.1603 - mae: 23.1713 - val_loss: 533.8073 - val_mae: 22.1614\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 623.2991 - mae: 23.1094 - val_loss: 531.1015 - val_mae: 22.1003\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 620.4837 - mae: 23.0479 - val_loss: 528.3718 - val_mae: 22.0384\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 617.6338 - mae: 22.9856 - val_loss: 525.6713 - val_mae: 21.9771\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 614.8240 - mae: 22.9252 - val_loss: 522.9863 - val_mae: 21.9159\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 612.0257 - mae: 22.8647 - val_loss: 520.3232 - val_mae: 21.8551\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 609.2516 - mae: 22.8028 - val_loss: 517.6721 - val_mae: 21.7943\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 606.4890 - mae: 22.7422 - val_loss: 515.0505 - val_mae: 21.7341\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 603.7579 - mae: 22.6820 - val_loss: 512.4183 - val_mae: 21.6735\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 601.0103 - mae: 22.6221 - val_loss: 509.8325 - val_mae: 21.6137\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 598.3196 - mae: 22.5619 - val_loss: 507.2498 - val_mae: 21.5539\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 595.6235 - mae: 22.5028 - val_loss: 504.6693 - val_mae: 21.4939\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 592.9301 - mae: 22.4426 - val_loss: 502.0940 - val_mae: 21.4340\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 590.2432 - mae: 22.3828 - val_loss: 499.5392 - val_mae: 21.3743\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 587.5801 - mae: 22.3227 - val_loss: 496.9970 - val_mae: 21.3147\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 584.9277 - mae: 22.2635 - val_loss: 494.4556 - val_mae: 21.2550\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 582.2736 - mae: 22.2034 - val_loss: 491.9372 - val_mae: 21.1957\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 579.6477 - mae: 22.1442 - val_loss: 489.4412 - val_mae: 21.1367\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 577.0430 - mae: 22.0856 - val_loss: 486.9437 - val_mae: 21.0776\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 574.4344 - mae: 22.0263 - val_loss: 484.4754 - val_mae: 21.0189\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 571.8604 - mae: 21.9683 - val_loss: 482.0110 - val_mae: 20.9602\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 569.2848 - mae: 21.9093 - val_loss: 479.5583 - val_mae: 20.9016\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 566.7250 - mae: 21.8509 - val_loss: 477.1216 - val_mae: 20.8433\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 564.1804 - mae: 21.7925 - val_loss: 474.7124 - val_mae: 20.7854\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 561.6664 - mae: 21.7350 - val_loss: 472.2981 - val_mae: 20.7272\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 559.1423 - mae: 21.6762 - val_loss: 469.9113 - val_mae: 20.6696\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 556.6524 - mae: 21.6187 - val_loss: 467.5456 - val_mae: 20.6123\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 554.1797 - mae: 21.5618 - val_loss: 465.1666 - val_mae: 20.5545\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 551.6894 - mae: 21.5046 - val_loss: 462.8067 - val_mae: 20.4970\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 549.2243 - mae: 21.4467 - val_loss: 460.4483 - val_mae: 20.4394\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 546.7574 - mae: 21.3890 - val_loss: 458.1067 - val_mae: 20.3820\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 544.3111 - mae: 21.3326 - val_loss: 455.7845 - val_mae: 20.3250\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 541.8848 - mae: 21.2751 - val_loss: 453.4936 - val_mae: 20.2685\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 539.4925 - mae: 21.2182 - val_loss: 451.2170 - val_mae: 20.2123\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 537.1114 - mae: 21.1620 - val_loss: 448.9377 - val_mae: 20.1558\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 534.7252 - mae: 21.1055 - val_loss: 446.6759 - val_mae: 20.0997\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 532.3606 - mae: 21.0496 - val_loss: 444.4313 - val_mae: 20.0437\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 530.0122 - mae: 20.9938 - val_loss: 442.1843 - val_mae: 19.9876\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 527.6597 - mae: 20.9374 - val_loss: 439.9607 - val_mae: 19.9319\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 525.3347 - mae: 20.8818 - val_loss: 437.7390 - val_mae: 19.8761\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 523.0082 - mae: 20.8267 - val_loss: 435.5463 - val_mae: 19.8209\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 520.7151 - mae: 20.7715 - val_loss: 433.3528 - val_mae: 19.7655\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 518.4164 - mae: 20.7162 - val_loss: 431.1596 - val_mae: 19.7099\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 516.1190 - mae: 20.6606 - val_loss: 428.9878 - val_mae: 19.6547\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 513.8466 - mae: 20.6052 - val_loss: 426.8336 - val_mae: 19.5998\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 511.5914 - mae: 20.5507 - val_loss: 424.6872 - val_mae: 19.5450\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 509.3426 - mae: 20.4959 - val_loss: 422.5431 - val_mae: 19.4901\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 507.0967 - mae: 20.4406 - val_loss: 420.4345 - val_mae: 19.4359\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 504.8908 - mae: 20.3871 - val_loss: 418.3271 - val_mae: 19.3816\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 502.6801 - mae: 20.3325 - val_loss: 416.2282 - val_mae: 19.3274\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 500.4805 - mae: 20.2785 - val_loss: 414.1486 - val_mae: 19.2735\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 498.3026 - mae: 20.2251 - val_loss: 412.0883 - val_mae: 19.2200\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 496.1431 - mae: 20.1713 - val_loss: 410.0226 - val_mae: 19.1662\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 493.9743 - mae: 20.1173 - val_loss: 407.9563 - val_mae: 19.1122\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.8067 - mae: 20.0630 - val_loss: 405.9095 - val_mae: 19.0586\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.6637 - mae: 20.0099 - val_loss: 403.9030 - val_mae: 19.0059\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 487.5623 - mae: 19.9571 - val_loss: 401.8887 - val_mae: 18.9528\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 485.4457 - mae: 19.9045 - val_loss: 399.8822 - val_mae: 18.8998\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 483.3408 - mae: 19.8511 - val_loss: 397.8764 - val_mae: 18.8467\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 481.2339 - mae: 19.7983 - val_loss: 395.8666 - val_mae: 18.7933\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 479.1236 - mae: 19.7454 - val_loss: 393.8950 - val_mae: 18.7407\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 477.0583 - mae: 19.6928 - val_loss: 391.9277 - val_mae: 18.6882\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 493.1888 - mae: 20.2471\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 6498237.5000 - mae: 912.8161 - val_loss: 409.2480 - val_mae: 19.1460\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 492.3568 - mae: 20.0780 - val_loss: 405.5058 - val_mae: 19.0480\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 488.5284 - mae: 19.9817 - val_loss: 401.9010 - val_mae: 18.9531\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 484.7503 - mae: 19.8868 - val_loss: 398.3216 - val_mae: 18.8585\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 480.9760 - mae: 19.7918 - val_loss: 394.7347 - val_mae: 18.7631\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 477.2229 - mae: 19.6955 - val_loss: 391.1841 - val_mae: 18.6683\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 473.5285 - mae: 19.6029 - val_loss: 387.6964 - val_mae: 18.5746\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 469.8511 - mae: 19.5093 - val_loss: 384.2226 - val_mae: 18.4809\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 466.1963 - mae: 19.4155 - val_loss: 380.7911 - val_mae: 18.3878\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 462.6267 - mae: 19.3229 - val_loss: 377.3984 - val_mae: 18.2953\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 459.0395 - mae: 19.2290 - val_loss: 373.9973 - val_mae: 18.2021\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 455.4951 - mae: 19.1366 - val_loss: 370.6721 - val_mae: 18.1106\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 451.9990 - mae: 19.0459 - val_loss: 367.3911 - val_mae: 18.0198\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 448.5562 - mae: 18.9546 - val_loss: 364.1175 - val_mae: 17.9287\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 445.1156 - mae: 18.8638 - val_loss: 360.8735 - val_mae: 17.8380\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 441.7124 - mae: 18.7738 - val_loss: 357.6804 - val_mae: 17.7483\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 438.3579 - mae: 18.6851 - val_loss: 354.5073 - val_mae: 17.6586\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 434.9767 - mae: 18.5937 - val_loss: 351.3256 - val_mae: 17.5683\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 431.6917 - mae: 18.5047 - val_loss: 348.2282 - val_mae: 17.4799\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 428.4033 - mae: 18.4156 - val_loss: 345.1356 - val_mae: 17.3913\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 425.1734 - mae: 18.3277 - val_loss: 342.0691 - val_mae: 17.3029\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 421.9091 - mae: 18.2398 - val_loss: 339.0181 - val_mae: 17.2145\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 418.7219 - mae: 18.1515 - val_loss: 336.0199 - val_mae: 17.1272\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 415.5846 - mae: 18.0638 - val_loss: 333.0631 - val_mae: 17.0406\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 412.4594 - mae: 17.9776 - val_loss: 330.1198 - val_mae: 16.9541\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 409.3604 - mae: 17.8910 - val_loss: 327.2070 - val_mae: 16.8679\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 406.3014 - mae: 17.8058 - val_loss: 324.3376 - val_mae: 16.7827\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 403.2899 - mae: 17.7208 - val_loss: 321.5057 - val_mae: 16.6981\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 400.2746 - mae: 17.6351 - val_loss: 318.6609 - val_mae: 16.6127\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 397.3019 - mae: 17.5519 - val_loss: 315.8853 - val_mae: 16.5289\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 394.3712 - mae: 17.4687 - val_loss: 313.1304 - val_mae: 16.4454\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 391.4395 - mae: 17.3853 - val_loss: 310.3742 - val_mae: 16.3614\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 388.5477 - mae: 17.3025 - val_loss: 307.6700 - val_mae: 16.2785\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 385.6868 - mae: 17.2204 - val_loss: 304.9643 - val_mae: 16.1952\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 382.8167 - mae: 17.1376 - val_loss: 302.2838 - val_mae: 16.1122\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 379.9999 - mae: 17.0556 - val_loss: 299.6343 - val_mae: 16.0298\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 377.2262 - mae: 16.9755 - val_loss: 297.0470 - val_mae: 15.9489\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 374.4683 - mae: 16.8943 - val_loss: 294.4596 - val_mae: 15.8676\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 371.7551 - mae: 16.8156 - val_loss: 291.9217 - val_mae: 15.7874\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 369.0530 - mae: 16.7355 - val_loss: 289.3974 - val_mae: 15.7073\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 366.4068 - mae: 16.6565 - val_loss: 286.9019 - val_mae: 15.6276\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 363.7365 - mae: 16.5758 - val_loss: 284.3932 - val_mae: 15.5471\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 361.1063 - mae: 16.4993 - val_loss: 281.9447 - val_mae: 15.4682\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 358.5042 - mae: 16.4218 - val_loss: 279.5228 - val_mae: 15.3897\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 355.9421 - mae: 16.3426 - val_loss: 277.1120 - val_mae: 15.3112\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 353.3969 - mae: 16.2651 - val_loss: 274.7380 - val_mae: 15.2335\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 350.8952 - mae: 16.1888 - val_loss: 272.3900 - val_mae: 15.1562\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 348.3835 - mae: 16.1134 - val_loss: 270.0641 - val_mae: 15.0793\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 345.9420 - mae: 16.0378 - val_loss: 267.7796 - val_mae: 15.0033\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 343.5038 - mae: 15.9642 - val_loss: 265.5065 - val_mae: 14.9274\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 341.0775 - mae: 15.8884 - val_loss: 263.2322 - val_mae: 14.8510\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 338.6617 - mae: 15.8139 - val_loss: 260.9786 - val_mae: 14.7749\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 336.2805 - mae: 15.7384 - val_loss: 258.7484 - val_mae: 14.6993\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.9168 - mae: 15.6646 - val_loss: 256.5352 - val_mae: 14.6238\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 331.5571 - mae: 15.5899 - val_loss: 254.3447 - val_mae: 14.5487\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 329.2354 - mae: 15.5163 - val_loss: 252.1885 - val_mae: 14.4766\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 326.9464 - mae: 15.4440 - val_loss: 250.0454 - val_mae: 14.4060\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 324.6604 - mae: 15.3706 - val_loss: 247.9174 - val_mae: 14.3356\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.4111 - mae: 15.2992 - val_loss: 245.8389 - val_mae: 14.2664\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 320.1789 - mae: 15.2273 - val_loss: 243.7463 - val_mae: 14.1964\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 317.9607 - mae: 15.1559 - val_loss: 241.6901 - val_mae: 14.1272\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 315.7701 - mae: 15.0845 - val_loss: 239.6567 - val_mae: 14.0585\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 313.6171 - mae: 15.0148 - val_loss: 237.6477 - val_mae: 13.9902\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 311.4653 - mae: 14.9439 - val_loss: 235.6403 - val_mae: 13.9217\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 309.3493 - mae: 14.8750 - val_loss: 233.6775 - val_mae: 13.8543\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 307.2587 - mae: 14.8069 - val_loss: 231.7347 - val_mae: 13.7873\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 305.1555 - mae: 14.7382 - val_loss: 229.7979 - val_mae: 13.7201\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 303.0891 - mae: 14.6687 - val_loss: 227.8595 - val_mae: 13.6525\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 301.0203 - mae: 14.5996 - val_loss: 225.9438 - val_mae: 13.5854\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 298.9794 - mae: 14.5326 - val_loss: 224.0581 - val_mae: 13.5190\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 296.9683 - mae: 14.4644 - val_loss: 222.1976 - val_mae: 13.4531\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 294.9989 - mae: 14.3969 - val_loss: 220.3730 - val_mae: 13.3882\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 293.0506 - mae: 14.3300 - val_loss: 218.5526 - val_mae: 13.3231\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 291.0986 - mae: 14.2639 - val_loss: 216.7505 - val_mae: 13.2583\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 289.1745 - mae: 14.1984 - val_loss: 214.9731 - val_mae: 13.1940\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.2734 - mae: 14.1337 - val_loss: 213.2064 - val_mae: 13.1299\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 285.3755 - mae: 14.0693 - val_loss: 211.4464 - val_mae: 13.0656\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 283.5055 - mae: 14.0065 - val_loss: 209.7162 - val_mae: 13.0021\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 281.6394 - mae: 13.9443 - val_loss: 208.0122 - val_mae: 12.9392\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.8186 - mae: 13.8825 - val_loss: 206.3151 - val_mae: 12.8763\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 277.9919 - mae: 13.8207 - val_loss: 204.6293 - val_mae: 12.8134\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 276.1726 - mae: 13.7589 - val_loss: 202.9553 - val_mae: 12.7507\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 274.3853 - mae: 13.6976 - val_loss: 201.2967 - val_mae: 12.6882\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 272.6173 - mae: 13.6383 - val_loss: 199.6652 - val_mae: 12.6265\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 270.8629 - mae: 13.5779 - val_loss: 198.0408 - val_mae: 12.5646\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 269.1162 - mae: 13.5172 - val_loss: 196.4353 - val_mae: 12.5032\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 267.4130 - mae: 13.4591 - val_loss: 194.8621 - val_mae: 12.4427\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 265.7115 - mae: 13.4000 - val_loss: 193.2941 - val_mae: 12.3821\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 264.0231 - mae: 13.3415 - val_loss: 191.7495 - val_mae: 12.3221\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 262.3635 - mae: 13.2839 - val_loss: 190.2264 - val_mae: 12.2626\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 260.7274 - mae: 13.2260 - val_loss: 188.7115 - val_mae: 12.2032\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 259.0850 - mae: 13.1679 - val_loss: 187.1969 - val_mae: 12.1434\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 257.4489 - mae: 13.1096 - val_loss: 185.6838 - val_mae: 12.0834\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 255.8365 - mae: 13.0529 - val_loss: 184.2148 - val_mae: 12.0248\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 254.2713 - mae: 12.9961 - val_loss: 182.7784 - val_mae: 11.9672\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 252.7011 - mae: 12.9408 - val_loss: 181.3313 - val_mae: 11.9089\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 251.1421 - mae: 12.8847 - val_loss: 179.8933 - val_mae: 11.8507\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 249.5835 - mae: 12.8282 - val_loss: 178.4554 - val_mae: 11.7922\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 248.0216 - mae: 12.7725 - val_loss: 177.0445 - val_mae: 11.7344\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 246.5134 - mae: 12.7162 - val_loss: 175.6507 - val_mae: 11.6771\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 254.5980 - mae: 13.4472\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 25)                350       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 27779566.0000 - mae: 1548.0587 - val_loss: 48.1292 - val_mae: 5.6120\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 121.7601 - mae: 9.4141 - val_loss: 145.3375 - val_mae: 10.5294\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 195.1229 - mae: 12.6640 - val_loss: 190.9088 - val_mae: 12.3459\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 220.0825 - mae: 13.5447 - val_loss: 200.3286 - val_mae: 12.7083\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 222.9443 - mae: 13.6347 - val_loss: 198.0465 - val_mae: 12.6215\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 219.1737 - mae: 13.5061 - val_loss: 192.6529 - val_mae: 12.4139\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 213.8216 - mae: 13.3223 - val_loss: 186.3307 - val_mae: 12.1657\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 208.0689 - mae: 13.1209 - val_loss: 180.0758 - val_mae: 11.9147\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.4560 - mae: 12.9282 - val_loss: 174.0867 - val_mae: 11.6796\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 196.9970 - mae: 12.7338 - val_loss: 168.3111 - val_mae: 11.4497\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 191.8149 - mae: 12.5479 - val_loss: 162.9342 - val_mae: 11.2413\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 171.7382 - mae: 11.4307\n"
     ]
    }
   ],
   "source": [
    "results_mom = []\n",
    "for mom in (.1, .5, .9):\n",
    "    run_logdir = get_run_logdir(\"momentum\", mom)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    model = build_model(optimizer=\"momentum\", momentum=mom)\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[es, tensorboard])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    results_mom.append((mom, score[0], score[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.1, 493.1888427734375, 20.24709701538086),\n (0.5, 254.59796142578125, 13.4472017288208),\n (0.9, 171.73822021484375, 11.43071174621582)]"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mom"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Automatyczne poszukiwanie przestrzeni argumentów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przygotuj słownik zawierający przeszukiwane wartości parametrów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": [5, 25, 125],\n",
    "    \"learning_rate\": [10e-6, 10e-5, 10e-4],\n",
    "    \"optimizer\": [\"sgd\", \"adam\", \"nesterov\", \"momentum\"],\n",
    "    \"momentum\": [.1, .5, .9]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przygotuj callback early stopping i obuduj przygotowaną wcześniej funkcję build_model obiektem\n",
    "KerasRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fudal\\AppData\\Local\\Temp/ipykernel_17604/461105605.py:4: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = KerasRegressor(build_model, callbacks=[es])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1.0, verbose=1)\n",
    "keras_reg = KerasRegressor(build_model, callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   1.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 21ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   1.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 27ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   1.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 19ms/step - loss: 450.1658 - mae: 18.7335 - val_loss: 124.1662 - val_mae: 8.6812\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117.3908 - mae: 7.8624 - val_loss: 63.9276 - val_mae: 6.7702\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 137.9716 - mae: 8.2034 - val_loss: 46.1937 - val_mae: 5.6523\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.8009 - mae: 6.8760 - val_loss: 42.3801 - val_mae: 5.4833\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.0800 - mae: 7.4312 - val_loss: 53.4871 - val_mae: 6.1132\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.2987 - mae: 7.2351 - val_loss: 35.5351 - val_mae: 5.0602\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.3380 - mae: 6.3799 - val_loss: 27.9020 - val_mae: 4.3462\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.7850 - mae: 6.1432 - val_loss: 27.2991 - val_mae: 4.3639\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.7006 - mae: 6.2033 - val_loss: 31.5764 - val_mae: 4.7034\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1419 - mae: 6.3370 - val_loss: 29.2452 - val_mae: 4.5421\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3916 - mae: 6.0013 - val_loss: 25.1723 - val_mae: 4.1908\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.2615 - mae: 5.8330 - val_loss: 25.0171 - val_mae: 4.2019\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.8312 - mae: 5.8307 - val_loss: 24.8244 - val_mae: 4.2010\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 69.3315 - mae: 5.9790 - val_loss: 26.1620 - val_mae: 4.3873\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.2801 - mae: 5.6750 - val_loss: 22.1758 - val_mae: 3.9566\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.6201 - mae: 5.5217 - val_loss: 23.1392 - val_mae: 4.0516\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.4807 - mae: 5.6344 - val_loss: 22.5694 - val_mae: 4.0076\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.6845 - mae: 5.5554 - val_loss: 21.9711 - val_mae: 3.9436\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.3200 - mae: 5.4179 - val_loss: 20.6993 - val_mae: 3.8067\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.7312 - mae: 5.6092 - val_loss: 22.4464 - val_mae: 4.0243\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.1757 - mae: 5.7549 - val_loss: 20.0027 - val_mae: 3.7800\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62.8418 - mae: 5.3236 - val_loss: 18.3416 - val_mae: 3.5926\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.3161 - mae: 5.2542 - val_loss: 20.5008 - val_mae: 3.8160\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.8677 - mae: 5.5845 - val_loss: 20.1764 - val_mae: 3.7853\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.2578 - mae: 5.4771 - val_loss: 17.9495 - val_mae: 3.5353\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6853 - mae: 5.1910 - val_loss: 18.3470 - val_mae: 3.6054\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.0135 - mae: 5.3649 - val_loss: 20.2287 - val_mae: 3.8112\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.8540 - mae: 5.3621 - val_loss: 17.8671 - val_mae: 3.5336\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 59.3784 - mae: 5.1220 - val_loss: 17.7410 - val_mae: 3.5157\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.3013 - mae: 5.4364 - val_loss: 19.4063 - val_mae: 3.7264\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.3424 - mae: 5.1167 - val_loss: 16.5265 - val_mae: 3.4113\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.2159 - mae: 5.0193 - val_loss: 16.8421 - val_mae: 3.4435\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58.4049 - mae: 5.3759 - val_loss: 18.6358 - val_mae: 3.6468\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.6311 - mae: 5.1230 - val_loss: 15.5200 - val_mae: 3.3026\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.0323 - mae: 5.0946 - val_loss: 17.8344 - val_mae: 3.5334\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.6650 - mae: 5.2525 - val_loss: 16.8964 - val_mae: 3.4228\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.1601 - mae: 5.0171 - val_loss: 16.2941 - val_mae: 3.3804\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.1504 - mae: 5.0117 - val_loss: 17.2032 - val_mae: 3.5110\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.4104 - mae: 5.0617 - val_loss: 16.2304 - val_mae: 3.3552\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.9352 - mae: 4.9124 - val_loss: 15.9716 - val_mae: 3.2967\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.9953 - mae: 5.2864 - val_loss: 18.7839 - val_mae: 3.6531\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.8862 - mae: 4.9236 - val_loss: 15.1137 - val_mae: 3.2293\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.8064 - mae: 4.9253 - val_loss: 17.9234 - val_mae: 3.6279\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.0660 - mae: 5.0997 - val_loss: 15.6633 - val_mae: 3.2924\n",
      "Epoch 44: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.4824 - mae: 5.1323\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=125, optimizer=adam; total time=   2.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 446.8630 - mae: 17.5538 - val_loss: 121.8429 - val_mae: 9.9578\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 192.8571 - mae: 10.9436 - val_loss: 165.4869 - val_mae: 9.7835\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.8072 - mae: 10.3482 - val_loss: 96.2642 - val_mae: 7.5879\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.7020 - mae: 8.2710 - val_loss: 45.7363 - val_mae: 5.3448\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8973 - mae: 7.4667 - val_loss: 37.2343 - val_mae: 4.6588\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.6073 - mae: 7.4182 - val_loss: 39.5093 - val_mae: 4.8943\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.7579 - mae: 7.3889 - val_loss: 34.7451 - val_mae: 4.6969\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6876 - mae: 6.9898 - val_loss: 28.5544 - val_mae: 4.2101\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7711 - mae: 6.7726 - val_loss: 28.4721 - val_mae: 4.3086\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.3453 - mae: 6.7651 - val_loss: 27.7039 - val_mae: 4.3034\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.1851 - mae: 6.5728 - val_loss: 25.1044 - val_mae: 4.0649\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.8827 - mae: 6.3186 - val_loss: 22.6255 - val_mae: 3.7707\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.9474 - mae: 6.3185 - val_loss: 24.5969 - val_mae: 4.1450\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.5625 - mae: 6.4809 - val_loss: 23.2481 - val_mae: 4.0026\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.8779 - mae: 6.1372 - val_loss: 19.8850 - val_mae: 3.5622\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4512 - mae: 6.2247 - val_loss: 22.3857 - val_mae: 3.9316\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.4746 - mae: 6.1641 - val_loss: 19.8631 - val_mae: 3.6210\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.4528 - mae: 6.0837 - val_loss: 20.6679 - val_mae: 3.7572\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3047 - mae: 6.0429 - val_loss: 19.5686 - val_mae: 3.6098\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.0536 - mae: 6.1037 - val_loss: 20.3712 - val_mae: 3.7382\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.4345 - mae: 6.2966 - val_loss: 19.3238 - val_mae: 3.6245\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4905 - mae: 5.8299 - val_loss: 16.0063 - val_mae: 3.1517\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.3739 - mae: 5.8251 - val_loss: 20.1365 - val_mae: 3.7729\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.7561 - mae: 6.2509 - val_loss: 19.4254 - val_mae: 3.6800\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.3650 - mae: 5.9660 - val_loss: 16.0785 - val_mae: 3.2204\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.4025 - mae: 5.7086 - val_loss: 17.0474 - val_mae: 3.3954\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7837 - mae: 5.9975 - val_loss: 19.0063 - val_mae: 3.6896\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.7019 - mae: 5.8126 - val_loss: 15.8504 - val_mae: 3.2205\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.7675 - mae: 5.7350 - val_loss: 17.5608 - val_mae: 3.4759\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.4149 - mae: 5.8291 - val_loss: 16.9513 - val_mae: 3.4315\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.1173 - mae: 5.8444 - val_loss: 16.4084 - val_mae: 3.3513\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.4102 - mae: 5.6942 - val_loss: 14.5102 - val_mae: 3.0494\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.4699 - mae: 5.8561 - val_loss: 19.1026 - val_mae: 3.7109\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.1802 - mae: 5.8416 - val_loss: 14.3829 - val_mae: 3.0523\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.4790 - mae: 5.6864 - val_loss: 17.1185 - val_mae: 3.4615\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.7632 - mae: 5.9591 - val_loss: 15.5509 - val_mae: 3.2402\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.1579 - mae: 5.5085 - val_loss: 14.2620 - val_mae: 3.0469\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.2590 - mae: 5.6282 - val_loss: 16.1438 - val_mae: 3.3625\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.9514 - mae: 5.7586 - val_loss: 14.7737 - val_mae: 3.1505\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.8891 - mae: 5.4071 - val_loss: 13.6354 - val_mae: 2.9694\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.4240 - mae: 5.9051 - val_loss: 18.8361 - val_mae: 3.6977\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.5035 - mae: 5.6093 - val_loss: 13.0885 - val_mae: 2.8935\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.1511 - mae: 5.3501 - val_loss: 15.1817 - val_mae: 3.2516\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.3923 - mae: 5.7526 - val_loss: 15.3166 - val_mae: 3.2739\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.7078 - mae: 5.6990 - val_loss: 13.9333 - val_mae: 3.0527\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.2980 - mae: 5.2444 - val_loss: 13.2735 - val_mae: 2.9655\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.1838 - mae: 5.5287 - val_loss: 15.5702 - val_mae: 3.3030\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.1124 - mae: 5.6222 - val_loss: 13.4395 - val_mae: 2.9828\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.2527 - mae: 5.2039 - val_loss: 13.5034 - val_mae: 2.9996\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.0014 - mae: 5.8351 - val_loss: 19.2467 - val_mae: 3.7651\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.6793 - mae: 5.4430 - val_loss: 12.2691 - val_mae: 2.7819\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.4154 - mae: 5.3080 - val_loss: 16.0686 - val_mae: 3.3323\n",
      "Epoch 52: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 36.2944 - mae: 4.7203\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=125, optimizer=adam; total time=   2.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1452.1533 - mae: 35.7937 - val_loss: 649.1470 - val_mae: 22.5727\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.5430 - mae: 17.3747 - val_loss: 213.5744 - val_mae: 11.8312\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.4499 - mae: 11.5452 - val_loss: 214.0088 - val_mae: 11.4865\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 168.0565 - mae: 10.0455 - val_loss: 151.1831 - val_mae: 9.8580\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.3020 - mae: 7.8043 - val_loss: 77.5711 - val_mae: 6.6173\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.6782 - mae: 6.0701 - val_loss: 57.8629 - val_mae: 5.2915\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.4706 - mae: 6.0675 - val_loss: 51.4550 - val_mae: 5.2438\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.6512 - mae: 6.0603 - val_loss: 50.6230 - val_mae: 5.5248\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.7265 - mae: 5.9708 - val_loss: 49.0678 - val_mae: 5.4665\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.3619 - mae: 5.7271 - val_loss: 46.6893 - val_mae: 5.2240\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.4694 - mae: 5.4741 - val_loss: 44.7291 - val_mae: 5.0441\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.0247 - mae: 5.3294 - val_loss: 43.7374 - val_mae: 5.0120\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.1279 - mae: 5.2528 - val_loss: 42.5924 - val_mae: 4.9737\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.2765 - mae: 5.1867 - val_loss: 42.2467 - val_mae: 4.9555\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.7805 - mae: 5.2403 - val_loss: 41.9354 - val_mae: 4.9454\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.2389 - mae: 5.2125 - val_loss: 40.9628 - val_mae: 4.9027\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.8465 - mae: 5.1509 - val_loss: 41.0259 - val_mae: 4.8784\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.0979 - mae: 5.0919 - val_loss: 40.4204 - val_mae: 4.8546\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.2274 - mae: 4.9776 - val_loss: 40.0258 - val_mae: 4.8264\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.5189 - mae: 5.0202 - val_loss: 40.0340 - val_mae: 4.7846\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.1325 - mae: 5.0066 - val_loss: 39.7052 - val_mae: 4.7484\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.9592 - mae: 4.9318 - val_loss: 39.3202 - val_mae: 4.7311\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51.8703 - mae: 4.8859 - val_loss: 39.2761 - val_mae: 4.7047\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.2816 - mae: 4.9994 - val_loss: 39.4947 - val_mae: 4.6859\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.0676 - mae: 5.0164 - val_loss: 39.1028 - val_mae: 4.6592\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.4473 - mae: 4.8633 - val_loss: 38.7692 - val_mae: 4.6517\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.9808 - mae: 4.9750 - val_loss: 39.6152 - val_mae: 4.6443\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.5000 - mae: 5.0022 - val_loss: 38.5911 - val_mae: 4.5901\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.3291 - mae: 4.7825 - val_loss: 38.2955 - val_mae: 4.5994\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.1231 - mae: 4.8507 - val_loss: 38.2408 - val_mae: 4.5569\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.7717 - mae: 4.9030 - val_loss: 38.1206 - val_mae: 4.5345\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.5963 - mae: 4.7529 - val_loss: 37.8472 - val_mae: 4.5375\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.4138 - mae: 4.8307 - val_loss: 38.0232 - val_mae: 4.5549\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.0454 - mae: 4.8551 - val_loss: 37.4563 - val_mae: 4.5042\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.0280 - mae: 4.6945 - val_loss: 37.1948 - val_mae: 4.4958\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.6397 - mae: 4.8069 - val_loss: 37.2887 - val_mae: 4.5212\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.6723 - mae: 4.8807 - val_loss: 36.8343 - val_mae: 4.4996\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.2632 - mae: 4.6569 - val_loss: 36.7991 - val_mae: 4.5061\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.7220 - mae: 4.6858 - val_loss: 36.6748 - val_mae: 4.4710\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.8557 - mae: 4.7130 - val_loss: 36.1741 - val_mae: 4.4628\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.8792 - mae: 4.6394 - val_loss: 36.0466 - val_mae: 4.4543\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.5912 - mae: 4.6766 - val_loss: 35.7528 - val_mae: 4.4374\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.3802 - mae: 4.8084 - val_loss: 36.4711 - val_mae: 4.4778\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.2779 - mae: 4.7420 - val_loss: 35.3691 - val_mae: 4.4662\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.0514 - mae: 4.5357 - val_loss: 35.1723 - val_mae: 4.4061\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.5164 - mae: 4.6787 - val_loss: 35.1560 - val_mae: 4.4129\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.6682 - mae: 4.7853 - val_loss: 35.0118 - val_mae: 4.3849\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.6382 - mae: 4.5100 - val_loss: 34.7773 - val_mae: 4.4494\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.8702 - mae: 4.6368 - val_loss: 34.5266 - val_mae: 4.3696\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.8164 - mae: 4.5779 - val_loss: 34.2606 - val_mae: 4.4169\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.8825 - mae: 4.5769 - val_loss: 34.1332 - val_mae: 4.3464\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.4604 - mae: 4.5168 - val_loss: 33.6388 - val_mae: 4.3750\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.0351 - mae: 4.4877 - val_loss: 33.3679 - val_mae: 4.3198\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.0116 - mae: 4.6565 - val_loss: 32.9691 - val_mae: 4.3287\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.8788 - mae: 4.4978 - val_loss: 32.5964 - val_mae: 4.3483\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.4653 - mae: 4.5881 - val_loss: 32.8130 - val_mae: 4.2968\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.1202 - mae: 4.4897 - val_loss: 32.2090 - val_mae: 4.2999\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.8481 - mae: 4.4116 - val_loss: 31.7588 - val_mae: 4.2736\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.5402 - mae: 4.4034 - val_loss: 31.7353 - val_mae: 4.2399\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.4291 - mae: 4.5765 - val_loss: 31.5847 - val_mae: 4.2442\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.2935 - mae: 4.3811 - val_loss: 31.5959 - val_mae: 4.3124\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43.5706 - mae: 4.4930 - val_loss: 31.3671 - val_mae: 4.2107\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.6974 - mae: 4.4211 - val_loss: 30.9177 - val_mae: 4.2874\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.7433 - mae: 4.3202 - val_loss: 30.8306 - val_mae: 4.2696\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.7479 - mae: 4.4546 - val_loss: 30.5634 - val_mae: 4.2453\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.3783 - mae: 4.3784 - val_loss: 30.5424 - val_mae: 4.2883\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.0046 - mae: 4.3492 - val_loss: 30.4737 - val_mae: 4.1699\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.0911 - mae: 4.5007 - val_loss: 30.1320 - val_mae: 4.2229\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.1518 - mae: 4.2499 - val_loss: 30.0336 - val_mae: 4.2338\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.5793 - mae: 4.4314 - val_loss: 29.8068 - val_mae: 4.2059\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.4382 - mae: 4.2915 - val_loss: 29.8152 - val_mae: 4.2699\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.2024 - mae: 4.3232 - val_loss: 29.6399 - val_mae: 4.1425\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 41.8209 - mae: 4.2806 - val_loss: 29.5244 - val_mae: 4.2510\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.5920 - mae: 4.2961 - val_loss: 29.1583 - val_mae: 4.1718\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.6490 - mae: 4.3605 - val_loss: 28.8860 - val_mae: 4.1822\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.6391 - mae: 4.1967 - val_loss: 28.9843 - val_mae: 4.1805\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.4747 - mae: 4.3201 - val_loss: 28.7861 - val_mae: 4.1401\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 40.2187 - mae: 4.2645 - val_loss: 28.4647 - val_mae: 4.2146\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 40.9931 - mae: 4.4305 - val_loss: 28.1561 - val_mae: 4.1507\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.9930 - mae: 4.1264 - val_loss: 28.7570 - val_mae: 4.2267\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.9238 - mae: 4.2006 - val_loss: 27.8384 - val_mae: 4.1046\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.7737 - mae: 4.3617 - val_loss: 27.7437 - val_mae: 4.1519\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.4436 - mae: 4.0380 - val_loss: 27.7945 - val_mae: 4.1959\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.0738 - mae: 4.2746 - val_loss: 27.3837 - val_mae: 4.1082\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.8117 - mae: 4.3112 - val_loss: 27.5908 - val_mae: 4.1389\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.7883 - mae: 4.0295 - val_loss: 27.2313 - val_mae: 4.0842\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.5390 - mae: 4.1098 - val_loss: 26.8208 - val_mae: 4.0697\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38.1776 - mae: 4.1373 - val_loss: 26.7133 - val_mae: 4.0873\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.1009 - mae: 4.0355 - val_loss: 26.6144 - val_mae: 4.0945\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.9780 - mae: 4.1056 - val_loss: 26.3959 - val_mae: 4.0591\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.8097 - mae: 4.1249 - val_loss: 26.4250 - val_mae: 4.0245\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.7367 - mae: 4.1117 - val_loss: 26.3147 - val_mae: 4.0538\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.8439 - mae: 4.1777 - val_loss: 26.0613 - val_mae: 4.0429\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37.1838 - mae: 4.0675 - val_loss: 26.4032 - val_mae: 4.0946\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.5869 - mae: 4.0269 - val_loss: 26.0573 - val_mae: 4.0536\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.2558 - mae: 4.0468 - val_loss: 25.5767 - val_mae: 4.0423\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.1705 - mae: 4.1128 - val_loss: 25.9918 - val_mae: 4.0517\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36.9007 - mae: 3.9320 - val_loss: 25.5483 - val_mae: 4.0372\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36.6483 - mae: 4.0091 - val_loss: 25.2977 - val_mae: 4.0279\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36.7089 - mae: 4.0744 - val_loss: 25.1943 - val_mae: 3.9986\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 65.7461 - mae: 5.2981\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=125, optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: inf - mae: 683391970055894859776.0000 - val_loss: inf - val_mae: 5951094305786649288638464.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=0, n_neurons=5, optimizer=momentum; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: inf - mae: 162509296328920530944.0000 - val_loss: inf - val_mae: 1338846814586517850161152.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=0, n_neurons=5, optimizer=momentum; total time=   0.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: inf - mae: 438899849797763596288.0000 - val_loss: inf - val_mae: 3292926843446011300413440.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=0, n_neurons=5, optimizer=momentum; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 4152.9517 - mae: 39.5793 - val_loss: 32.0470 - val_mae: 4.7361\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1485 - mae: 6.0850 - val_loss: 20.0016 - val_mae: 3.6436\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8683 - mae: 5.9787 - val_loss: 18.5591 - val_mae: 3.4732\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3070 - mae: 5.9344 - val_loss: 27.6109 - val_mae: 4.6298\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4331 - mae: 5.8963 - val_loss: 18.8338 - val_mae: 3.5651\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.2372 - mae: 5.8520 - val_loss: 18.3958 - val_mae: 3.3052\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.4575 - mae: 5.8106 - val_loss: 19.3684 - val_mae: 3.5899\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3977 - mae: 5.8682 - val_loss: 33.1575 - val_mae: 5.1317\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.2558 - mae: 5.7271 - val_loss: 44.0228 - val_mae: 5.9450\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.5760 - mae: 5.9213 - val_loss: 22.8349 - val_mae: 4.1234\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.3536 - mae: 5.7904 - val_loss: 20.1381 - val_mae: 3.7539\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.0767 - mae: 5.7983 - val_loss: 19.5515 - val_mae: 3.6427\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.9678 - mae: 5.7084 - val_loss: 40.8445 - val_mae: 5.6956\n",
      "Epoch 13: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 76.7936 - mae: 7.2322\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=125, optimizer=sgd; total time=   0.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 4873.4614 - mae: 45.7558 - val_loss: 57.6180 - val_mae: 6.5175\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.5943 - mae: 7.8199 - val_loss: 31.3427 - val_mae: 4.7685\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.7729 - mae: 7.1024 - val_loss: 32.5545 - val_mae: 4.5710\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.0570 - mae: 6.8866 - val_loss: 28.0380 - val_mae: 4.4242\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.8566 - mae: 6.7654 - val_loss: 21.7350 - val_mae: 3.8637\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0831 - mae: 6.6751 - val_loss: 18.3843 - val_mae: 3.4505\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.7454 - mae: 6.4910 - val_loss: 21.9199 - val_mae: 3.9473\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.9470 - mae: 6.5452 - val_loss: 27.2614 - val_mae: 4.4715\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.0773 - mae: 6.3974 - val_loss: 31.7029 - val_mae: 4.8225\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7831 - mae: 6.5066 - val_loss: 29.7011 - val_mae: 4.6960\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.9245 - mae: 6.5732 - val_loss: 19.7415 - val_mae: 3.6873\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.9316 - mae: 6.3654 - val_loss: 28.8370 - val_mae: 4.6358\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5075 - mae: 6.4223 - val_loss: 27.6773 - val_mae: 4.5556\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.0531 - mae: 6.5947 - val_loss: 21.4278 - val_mae: 3.8942\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.8633 - mae: 6.3134 - val_loss: 22.9526 - val_mae: 4.0781\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.8482 - mae: 6.3198 - val_loss: 20.6607 - val_mae: 3.8133\n",
      "Epoch 16: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 44.0627 - mae: 5.0307\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=125, optimizer=sgd; total time=   1.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 6522.7505 - mae: 46.9016 - val_loss: 94.1949 - val_mae: 7.4911\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6707 - mae: 6.2247 - val_loss: 50.4150 - val_mae: 5.1440\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.8350 - mae: 5.7060 - val_loss: 44.8122 - val_mae: 5.1183\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.8169 - mae: 5.2103 - val_loss: 41.2741 - val_mae: 5.0706\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.9026 - mae: 5.1801 - val_loss: 43.9496 - val_mae: 5.0927\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.6098 - mae: 5.2403 - val_loss: 39.8537 - val_mae: 4.9056\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.7991 - mae: 5.4274 - val_loss: 53.1366 - val_mae: 5.6699\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.4608 - mae: 5.4837 - val_loss: 39.2593 - val_mae: 4.8589\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.5075 - mae: 5.0849 - val_loss: 38.3795 - val_mae: 4.7524\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.4950 - mae: 5.0971 - val_loss: 37.6603 - val_mae: 4.8586\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.2159 - mae: 5.0541 - val_loss: 39.5896 - val_mae: 4.9099\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.5396 - mae: 5.2168 - val_loss: 59.6338 - val_mae: 6.2455\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.6454 - mae: 5.5217 - val_loss: 38.5882 - val_mae: 4.6716\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.4553 - mae: 5.1585 - val_loss: 37.6789 - val_mae: 4.7034\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.9018 - mae: 5.0821 - val_loss: 37.2865 - val_mae: 4.6614\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.1041 - mae: 4.9803 - val_loss: 41.2591 - val_mae: 4.8252\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.2532 - mae: 5.2270 - val_loss: 37.7217 - val_mae: 4.7563\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.4931 - mae: 5.0768 - val_loss: 36.3112 - val_mae: 4.6253\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.4383 - mae: 5.0897 - val_loss: 40.6523 - val_mae: 4.9055\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.9068 - mae: 4.9165 - val_loss: 37.2790 - val_mae: 4.7142\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.9249 - mae: 5.2089 - val_loss: 37.6907 - val_mae: 4.7426\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.0503 - mae: 4.9144 - val_loss: 36.2024 - val_mae: 4.5404\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.4829 - mae: 5.0743 - val_loss: 44.3751 - val_mae: 5.1677\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.3799 - mae: 4.9441 - val_loss: 48.6603 - val_mae: 5.3446\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.1542 - mae: 5.2759 - val_loss: 36.6549 - val_mae: 4.6726\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.3198 - mae: 4.9054 - val_loss: 45.2052 - val_mae: 5.1181\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.7796 - mae: 5.1585 - val_loss: 35.7121 - val_mae: 4.5840\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.0004 - mae: 5.1712 - val_loss: 35.2479 - val_mae: 4.5339\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.8303 - mae: 4.9134 - val_loss: 36.3258 - val_mae: 4.6531\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.4352 - mae: 4.8851 - val_loss: 40.6772 - val_mae: 4.7696\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.8143 - mae: 4.9101 - val_loss: 35.2235 - val_mae: 4.5738\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.2698 - mae: 4.9283 - val_loss: 41.2835 - val_mae: 4.8577\n",
      "Epoch 32: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 79.4810 - mae: 6.7227\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=125, optimizer=sgd; total time=   1.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 43ms/step - loss: 13856.9502 - mae: 114.9156 - val_loss: 12068.3164 - val_mae: 106.2812\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13670.8906 - mae: 114.1070 - val_loss: 11901.5332 - val_mae: 105.4967\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13486.2539 - mae: 113.2968 - val_loss: 11738.0488 - val_mae: 104.7216\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13305.0215 - mae: 112.4989 - val_loss: 11576.9707 - val_mae: 103.9518\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13127.6641 - mae: 111.7113 - val_loss: 11417.6064 - val_mae: 103.1842\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12951.4570 - mae: 110.9231 - val_loss: 11261.2070 - val_mae: 102.4252\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12778.7207 - mae: 110.1455 - val_loss: 11107.2100 - val_mae: 101.6716\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12607.5498 - mae: 109.3757 - val_loss: 10956.4111 - val_mae: 100.9277\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12441.6191 - mae: 108.6115 - val_loss: 10807.0430 - val_mae: 100.1847\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12277.2324 - mae: 107.8549 - val_loss: 10660.1162 - val_mae: 99.4484\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12115.3555 - mae: 107.1095 - val_loss: 10515.9326 - val_mae: 98.7195\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11956.1465 - mae: 106.3677 - val_loss: 10374.2666 - val_mae: 97.9987\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11799.9873 - mae: 105.6343 - val_loss: 10234.3926 - val_mae: 97.2816\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11645.4824 - mae: 104.9074 - val_loss: 10096.4199 - val_mae: 96.5671\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11493.0146 - mae: 104.1799 - val_loss: 9960.3447 - val_mae: 95.8580\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11343.5576 - mae: 103.4595 - val_loss: 9825.1240 - val_mae: 95.1477\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11194.8887 - mae: 102.7486 - val_loss: 9693.0928 - val_mae: 94.4477\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11049.8262 - mae: 102.0426 - val_loss: 9562.8682 - val_mae: 93.7518\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10905.5391 - mae: 101.3357 - val_loss: 9435.1787 - val_mae: 93.0652\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10763.6318 - mae: 100.6364 - val_loss: 9308.7607 - val_mae: 92.3800\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10623.4004 - mae: 99.9378 - val_loss: 9181.4990 - val_mae: 91.6841\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10484.2529 - mae: 99.2423 - val_loss: 9055.5801 - val_mae: 90.9895\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10346.6904 - mae: 98.5507 - val_loss: 8931.7803 - val_mae: 90.3005\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10211.2256 - mae: 97.8606 - val_loss: 8809.7461 - val_mae: 89.6167\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10077.4473 - mae: 97.1759 - val_loss: 8689.1836 - val_mae: 88.9349\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9945.1045 - mae: 96.4931 - val_loss: 8569.6504 - val_mae: 88.2540\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9814.1621 - mae: 95.8164 - val_loss: 8450.9648 - val_mae: 87.5721\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9685.1777 - mae: 95.1421 - val_loss: 8333.8320 - val_mae: 86.8941\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9558.6777 - mae: 94.4739 - val_loss: 8216.5488 - val_mae: 86.2083\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9431.5371 - mae: 93.7992 - val_loss: 8101.7720 - val_mae: 85.5327\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9306.9424 - mae: 93.1380 - val_loss: 7988.4238 - val_mae: 84.8589\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9184.3701 - mae: 92.4769 - val_loss: 7875.9839 - val_mae: 84.1845\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9062.5928 - mae: 91.8209 - val_loss: 7765.0449 - val_mae: 83.5123\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8941.1592 - mae: 91.1581 - val_loss: 7656.7456 - val_mae: 82.8520\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8822.8516 - mae: 90.5077 - val_loss: 7549.7852 - val_mae: 82.1944\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8707.2451 - mae: 89.8595 - val_loss: 7443.6499 - val_mae: 81.5362\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8592.0615 - mae: 89.2225 - val_loss: 7338.5591 - val_mae: 80.8756\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8476.3018 - mae: 88.5786 - val_loss: 7236.5386 - val_mae: 80.2299\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8365.4854 - mae: 87.9544 - val_loss: 7135.0776 - val_mae: 79.5817\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8253.1963 - mae: 87.3218 - val_loss: 7035.8213 - val_mae: 78.9426\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8144.6450 - mae: 86.6899 - val_loss: 6936.9272 - val_mae: 78.3006\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8035.3398 - mae: 86.0629 - val_loss: 6840.2212 - val_mae: 77.6664\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7928.9131 - mae: 85.4459 - val_loss: 6744.6460 - val_mae: 77.0774\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7822.8662 - mae: 84.8379 - val_loss: 6650.5400 - val_mae: 76.4951\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7718.6460 - mae: 84.2206 - val_loss: 6557.3628 - val_mae: 75.9084\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7615.2681 - mae: 83.6236 - val_loss: 6465.1782 - val_mae: 75.3201\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7513.4663 - mae: 83.0283 - val_loss: 6374.0903 - val_mae: 74.7332\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7410.9443 - mae: 82.4289 - val_loss: 6284.9971 - val_mae: 74.1543\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7310.3574 - mae: 81.8346 - val_loss: 6196.2324 - val_mae: 73.5722\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7209.6260 - mae: 81.2309 - val_loss: 6107.7534 - val_mae: 73.0053\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7109.8862 - mae: 80.6342 - val_loss: 6019.7100 - val_mae: 72.4691\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7012.4458 - mae: 80.0394 - val_loss: 5931.8335 - val_mae: 71.9289\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6913.7642 - mae: 79.4429 - val_loss: 5845.2544 - val_mae: 71.3919\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6815.9697 - mae: 78.8459 - val_loss: 5758.8130 - val_mae: 70.8508\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6718.8755 - mae: 78.2494 - val_loss: 5673.4688 - val_mae: 70.3115\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6621.7334 - mae: 77.6423 - val_loss: 5588.6714 - val_mae: 69.7710\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6526.1694 - mae: 77.0443 - val_loss: 5503.3345 - val_mae: 69.2228\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6430.2261 - mae: 76.4370 - val_loss: 5419.1968 - val_mae: 68.6775\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6336.1709 - mae: 75.8306 - val_loss: 5334.3794 - val_mae: 68.1234\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6242.6426 - mae: 75.2420 - val_loss: 5249.4321 - val_mae: 67.5643\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6148.5190 - mae: 74.6354 - val_loss: 5166.4146 - val_mae: 67.0123\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6056.9692 - mae: 74.0438 - val_loss: 5084.4932 - val_mae: 66.4615\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5965.9697 - mae: 73.4528 - val_loss: 5003.7554 - val_mae: 65.9129\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5874.8149 - mae: 72.8605 - val_loss: 4923.9727 - val_mae: 65.3662\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5785.8652 - mae: 72.2888 - val_loss: 4844.5239 - val_mae: 64.8306\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5696.8101 - mae: 71.6897 - val_loss: 4767.1733 - val_mae: 64.3402\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5609.8501 - mae: 71.1130 - val_loss: 4690.4634 - val_mae: 63.8489\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5522.2124 - mae: 70.5207 - val_loss: 4615.9282 - val_mae: 63.3663\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5438.9038 - mae: 69.9592 - val_loss: 4540.9956 - val_mae: 62.8759\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5353.1626 - mae: 69.3651 - val_loss: 4468.3223 - val_mae: 62.3951\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5270.8677 - mae: 68.7904 - val_loss: 4396.8716 - val_mae: 61.9172\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5189.4771 - mae: 68.2193 - val_loss: 4326.9946 - val_mae: 61.4448\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5111.1318 - mae: 67.6643 - val_loss: 4257.5972 - val_mae: 60.9703\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5031.5552 - mae: 67.0922 - val_loss: 4190.1035 - val_mae: 60.5042\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4955.2363 - mae: 66.5487 - val_loss: 4122.5493 - val_mae: 60.0332\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4879.0059 - mae: 65.9873 - val_loss: 4056.4558 - val_mae: 59.5671\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4804.4253 - mae: 65.4364 - val_loss: 3991.9209 - val_mae: 59.1071\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4732.0737 - mae: 64.8991 - val_loss: 3927.8291 - val_mae: 58.6452\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4658.8989 - mae: 64.3479 - val_loss: 3865.2900 - val_mae: 58.1892\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4588.5146 - mae: 63.8117 - val_loss: 3803.2996 - val_mae: 57.7323\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4517.8750 - mae: 63.2691 - val_loss: 3743.0105 - val_mae: 57.2825\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4449.3892 - mae: 62.7384 - val_loss: 3684.3550 - val_mae: 56.8399\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4382.9375 - mae: 62.2206 - val_loss: 3626.1116 - val_mae: 56.3952\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4316.4941 - mae: 61.6931 - val_loss: 3569.0186 - val_mae: 55.9541\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4251.4526 - mae: 61.1745 - val_loss: 3512.9255 - val_mae: 55.5157\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4188.0083 - mae: 60.6582 - val_loss: 3457.7144 - val_mae: 55.0788\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4125.5688 - mae: 60.1394 - val_loss: 3403.2271 - val_mae: 54.6426\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4063.2998 - mae: 59.6404 - val_loss: 3350.3567 - val_mae: 54.2140\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4003.2310 - mae: 59.1386 - val_loss: 3298.0188 - val_mae: 53.7848\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3943.6602 - mae: 58.6408 - val_loss: 3246.7705 - val_mae: 53.3590\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3884.5056 - mae: 58.1453 - val_loss: 3196.5576 - val_mae: 52.9362\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3826.3999 - mae: 57.6426 - val_loss: 3147.2129 - val_mae: 52.5158\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3768.9998 - mae: 57.1509 - val_loss: 3098.6433 - val_mae: 52.0966\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3712.4917 - mae: 56.6662 - val_loss: 3051.0315 - val_mae: 51.6805\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3658.1990 - mae: 56.1909 - val_loss: 3003.5596 - val_mae: 51.2591\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3602.8904 - mae: 55.7045 - val_loss: 2957.4019 - val_mae: 50.8423\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3549.5122 - mae: 55.2368 - val_loss: 2912.3792 - val_mae: 50.4301\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3498.3064 - mae: 54.7746 - val_loss: 2867.4001 - val_mae: 50.0127\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3445.6443 - mae: 54.3044 - val_loss: 2824.0557 - val_mae: 49.6056\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3394.4668 - mae: 53.8507 - val_loss: 2781.4512 - val_mae: 49.2005\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3317.9460 - mae: 53.2965\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=5, optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 71286.8594 - mae: 263.1623 - val_loss: 70840.5078 - val_mae: 263.4847\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70486.6562 - mae: 261.6683 - val_loss: 70037.9922 - val_mae: 261.9816\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69694.7188 - mae: 260.1805 - val_loss: 69241.7812 - val_mae: 260.4818\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68910.3984 - mae: 258.6966 - val_loss: 68453.5859 - val_mae: 258.9886\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68126.9531 - mae: 257.2155 - val_loss: 67677.2109 - val_mae: 257.5095\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67357.2344 - mae: 255.7457 - val_loss: 66908.2344 - val_mae: 256.0361\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66593.1875 - mae: 254.2846 - val_loss: 66148.5312 - val_mae: 254.5742\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65837.4062 - mae: 252.8300 - val_loss: 65394.6445 - val_mae: 253.1156\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65085.9688 - mae: 251.3727 - val_loss: 64648.9414 - val_mae: 251.6647\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64347.2188 - mae: 249.9260 - val_loss: 63908.7305 - val_mae: 250.2166\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63612.2617 - mae: 248.4821 - val_loss: 63175.1016 - val_mae: 248.7723\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62881.4375 - mae: 247.0429 - val_loss: 62453.7969 - val_mae: 247.3444\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62161.1016 - mae: 245.6134 - val_loss: 61737.2227 - val_mae: 245.9177\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61453.1680 - mae: 244.1928 - val_loss: 61023.6992 - val_mae: 244.4886\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60744.4102 - mae: 242.7705 - val_loss: 60320.9219 - val_mae: 243.0732\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60043.5195 - mae: 241.3592 - val_loss: 59627.6250 - val_mae: 241.6690\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59356.8438 - mae: 239.9619 - val_loss: 58939.0977 - val_mae: 240.2666\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58677.7773 - mae: 238.5658 - val_loss: 58254.6797 - val_mae: 238.8646\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57995.1523 - mae: 237.1725 - val_loss: 57584.5547 - val_mae: 237.4836\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57325.8086 - mae: 235.7929 - val_loss: 56919.8242 - val_mae: 236.1058\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56666.6445 - mae: 234.4179 - val_loss: 56256.3203 - val_mae: 234.7226\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56010.6992 - mae: 233.0416 - val_loss: 55597.4648 - val_mae: 233.3413\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55355.6562 - mae: 231.6681 - val_loss: 54947.7227 - val_mae: 231.9709\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54710.0977 - mae: 230.3053 - val_loss: 54306.6953 - val_mae: 230.6105\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54078.6172 - mae: 228.9482 - val_loss: 53668.6016 - val_mae: 229.2489\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53445.0195 - mae: 227.5935 - val_loss: 53038.9102 - val_mae: 227.8967\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52815.8281 - mae: 226.2472 - val_loss: 52418.9688 - val_mae: 226.5578\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52202.3594 - mae: 224.9132 - val_loss: 51801.8516 - val_mae: 225.2166\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51592.7461 - mae: 223.5796 - val_loss: 51190.6289 - val_mae: 223.8810\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50988.9727 - mae: 222.2518 - val_loss: 50585.6797 - val_mae: 222.5509\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50383.9375 - mae: 220.9274 - val_loss: 49992.5547 - val_mae: 221.2389\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49794.6094 - mae: 219.6188 - val_loss: 49402.5078 - val_mae: 219.9262\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49210.8906 - mae: 218.3101 - val_loss: 48816.9336 - val_mae: 218.6159\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48626.6719 - mae: 217.0051 - val_loss: 48240.6172 - val_mae: 217.3181\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48055.4766 - mae: 215.7125 - val_loss: 47667.3320 - val_mae: 216.0192\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47483.9219 - mae: 214.4182 - val_loss: 47101.9492 - val_mae: 214.7314\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46923.1328 - mae: 213.1337 - val_loss: 46536.4727 - val_mae: 213.4356\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 46362.7148 - mae: 211.8412 - val_loss: 45979.1797 - val_mae: 212.1508\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45812.4062 - mae: 210.5615 - val_loss: 45426.4961 - val_mae: 210.8688\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45260.2578 - mae: 209.2837 - val_loss: 44882.5078 - val_mae: 209.5992\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44714.6289 - mae: 208.0121 - val_loss: 44345.3320 - val_mae: 208.3375\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44180.0156 - mae: 206.7481 - val_loss: 43810.2344 - val_mae: 207.0736\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43644.0977 - mae: 205.4829 - val_loss: 43281.0430 - val_mae: 205.8158\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43117.4883 - mae: 204.2182 - val_loss: 42753.2500 - val_mae: 204.5539\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42586.1016 - mae: 202.9421 - val_loss: 42232.1094 - val_mae: 203.2988\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42062.7695 - mae: 201.6729 - val_loss: 41712.4180 - val_mae: 202.0388\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41538.5078 - mae: 200.3908 - val_loss: 41191.7695 - val_mae: 200.7679\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 41011.5586 - mae: 199.0967 - val_loss: 40673.3477 - val_mae: 199.4930\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40492.7734 - mae: 197.8100 - val_loss: 40155.4180 - val_mae: 198.2100\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39970.7891 - mae: 196.5114 - val_loss: 39642.6094 - val_mae: 196.9312\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39454.4258 - mae: 195.2139 - val_loss: 39130.3789 - val_mae: 195.6445\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38941.1328 - mae: 193.9143 - val_loss: 38618.9492 - val_mae: 194.3515\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38425.5547 - mae: 192.5997 - val_loss: 38115.5469 - val_mae: 193.0717\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37916.1523 - mae: 191.2963 - val_loss: 37616.3438 - val_mae: 191.7939\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37414.3555 - mae: 189.9928 - val_loss: 37118.3086 - val_mae: 190.5087\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36914.1016 - mae: 188.6811 - val_loss: 36623.8398 - val_mae: 189.2242\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36414.1328 - mae: 187.3758 - val_loss: 36127.8281 - val_mae: 187.9270\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35918.0273 - mae: 186.0596 - val_loss: 35620.6289 - val_mae: 186.5944\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35410.6172 - mae: 184.7247 - val_loss: 35114.2266 - val_mae: 185.2548\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34907.3516 - mae: 183.3716 - val_loss: 34603.8555 - val_mae: 183.8960\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34394.8555 - mae: 182.0010 - val_loss: 34094.2031 - val_mae: 182.5300\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33889.9727 - mae: 180.6342 - val_loss: 33582.4219 - val_mae: 181.1480\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33384.8242 - mae: 179.2634 - val_loss: 33074.9570 - val_mae: 179.7670\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32884.7852 - mae: 177.8864 - val_loss: 32568.7363 - val_mae: 178.3764\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32391.1445 - mae: 176.5200 - val_loss: 32063.3379 - val_mae: 176.9752\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31898.6855 - mae: 175.1374 - val_loss: 31566.1113 - val_mae: 175.5856\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31408.7891 - mae: 173.7600 - val_loss: 31075.8574 - val_mae: 174.2044\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30930.2383 - mae: 172.3952 - val_loss: 30587.5508 - val_mae: 172.8177\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30450.0742 - mae: 171.0204 - val_loss: 30104.3008 - val_mae: 171.4342\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29973.4648 - mae: 169.6596 - val_loss: 29628.4922 - val_mae: 170.0606\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29504.8203 - mae: 168.2871 - val_loss: 29155.9238 - val_mae: 168.6852\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29035.5410 - mae: 166.9220 - val_loss: 28689.8008 - val_mae: 167.3172\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28572.9785 - mae: 165.5585 - val_loss: 28229.4629 - val_mae: 165.9550\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 28112.6309 - mae: 164.1964 - val_loss: 27771.0156 - val_mae: 164.5888\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27664.4023 - mae: 162.8348 - val_loss: 27308.9238 - val_mae: 163.2007\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27208.2871 - mae: 161.4668 - val_loss: 26857.2148 - val_mae: 161.8319\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 26764.8086 - mae: 160.1104 - val_loss: 26408.0332 - val_mae: 160.4593\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 26320.5234 - mae: 158.7412 - val_loss: 25962.8750 - val_mae: 159.0880\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25884.4297 - mae: 157.3840 - val_loss: 25519.8086 - val_mae: 157.7111\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25450.5352 - mae: 156.0266 - val_loss: 25083.1172 - val_mae: 156.3420\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25020.8320 - mae: 154.6700 - val_loss: 24654.3516 - val_mae: 154.9860\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24596.9609 - mae: 153.3307 - val_loss: 24232.8828 - val_mae: 153.6411\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24182.1191 - mae: 151.9921 - val_loss: 23814.5957 - val_mae: 152.2946\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23769.0762 - mae: 150.6589 - val_loss: 23403.9297 - val_mae: 150.9609\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23364.0684 - mae: 149.3383 - val_loss: 22996.9395 - val_mae: 149.6271\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22966.0312 - mae: 148.0129 - val_loss: 22594.3047 - val_mae: 148.2962\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22563.8340 - mae: 146.6914 - val_loss: 22200.6328 - val_mae: 146.9841\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22173.8809 - mae: 145.3744 - val_loss: 21809.1035 - val_mae: 145.6675\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21784.2715 - mae: 144.0643 - val_loss: 21424.5605 - val_mae: 144.3625\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21403.9707 - mae: 142.7582 - val_loss: 21042.0078 - val_mae: 143.0523\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21027.5977 - mae: 141.4544 - val_loss: 20662.4160 - val_mae: 141.7402\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20646.0352 - mae: 140.1421 - val_loss: 20294.4238 - val_mae: 140.4563\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20278.7969 - mae: 138.8572 - val_loss: 19929.5488 - val_mae: 139.1715\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19918.8848 - mae: 137.5703 - val_loss: 19564.8828 - val_mae: 137.8755\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19557.2441 - mae: 136.2771 - val_loss: 19208.5391 - val_mae: 136.5971\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19203.5977 - mae: 135.0004 - val_loss: 18858.2773 - val_mae: 135.3284\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18852.4922 - mae: 133.7273 - val_loss: 18513.4102 - val_mae: 134.0675\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18513.1152 - mae: 132.4639 - val_loss: 18168.1660 - val_mae: 132.7929\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18167.9883 - mae: 131.1933 - val_loss: 17831.2695 - val_mae: 131.5371\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17835.2285 - mae: 129.9366 - val_loss: 17497.5000 - val_mae: 130.2810\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16801.1914 - mae: 126.5394\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=5, optimizer=adam; total time=   4.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 14807.6738 - mae: 118.6394 - val_loss: 12942.7822 - val_mae: 109.6889\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14565.8594 - mae: 117.5821 - val_loss: 12669.7432 - val_mae: 108.4630\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14333.8652 - mae: 116.5600 - val_loss: 12397.7803 - val_mae: 107.2204\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14099.9229 - mae: 115.5019 - val_loss: 12132.7334 - val_mae: 105.9913\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13872.0576 - mae: 114.4766 - val_loss: 11872.7441 - val_mae: 104.7697\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13652.1934 - mae: 113.4451 - val_loss: 11619.4199 - val_mae: 103.5640\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13440.3545 - mae: 112.4539 - val_loss: 11369.5078 - val_mae: 102.3546\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13225.1221 - mae: 111.4298 - val_loss: 11131.2559 - val_mae: 101.1863\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13023.1035 - mae: 110.4590 - val_loss: 10894.1006 - val_mae: 100.0056\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12819.8047 - mae: 109.4741 - val_loss: 10667.5273 - val_mae: 98.8619\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12628.6328 - mae: 108.5243 - val_loss: 10439.4043 - val_mae: 97.6901\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12434.4404 - mae: 107.5515 - val_loss: 10223.2148 - val_mae: 96.5678\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12248.2256 - mae: 106.6233 - val_loss: 10012.4561 - val_mae: 95.4558\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12065.4736 - mae: 105.6831 - val_loss: 9807.4629 - val_mae: 94.3615\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11888.8613 - mae: 104.7570 - val_loss: 9603.9619 - val_mae: 93.2598\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11712.3232 - mae: 103.8403 - val_loss: 9405.3496 - val_mae: 92.1693\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11538.6191 - mae: 102.9151 - val_loss: 9213.5527 - val_mae: 91.1042\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11375.7588 - mae: 102.0441 - val_loss: 9018.6943 - val_mae: 89.9982\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11213.3584 - mae: 101.1513 - val_loss: 8832.2207 - val_mae: 88.9260\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11048.7510 - mae: 100.2597 - val_loss: 8662.7441 - val_mae: 87.9494\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10902.6348 - mae: 99.4556 - val_loss: 8481.7959 - val_mae: 86.8768\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10743.3008 - mae: 98.5791 - val_loss: 8316.9502 - val_mae: 85.8978\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10596.4199 - mae: 97.7660 - val_loss: 8153.1533 - val_mae: 84.9086\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10451.5684 - mae: 96.9403 - val_loss: 7989.2695 - val_mae: 83.8997\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10307.6582 - mae: 96.1062 - val_loss: 7831.1934 - val_mae: 82.9168\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10166.1953 - mae: 95.2826 - val_loss: 7675.9175 - val_mae: 81.9341\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10027.2539 - mae: 94.4785 - val_loss: 7528.4062 - val_mae: 80.9899\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9897.3066 - mae: 93.7207 - val_loss: 7380.0493 - val_mae: 80.0208\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9765.2959 - mae: 92.9072 - val_loss: 7234.9043 - val_mae: 79.0602\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9634.4219 - mae: 92.1250 - val_loss: 7097.3979 - val_mae: 78.1424\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9511.7783 - mae: 91.3821 - val_loss: 6960.2061 - val_mae: 77.2082\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9388.1885 - mae: 90.6489 - val_loss: 6828.9932 - val_mae: 76.3059\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9269.5879 - mae: 89.9081 - val_loss: 6702.6597 - val_mae: 75.4323\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9151.1406 - mae: 89.1899 - val_loss: 6582.6250 - val_mae: 74.6085\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9038.0527 - mae: 88.4838 - val_loss: 6461.6274 - val_mae: 73.8292\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8928.1729 - mae: 87.7675 - val_loss: 6339.5371 - val_mae: 73.0275\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8817.6348 - mae: 87.0534 - val_loss: 6225.9844 - val_mae: 72.2786\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8711.8584 - mae: 86.3709 - val_loss: 6113.4102 - val_mae: 71.5211\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8607.0117 - mae: 85.7018 - val_loss: 6005.2651 - val_mae: 70.7861\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8503.3398 - mae: 85.0232 - val_loss: 5902.6543 - val_mae: 70.0832\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8405.8066 - mae: 84.3816 - val_loss: 5801.1587 - val_mae: 69.3843\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8307.8105 - mae: 83.7351 - val_loss: 5701.3613 - val_mae: 68.6854\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8210.2051 - mae: 83.0961 - val_loss: 5606.7949 - val_mae: 68.0204\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8116.7515 - mae: 82.4653 - val_loss: 5512.2144 - val_mae: 67.3441\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8024.0107 - mae: 81.8480 - val_loss: 5419.1084 - val_mae: 66.6685\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7934.8643 - mae: 81.2177 - val_loss: 5326.5044 - val_mae: 65.9877\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7844.3726 - mae: 80.6081 - val_loss: 5241.2964 - val_mae: 65.3660\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7757.4312 - mae: 80.0204 - val_loss: 5156.1494 - val_mae: 64.7308\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7672.3481 - mae: 79.4340 - val_loss: 5070.1519 - val_mae: 64.0724\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7590.1323 - mae: 78.8298 - val_loss: 4988.5586 - val_mae: 63.4555\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7507.3765 - mae: 78.2709 - val_loss: 4909.6987 - val_mae: 62.8532\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7426.6782 - mae: 77.7014 - val_loss: 4833.1694 - val_mae: 62.2632\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7347.2407 - mae: 77.1643 - val_loss: 4757.4531 - val_mae: 61.6691\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7269.4058 - mae: 76.6226 - val_loss: 4686.1777 - val_mae: 61.1184\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7193.2427 - mae: 76.1001 - val_loss: 4616.6143 - val_mae: 60.5790\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7117.4668 - mae: 75.5884 - val_loss: 4548.5879 - val_mae: 60.0474\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7043.2563 - mae: 75.0617 - val_loss: 4478.5112 - val_mae: 59.4803\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6969.3457 - mae: 74.5377 - val_loss: 4409.5024 - val_mae: 58.9169\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6897.2427 - mae: 74.0184 - val_loss: 4342.4561 - val_mae: 58.3936\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6825.6362 - mae: 73.5128 - val_loss: 4276.6021 - val_mae: 57.8966\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6754.3535 - mae: 73.0222 - val_loss: 4214.9946 - val_mae: 57.4339\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6686.6499 - mae: 72.5339 - val_loss: 4149.1401 - val_mae: 56.9214\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6617.7524 - mae: 72.0253 - val_loss: 4088.1765 - val_mae: 56.4519\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6549.4609 - mae: 71.5448 - val_loss: 4030.5425 - val_mae: 56.0071\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6485.2734 - mae: 71.0885 - val_loss: 3973.8870 - val_mae: 55.5711\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6419.6284 - mae: 70.6278 - val_loss: 3918.0850 - val_mae: 55.1370\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6354.7930 - mae: 70.1730 - val_loss: 3861.4954 - val_mae: 54.6885\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6290.2334 - mae: 69.7122 - val_loss: 3808.3284 - val_mae: 54.2737\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6227.4312 - mae: 69.2632 - val_loss: 3754.4949 - val_mae: 53.8569\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6163.7275 - mae: 68.8115 - val_loss: 3702.6292 - val_mae: 53.4955\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6102.0083 - mae: 68.3709 - val_loss: 3651.4163 - val_mae: 53.1412\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6040.8960 - mae: 67.9369 - val_loss: 3600.0410 - val_mae: 52.7815\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5979.6333 - mae: 67.4970 - val_loss: 3548.8735 - val_mae: 52.4190\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5920.3203 - mae: 67.0670 - val_loss: 3500.1768 - val_mae: 52.0673\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5860.5493 - mae: 66.6492 - val_loss: 3452.6536 - val_mae: 51.7196\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5802.8130 - mae: 66.2336 - val_loss: 3401.7668 - val_mae: 51.3477\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5745.1699 - mae: 65.8058 - val_loss: 3354.2803 - val_mae: 50.9945\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5688.0229 - mae: 65.3987 - val_loss: 3307.6252 - val_mae: 50.6443\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5631.9658 - mae: 64.9934 - val_loss: 3261.2822 - val_mae: 50.2938\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5575.8560 - mae: 64.5899 - val_loss: 3217.7847 - val_mae: 49.9608\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5521.2534 - mae: 64.2008 - val_loss: 3175.0957 - val_mae: 49.6313\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5467.9434 - mae: 63.8144 - val_loss: 3128.5232 - val_mae: 49.2688\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5414.4048 - mae: 63.4127 - val_loss: 3084.0532 - val_mae: 48.9181\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5361.6812 - mae: 63.0264 - val_loss: 3040.5059 - val_mae: 48.5713\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5309.9795 - mae: 62.6446 - val_loss: 2996.1001 - val_mae: 48.2156\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5258.3003 - mae: 62.2687 - val_loss: 2953.8525 - val_mae: 47.8731\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5207.1714 - mae: 61.8983 - val_loss: 2911.7207 - val_mae: 47.5290\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5157.5454 - mae: 61.5335 - val_loss: 2871.3374 - val_mae: 47.1954\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5108.3779 - mae: 61.1753 - val_loss: 2832.2407 - val_mae: 46.8693\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5058.7812 - mae: 60.8126 - val_loss: 2793.8049 - val_mae: 46.5460\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5011.3149 - mae: 60.4641 - val_loss: 2757.9419 - val_mae: 46.2414\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4962.7183 - mae: 60.1079 - val_loss: 2721.1265 - val_mae: 45.9270\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4915.6821 - mae: 59.7533 - val_loss: 2683.3135 - val_mae: 45.6016\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4869.9209 - mae: 59.4118 - val_loss: 2645.1897 - val_mae: 45.2705\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4822.8857 - mae: 59.0518 - val_loss: 2609.7068 - val_mae: 44.9598\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4778.8345 - mae: 58.7097 - val_loss: 2572.7974 - val_mae: 44.6336\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4733.5464 - mae: 58.3631 - val_loss: 2540.8162 - val_mae: 44.3488\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4689.2041 - mae: 58.0301 - val_loss: 2505.8379 - val_mae: 44.0348\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4645.0591 - mae: 57.6792 - val_loss: 2471.6030 - val_mae: 43.7247\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4602.2690 - mae: 57.3474 - val_loss: 2437.0347 - val_mae: 43.4088\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3913.8350 - mae: 54.8414\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=5, optimizer=adam; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1367.9415 - mae: 34.4932 - val_loss: 586.5599 - val_mae: 23.6350\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 704.2239 - mae: 25.0088 - val_loss: 504.2605 - val_mae: 21.7314\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.4026 - mae: 23.7464 - val_loss: 474.8289 - val_mae: 20.9908\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 615.6658 - mae: 23.1260 - val_loss: 455.5047 - val_mae: 20.4867\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 594.2338 - mae: 22.6516 - val_loss: 437.9061 - val_mae: 20.0204\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.0821 - mae: 22.1294 - val_loss: 414.2650 - val_mae: 19.3915\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 534.2076 - mae: 21.2921 - val_loss: 369.9425 - val_mae: 18.1781\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.1330 - mae: 19.5421 - val_loss: 276.7914 - val_mae: 15.3508\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.2392 - mae: 15.1914 - val_loss: 103.7799 - val_mae: 8.8083\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.6348 - mae: 8.0098 - val_loss: 38.4277 - val_mae: 4.9698\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.4608 - mae: 6.3971 - val_loss: 37.5934 - val_mae: 4.7761\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.5561 - mae: 6.5024 - val_loss: 36.2673 - val_mae: 4.7144\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.9417 - mae: 6.4917 - val_loss: 37.9599 - val_mae: 4.8987\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.3792 - mae: 6.6599 - val_loss: 33.6753 - val_mae: 4.5670\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.8337 - mae: 6.4899 - val_loss: 33.1736 - val_mae: 4.5451\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.9291 - mae: 6.5095 - val_loss: 31.3892 - val_mae: 4.3850\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.4243 - mae: 6.3640 - val_loss: 32.9793 - val_mae: 4.5423\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.3135 - mae: 6.4510 - val_loss: 31.6461 - val_mae: 4.4443\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.7649 - mae: 6.3621 - val_loss: 33.3322 - val_mae: 4.6292\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.0761 - mae: 6.4463 - val_loss: 33.5715 - val_mae: 4.6631\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.5576 - mae: 6.4708 - val_loss: 31.9452 - val_mae: 4.5085\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.7260 - mae: 6.4711 - val_loss: 29.8605 - val_mae: 4.3031\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.2467 - mae: 6.3468 - val_loss: 31.1151 - val_mae: 4.4381\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.1023 - mae: 6.3826 - val_loss: 31.9339 - val_mae: 4.5420\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 77.2255 - mae: 6.5153 - val_loss: 29.2003 - val_mae: 4.2454\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.7330 - mae: 6.3572 - val_loss: 30.5680 - val_mae: 4.3815\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.2915 - mae: 6.4189 - val_loss: 29.6756 - val_mae: 4.2815\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.1094 - mae: 6.3904 - val_loss: 29.1139 - val_mae: 4.2353\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.9321 - mae: 6.3659 - val_loss: 30.2150 - val_mae: 4.3514\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.4908 - mae: 6.4526 - val_loss: 27.8913 - val_mae: 4.1082\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.6149 - mae: 6.3430 - val_loss: 27.6591 - val_mae: 4.0825\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.5241 - mae: 6.2436 - val_loss: 31.0160 - val_mae: 4.4631\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.2373 - mae: 6.3654 - val_loss: 29.1846 - val_mae: 4.2462\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.3627 - mae: 6.1370 - val_loss: 32.5278 - val_mae: 4.6328\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.0401 - mae: 6.4312 - val_loss: 30.5059 - val_mae: 4.4312\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.8841 - mae: 6.3410 - val_loss: 28.1279 - val_mae: 4.1688\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.8117 - mae: 6.2417 - val_loss: 28.8428 - val_mae: 4.2322\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.6248 - mae: 6.3132 - val_loss: 27.5214 - val_mae: 4.0777\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.2772 - mae: 6.2280 - val_loss: 29.1781 - val_mae: 4.2830\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.2483 - mae: 6.1864 - val_loss: 31.8127 - val_mae: 4.5713\n",
      "Epoch 40: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 84.8509 - mae: 7.0562\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   2.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 370.7465 - mae: 12.9329 - val_loss: 137.8002 - val_mae: 7.1607\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 163.4388 - mae: 9.1115 - val_loss: 80.1428 - val_mae: 6.1808\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129.4207 - mae: 8.4204 - val_loss: 69.5041 - val_mae: 6.9276\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.9882 - mae: 7.9059 - val_loss: 66.4090 - val_mae: 7.1808\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.5812 - mae: 7.7591 - val_loss: 41.6141 - val_mae: 5.3655\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9523 - mae: 7.3313 - val_loss: 37.4556 - val_mae: 5.1156\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3013 - mae: 7.1187 - val_loss: 40.1878 - val_mae: 5.2836\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.1831 - mae: 7.0808 - val_loss: 52.2040 - val_mae: 6.0698\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.6650 - mae: 6.6834 - val_loss: 90.0723 - val_mae: 8.1035\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.3962 - mae: 6.8226 - val_loss: 41.7003 - val_mae: 5.4613\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.7021 - mae: 7.0665 - val_loss: 35.4403 - val_mae: 4.9072\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.2290 - mae: 6.8512 - val_loss: 33.6668 - val_mae: 4.8458\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.4194 - mae: 6.7421 - val_loss: 31.6917 - val_mae: 4.6869\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 88.4525 - mae: 7.0396 - val_loss: 31.0227 - val_mae: 4.5778\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.5619 - mae: 6.6054 - val_loss: 31.2414 - val_mae: 4.5932\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 81.0875 - mae: 6.6147 - val_loss: 33.6122 - val_mae: 4.6711\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.3242 - mae: 6.4666 - val_loss: 60.5314 - val_mae: 6.5609\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.0600 - mae: 6.8917 - val_loss: 37.4645 - val_mae: 4.9542\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.1631 - mae: 6.4980 - val_loss: 45.6407 - val_mae: 5.6022\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9592 - mae: 6.6383 - val_loss: 50.7754 - val_mae: 5.9357\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.1866 - mae: 6.7161 - val_loss: 36.3527 - val_mae: 4.8720\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.5302 - mae: 6.5319 - val_loss: 34.0941 - val_mae: 4.7575\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.2130 - mae: 6.5288 - val_loss: 40.6563 - val_mae: 5.2590\n",
      "Epoch 23: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 54.7647 - mae: 5.7795\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   1.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 566.8768 - mae: 22.0721 - val_loss: 553.0020 - val_mae: 21.8824\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 563.1856 - mae: 22.0050 - val_loss: 549.6710 - val_mae: 21.8446\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.8733 - mae: 21.9652 - val_loss: 548.1863 - val_mae: 21.8264\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 559.5349 - mae: 21.9410 - val_loss: 548.0333 - val_mae: 21.8229\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 558.8878 - mae: 21.9285 - val_loss: 547.8807 - val_mae: 21.8194\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 558.2982 - mae: 21.9171 - val_loss: 547.7282 - val_mae: 21.8159\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.7481 - mae: 21.9054 - val_loss: 547.5746 - val_mae: 21.8124\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2229 - mae: 21.8946 - val_loss: 547.4219 - val_mae: 21.8089\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.6465 - mae: 21.8819 - val_loss: 547.2698 - val_mae: 21.8054\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.1949 - mae: 21.8724 - val_loss: 547.1169 - val_mae: 21.8019\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.9771 - mae: 21.8671 - val_loss: 546.9645 - val_mae: 21.7984\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7710 - mae: 21.8622 - val_loss: 546.8132 - val_mae: 21.7950\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5719 - mae: 21.8575 - val_loss: 546.6609 - val_mae: 21.7915\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 555.3687 - mae: 21.8526 - val_loss: 546.5086 - val_mae: 21.7880\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.1677 - mae: 21.8478 - val_loss: 546.3568 - val_mae: 21.7845\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.0089 - mae: 21.8442 - val_loss: 546.2036 - val_mae: 21.7810\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.8489 - mae: 21.8404 - val_loss: 546.0519 - val_mae: 21.7775\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.6904 - mae: 21.8368 - val_loss: 545.9001 - val_mae: 21.7740\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.5318 - mae: 21.8332 - val_loss: 545.7489 - val_mae: 21.7705\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3694 - mae: 21.8295 - val_loss: 545.5969 - val_mae: 21.7670\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.2108 - mae: 21.8258 - val_loss: 545.4456 - val_mae: 21.7636\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.0485 - mae: 21.8221 - val_loss: 545.2939 - val_mae: 21.7601\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.8901 - mae: 21.8184 - val_loss: 545.1417 - val_mae: 21.7566\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.7313 - mae: 21.8147 - val_loss: 544.9888 - val_mae: 21.7531\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.5720 - mae: 21.8111 - val_loss: 544.8365 - val_mae: 21.7496\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.4131 - mae: 21.8074 - val_loss: 544.6844 - val_mae: 21.7461\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.2545 - mae: 21.8037 - val_loss: 544.5328 - val_mae: 21.7426\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.0963 - mae: 21.8001 - val_loss: 544.3804 - val_mae: 21.7391\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.9375 - mae: 21.7964 - val_loss: 544.2289 - val_mae: 21.7356\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.7797 - mae: 21.7928 - val_loss: 544.0769 - val_mae: 21.7321\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.6212 - mae: 21.7891 - val_loss: 543.9249 - val_mae: 21.7286\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4679 - mae: 21.7856 - val_loss: 543.7728 - val_mae: 21.7251\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.3156 - mae: 21.7821 - val_loss: 543.6224 - val_mae: 21.7216\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.1647 - mae: 21.7786 - val_loss: 543.4711 - val_mae: 21.7182\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.0129 - mae: 21.7752 - val_loss: 543.3193 - val_mae: 21.7147\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.8609 - mae: 21.7716 - val_loss: 543.1695 - val_mae: 21.7112\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.7108 - mae: 21.7681 - val_loss: 543.0195 - val_mae: 21.7078\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.5603 - mae: 21.7647 - val_loss: 542.8694 - val_mae: 21.7043\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.4098 - mae: 21.7613 - val_loss: 542.7183 - val_mae: 21.7008\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.2584 - mae: 21.7578 - val_loss: 542.5674 - val_mae: 21.6973\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.1072 - mae: 21.7543 - val_loss: 542.4171 - val_mae: 21.6939\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.9561 - mae: 21.7509 - val_loss: 542.2639 - val_mae: 21.6903\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 550.8028 - mae: 21.7474 - val_loss: 542.1132 - val_mae: 21.6869\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.6516 - mae: 21.7439 - val_loss: 541.9628 - val_mae: 21.6834\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5007 - mae: 21.7404 - val_loss: 541.8112 - val_mae: 21.6799\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.3488 - mae: 21.7369 - val_loss: 541.6608 - val_mae: 21.6764\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.1982 - mae: 21.7334 - val_loss: 541.5110 - val_mae: 21.6730\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.0480 - mae: 21.7300 - val_loss: 541.3608 - val_mae: 21.6695\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.8972 - mae: 21.7265 - val_loss: 541.2101 - val_mae: 21.6660\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.7463 - mae: 21.7230 - val_loss: 541.0596 - val_mae: 21.6626\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.5954 - mae: 21.7195 - val_loss: 540.9098 - val_mae: 21.6591\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.4452 - mae: 21.7161 - val_loss: 540.7593 - val_mae: 21.6556\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.2943 - mae: 21.7127 - val_loss: 540.6083 - val_mae: 21.6522\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.1429 - mae: 21.7091 - val_loss: 540.4575 - val_mae: 21.6487\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.9918 - mae: 21.7057 - val_loss: 540.3074 - val_mae: 21.6452\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.8413 - mae: 21.7022 - val_loss: 540.1577 - val_mae: 21.6417\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.6910 - mae: 21.6988 - val_loss: 540.0069 - val_mae: 21.6383\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.5399 - mae: 21.6953 - val_loss: 539.8563 - val_mae: 21.6348\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.3890 - mae: 21.6918 - val_loss: 539.7051 - val_mae: 21.6313\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2375 - mae: 21.6883 - val_loss: 539.5559 - val_mae: 21.6278\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.0877 - mae: 21.6849 - val_loss: 539.4048 - val_mae: 21.6243\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.9363 - mae: 21.6813 - val_loss: 539.2549 - val_mae: 21.6209\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.7860 - mae: 21.6779 - val_loss: 539.1057 - val_mae: 21.6174\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.6365 - mae: 21.6745 - val_loss: 538.9558 - val_mae: 21.6140\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.4863 - mae: 21.6709 - val_loss: 538.8067 - val_mae: 21.6105\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.3367 - mae: 21.6675 - val_loss: 538.6559 - val_mae: 21.6070\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.1854 - mae: 21.6640 - val_loss: 538.5059 - val_mae: 21.6035\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.0352 - mae: 21.6605 - val_loss: 538.3572 - val_mae: 21.6001\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.8859 - mae: 21.6571 - val_loss: 538.2060 - val_mae: 21.5966\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7345 - mae: 21.6536 - val_loss: 538.0572 - val_mae: 21.5932\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.5853 - mae: 21.6502 - val_loss: 537.9075 - val_mae: 21.5897\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.4351 - mae: 21.6467 - val_loss: 537.7582 - val_mae: 21.5862\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.2855 - mae: 21.6433 - val_loss: 537.6093 - val_mae: 21.5828\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.1361 - mae: 21.6398 - val_loss: 537.4599 - val_mae: 21.5793\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 545.9865 - mae: 21.6363 - val_loss: 537.3106 - val_mae: 21.5759\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.8367 - mae: 21.6329 - val_loss: 537.1610 - val_mae: 21.5724\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.6867 - mae: 21.6294 - val_loss: 537.0118 - val_mae: 21.5689\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.5371 - mae: 21.6259 - val_loss: 536.8617 - val_mae: 21.5655\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.3868 - mae: 21.6224 - val_loss: 536.7142 - val_mae: 21.5620\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.2388 - mae: 21.6190 - val_loss: 536.5659 - val_mae: 21.5586\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.0899 - mae: 21.6156 - val_loss: 536.4150 - val_mae: 21.5551\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.9387 - mae: 21.6121 - val_loss: 536.2652 - val_mae: 21.5516\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.7885 - mae: 21.6086 - val_loss: 536.1147 - val_mae: 21.5481\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.6377 - mae: 21.6052 - val_loss: 535.9655 - val_mae: 21.5447\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.4882 - mae: 21.6016 - val_loss: 535.8173 - val_mae: 21.5412\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.3397 - mae: 21.5982 - val_loss: 535.6687 - val_mae: 21.5378\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.1907 - mae: 21.5948 - val_loss: 535.5206 - val_mae: 21.5343\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.0421 - mae: 21.5913 - val_loss: 535.3721 - val_mae: 21.5309\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.8932 - mae: 21.5879 - val_loss: 535.2236 - val_mae: 21.5274\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.7444 - mae: 21.5845 - val_loss: 535.0756 - val_mae: 21.5240\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.5959 - mae: 21.5810 - val_loss: 534.9262 - val_mae: 21.5205\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.4460 - mae: 21.5776 - val_loss: 534.7758 - val_mae: 21.5170\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.2954 - mae: 21.5740 - val_loss: 534.6273 - val_mae: 21.5136\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.1465 - mae: 21.5705 - val_loss: 534.4796 - val_mae: 21.5102\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.9984 - mae: 21.5672 - val_loss: 534.3303 - val_mae: 21.5067\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.8488 - mae: 21.5637 - val_loss: 534.1830 - val_mae: 21.5033\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.7010 - mae: 21.5603 - val_loss: 534.0345 - val_mae: 21.4998\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.5521 - mae: 21.5568 - val_loss: 533.8859 - val_mae: 21.4964\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.4031 - mae: 21.5533 - val_loss: 533.7374 - val_mae: 21.4929\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.2543 - mae: 21.5498 - val_loss: 533.5898 - val_mae: 21.4895\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 629.9594 - mae: 23.0659\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   4.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 890.9608 - mae: 24.9847 - val_loss: 304.2584 - val_mae: 12.6714\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.5053 - mae: 11.1896 - val_loss: 205.9011 - val_mae: 12.4428\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.2510 - mae: 13.5439 - val_loss: 190.1055 - val_mae: 11.8010\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 172.4268 - mae: 11.0623 - val_loss: 107.0995 - val_mae: 8.4463\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.4390 - mae: 8.9883 - val_loss: 99.1829 - val_mae: 7.8955\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1177 - mae: 8.6315 - val_loss: 74.5133 - val_mae: 6.8945\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.0751 - mae: 8.1843 - val_loss: 62.6802 - val_mae: 6.4113\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0674 - mae: 7.9786 - val_loss: 53.2296 - val_mae: 5.7583\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.1466 - mae: 7.5785 - val_loss: 45.3936 - val_mae: 5.1309\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.1054 - mae: 7.2173 - val_loss: 41.3065 - val_mae: 4.7781\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.5256 - mae: 7.0375 - val_loss: 38.7185 - val_mae: 4.6127\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1583 - mae: 6.9279 - val_loss: 36.6922 - val_mae: 4.5233\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3539 - mae: 6.8123 - val_loss: 34.5652 - val_mae: 4.4090\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0905 - mae: 6.8007 - val_loss: 34.6353 - val_mae: 4.4491\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6079 - mae: 6.6826 - val_loss: 31.8294 - val_mae: 4.2357\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4819 - mae: 6.5740 - val_loss: 31.0157 - val_mae: 4.2335\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0990 - mae: 6.5128 - val_loss: 30.1199 - val_mae: 4.1271\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8604 - mae: 6.4327 - val_loss: 29.4907 - val_mae: 4.1168\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.6667 - mae: 6.3410 - val_loss: 27.9669 - val_mae: 3.9993\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8529 - mae: 6.3321 - val_loss: 28.1219 - val_mae: 4.0920\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.7694 - mae: 6.3894 - val_loss: 27.3169 - val_mae: 3.9750\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0052 - mae: 6.1764 - val_loss: 25.2356 - val_mae: 3.7937\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8091 - mae: 6.0542 - val_loss: 25.1085 - val_mae: 3.8903\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3970 - mae: 6.1231 - val_loss: 25.3473 - val_mae: 3.9723\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.5815 - mae: 6.2017 - val_loss: 24.3543 - val_mae: 3.8455\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1270 - mae: 5.9268 - val_loss: 22.8742 - val_mae: 3.6209\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.3151 - mae: 5.8722 - val_loss: 24.1811 - val_mae: 3.9188\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.0151 - mae: 5.9796 - val_loss: 22.9989 - val_mae: 3.7952\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4710 - mae: 5.8389 - val_loss: 21.5871 - val_mae: 3.6295\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.0991 - mae: 5.9315 - val_loss: 22.6120 - val_mae: 3.8295\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.1551 - mae: 5.7373 - val_loss: 20.2904 - val_mae: 3.4784\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.1191 - mae: 5.6399 - val_loss: 20.2472 - val_mae: 3.5334\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1822 - mae: 5.8838 - val_loss: 21.9644 - val_mae: 3.8562\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.2902 - mae: 5.7181 - val_loss: 19.0487 - val_mae: 3.3996\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.7949 - mae: 5.5982 - val_loss: 19.8460 - val_mae: 3.5805\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.4795 - mae: 5.7814 - val_loss: 20.2289 - val_mae: 3.6539\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.0485 - mae: 5.6212 - val_loss: 18.6678 - val_mae: 3.4597\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.9141 - mae: 5.5773 - val_loss: 19.6529 - val_mae: 3.6101\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.1689 - mae: 5.5553 - val_loss: 18.2322 - val_mae: 3.4443\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.2439 - mae: 5.5093 - val_loss: 18.1706 - val_mae: 3.4682\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4315 - mae: 5.7529 - val_loss: 19.9581 - val_mae: 3.7237\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.1257 - mae: 5.4911 - val_loss: 16.9844 - val_mae: 3.3054\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.3922 - mae: 5.4357 - val_loss: 18.2945 - val_mae: 3.5068\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.7989 - mae: 5.5723 - val_loss: 17.6998 - val_mae: 3.4474\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.1050 - mae: 5.4226 - val_loss: 17.0832 - val_mae: 3.3704\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.0420 - mae: 5.4602 - val_loss: 17.2273 - val_mae: 3.3954\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.5864 - mae: 5.4009 - val_loss: 16.1944 - val_mae: 3.2656\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 59.9854 - mae: 5.3999 - val_loss: 18.0226 - val_mae: 3.5246\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.5506 - mae: 5.4273 - val_loss: 16.2697 - val_mae: 3.3089\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.8035 - mae: 5.4183 - val_loss: 18.5555 - val_mae: 3.6073\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.1871 - mae: 5.3743 - val_loss: 16.0760 - val_mae: 3.3192\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.8062 - mae: 5.2505 - val_loss: 17.5790 - val_mae: 3.4969\n",
      "Epoch 52: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 60.0015 - mae: 5.7135\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=2, n_neurons=125, optimizer=adam; total time=   2.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 21ms/step - loss: 8072.4355 - mae: 88.0346 - val_loss: 5229.9043 - val_mae: 71.4918\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4264.5259 - mae: 63.4055 - val_loss: 2371.1709 - val_mae: 47.5219\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1916.2218 - mae: 41.1162 - val_loss: 859.5199 - val_mae: 27.1442\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 738.7502 - mae: 23.7152 - val_loss: 293.3941 - val_mae: 14.9636\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 312.2815 - mae: 14.6172 - val_loss: 208.6590 - val_mae: 11.4589\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.6828 - mae: 12.0560 - val_loss: 220.6203 - val_mae: 11.1268\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220.8110 - mae: 11.6095 - val_loss: 182.0938 - val_mae: 10.1497\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 180.4057 - mae: 10.7094 - val_loss: 117.8997 - val_mae: 8.3053\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 139.2082 - mae: 9.3673 - val_loss: 77.7333 - val_mae: 6.8465\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.0847 - mae: 8.3927 - val_loss: 57.6296 - val_mae: 5.7916\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.0276 - mae: 7.8945 - val_loss: 48.2945 - val_mae: 5.1806\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.6175 - mae: 7.6383 - val_loss: 44.0667 - val_mae: 4.9353\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.4707 - mae: 7.5371 - val_loss: 42.4488 - val_mae: 4.8920\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.4857 - mae: 7.5308 - val_loss: 41.9931 - val_mae: 4.9236\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.8827 - mae: 7.5266 - val_loss: 40.8279 - val_mae: 4.8992\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.6487 - mae: 7.5006 - val_loss: 39.8705 - val_mae: 4.8976\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.1161 - mae: 7.4219 - val_loss: 37.9982 - val_mae: 4.7131\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.8666 - mae: 7.3475 - val_loss: 36.8461 - val_mae: 4.6560\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.9332 - mae: 7.2813 - val_loss: 35.3961 - val_mae: 4.5530\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.4915 - mae: 7.2376 - val_loss: 35.0747 - val_mae: 4.6079\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.4869 - mae: 7.2342 - val_loss: 35.0851 - val_mae: 4.6757\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 91.2406 - mae: 7.1807 - val_loss: 33.4094 - val_mae: 4.5284\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.2281 - mae: 7.0925 - val_loss: 31.7497 - val_mae: 4.3698\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.0680 - mae: 7.0287 - val_loss: 31.0855 - val_mae: 4.3572\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.1940 - mae: 7.0316 - val_loss: 31.1922 - val_mae: 4.4397\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.0928 - mae: 6.9929 - val_loss: 30.0785 - val_mae: 4.3458\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.1130 - mae: 6.9254 - val_loss: 29.0738 - val_mae: 4.2327\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.2930 - mae: 6.8449 - val_loss: 27.7904 - val_mae: 4.1012\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.3491 - mae: 6.7889 - val_loss: 27.2563 - val_mae: 4.0663\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5371 - mae: 6.7585 - val_loss: 26.9069 - val_mae: 4.0562\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.8392 - mae: 6.7413 - val_loss: 26.3928 - val_mae: 4.0328\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.2111 - mae: 6.6927 - val_loss: 25.2243 - val_mae: 3.8815\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.2963 - mae: 6.6470 - val_loss: 25.6753 - val_mae: 4.0168\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.7250 - mae: 6.6603 - val_loss: 24.8508 - val_mae: 3.9367\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.0089 - mae: 6.6197 - val_loss: 24.5203 - val_mae: 3.9377\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.4848 - mae: 6.6359 - val_loss: 24.6333 - val_mae: 4.0027\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.6253 - mae: 6.5772 - val_loss: 23.4331 - val_mae: 3.8483\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.8820 - mae: 6.5045 - val_loss: 22.6808 - val_mae: 3.7678\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 77.2700 - mae: 6.4769 - val_loss: 22.3839 - val_mae: 3.7591\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.9527 - mae: 6.4117 - val_loss: 21.1921 - val_mae: 3.5994\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.2644 - mae: 6.4317 - val_loss: 22.5069 - val_mae: 3.8433\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.5017 - mae: 6.4780 - val_loss: 21.9856 - val_mae: 3.7990\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.9633 - mae: 6.3576 - val_loss: 20.1843 - val_mae: 3.5452\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.2939 - mae: 6.3121 - val_loss: 20.3540 - val_mae: 3.6077\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.6651 - mae: 6.4387 - val_loss: 21.3935 - val_mae: 3.7815\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.4817 - mae: 6.3290 - val_loss: 19.1120 - val_mae: 3.4572\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.9903 - mae: 6.2053 - val_loss: 18.3566 - val_mae: 3.3513\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.5795 - mae: 6.2065 - val_loss: 19.0066 - val_mae: 3.4818\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.0285 - mae: 6.2334 - val_loss: 19.0066 - val_mae: 3.5005\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.5917 - mae: 6.3018 - val_loss: 20.8564 - val_mae: 3.7626\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.2606 - mae: 6.3288 - val_loss: 19.1440 - val_mae: 3.5495\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.8493 - mae: 6.1944 - val_loss: 17.8278 - val_mae: 3.3573\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.4016 - mae: 6.1479 - val_loss: 18.3050 - val_mae: 3.4423\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.6894 - mae: 6.2393 - val_loss: 19.5771 - val_mae: 3.6109\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 69.8276 - mae: 6.1632 - val_loss: 17.1110 - val_mae: 3.2909\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.5310 - mae: 6.0727 - val_loss: 17.5266 - val_mae: 3.3613\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.2835 - mae: 6.0968 - val_loss: 17.4499 - val_mae: 3.3491\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.8245 - mae: 6.1520 - val_loss: 18.1561 - val_mae: 3.4541\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.6259 - mae: 6.1023 - val_loss: 17.3481 - val_mae: 3.3593\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.2681 - mae: 6.0781 - val_loss: 17.6326 - val_mae: 3.4039\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.1280 - mae: 6.1331 - val_loss: 17.6178 - val_mae: 3.4026\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.6749 - mae: 6.0669 - val_loss: 16.8938 - val_mae: 3.3122\n",
      "Epoch 62: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.4806 - mae: 4.8309\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=2, n_neurons=125, optimizer=adam; total time=   3.2s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 21ms/step - loss: 372.6121 - mae: 16.7536 - val_loss: 44.8411 - val_mae: 4.6447\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.2166 - mae: 6.9885 - val_loss: 121.3179 - val_mae: 9.2462\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.6573 - mae: 7.0166 - val_loss: 40.2427 - val_mae: 4.5001\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.2672 - mae: 5.5438 - val_loss: 51.1024 - val_mae: 5.7788\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62.1777 - mae: 6.3704 - val_loss: 36.6018 - val_mae: 4.6696\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.7433 - mae: 4.9379 - val_loss: 38.9275 - val_mae: 4.5958\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.5008 - mae: 4.7250 - val_loss: 34.2212 - val_mae: 4.3806\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.8306 - mae: 5.3191 - val_loss: 34.6959 - val_mae: 4.5642\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.9905 - mae: 5.1339 - val_loss: 33.1337 - val_mae: 4.2749\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.9487 - mae: 4.7094 - val_loss: 31.5202 - val_mae: 4.2259\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.4909 - mae: 4.9641 - val_loss: 30.9412 - val_mae: 4.2894\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.0656 - mae: 4.9581 - val_loss: 30.7292 - val_mae: 4.2457\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.1651 - mae: 4.7603 - val_loss: 30.3402 - val_mae: 4.2250\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.7005 - mae: 4.8402 - val_loss: 30.2847 - val_mae: 4.1810\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.8098 - mae: 4.9142 - val_loss: 30.1515 - val_mae: 4.1431\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.5232 - mae: 4.7448 - val_loss: 30.2442 - val_mae: 4.1880\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.8851 - mae: 4.8776 - val_loss: 29.8712 - val_mae: 4.0953\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.8364 - mae: 4.8096 - val_loss: 29.8362 - val_mae: 4.1721\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.7346 - mae: 4.6292 - val_loss: 29.1808 - val_mae: 4.0902\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.8141 - mae: 4.7952 - val_loss: 29.0828 - val_mae: 4.0670\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46.4406 - mae: 4.6847 - val_loss: 28.8277 - val_mae: 4.0798\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.5874 - mae: 4.6441 - val_loss: 28.4710 - val_mae: 4.0799\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.1398 - mae: 4.6621 - val_loss: 28.4244 - val_mae: 4.0462\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46.2508 - mae: 4.8199 - val_loss: 28.2879 - val_mae: 4.0379\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45.5499 - mae: 4.6170 - val_loss: 28.0007 - val_mae: 3.9946\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45.4705 - mae: 4.6169 - val_loss: 27.6905 - val_mae: 3.9978\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45.6899 - mae: 4.7885 - val_loss: 27.8522 - val_mae: 3.9388\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.8744 - mae: 4.5744 - val_loss: 28.2834 - val_mae: 4.0954\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.1901 - mae: 4.4741 - val_loss: 27.2634 - val_mae: 3.9222\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45.1343 - mae: 4.7798 - val_loss: 27.0190 - val_mae: 3.9718\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.7562 - mae: 4.5517 - val_loss: 27.0244 - val_mae: 3.9550\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44.4501 - mae: 4.4712 - val_loss: 26.8635 - val_mae: 3.9326\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44.4050 - mae: 4.6976 - val_loss: 26.7541 - val_mae: 3.8693\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.7773 - mae: 4.5227 - val_loss: 27.1541 - val_mae: 4.0268\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.8892 - mae: 4.4445 - val_loss: 26.3551 - val_mae: 3.8639\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.7665 - mae: 4.6055 - val_loss: 26.2880 - val_mae: 3.9106\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.9338 - mae: 4.5482 - val_loss: 26.0635 - val_mae: 3.9171\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.5766 - mae: 4.3831 - val_loss: 25.8731 - val_mae: 3.8877\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.6379 - mae: 4.5050 - val_loss: 25.7952 - val_mae: 3.8301\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.9565 - mae: 4.4439 - val_loss: 25.6592 - val_mae: 3.8876\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.1112 - mae: 4.3963 - val_loss: 25.6215 - val_mae: 3.8011\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.6855 - mae: 4.5119 - val_loss: 25.5689 - val_mae: 3.8678\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.0432 - mae: 4.5745 - val_loss: 25.5766 - val_mae: 3.7625\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43.3203 - mae: 4.3877 - val_loss: 25.7137 - val_mae: 3.9428\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 42.4937 - mae: 4.4439 - val_loss: 25.4534 - val_mae: 3.7595\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.3104 - mae: 4.4280 - val_loss: 25.2625 - val_mae: 3.8658\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.6280 - mae: 4.5394 - val_loss: 25.1143 - val_mae: 3.7556\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.8251 - mae: 4.3033 - val_loss: 24.7949 - val_mae: 3.8112\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.4138 - mae: 4.6484 - val_loss: 24.8430 - val_mae: 3.8157\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.8247 - mae: 4.2296 - val_loss: 24.9263 - val_mae: 3.8291\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.7087 - mae: 4.5776 - val_loss: 24.7879 - val_mae: 3.7435\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.9916 - mae: 4.2347 - val_loss: 24.5615 - val_mae: 3.7839\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.9330 - mae: 4.3825 - val_loss: 24.5336 - val_mae: 3.7424\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 41.2539 - mae: 4.4401 - val_loss: 24.6258 - val_mae: 3.8408\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.8840 - mae: 4.2394 - val_loss: 24.1938 - val_mae: 3.7281\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.7894 - mae: 4.4404 - val_loss: 24.0139 - val_mae: 3.7209\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.9722 - mae: 4.2507 - val_loss: 24.0658 - val_mae: 3.7315\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.7498 - mae: 4.3944 - val_loss: 23.9593 - val_mae: 3.7704\n",
      "Epoch 58: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 71.2744 - mae: 5.3707\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=2, n_neurons=125, optimizer=adam; total time=   2.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 253.8294 - mae: 12.2326 - val_loss: 65.8659 - val_mae: 7.2058\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.6254 - mae: 7.9968 - val_loss: 23.3593 - val_mae: 3.8580\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.6042 - mae: 5.8898 - val_loss: 31.5032 - val_mae: 4.7672\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.0369 - mae: 6.6737 - val_loss: 18.0354 - val_mae: 3.6946\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.8553 - mae: 5.7710 - val_loss: 15.6995 - val_mae: 3.2802\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.1521 - mae: 5.6872 - val_loss: 19.1857 - val_mae: 3.6680\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.6201 - mae: 5.5939 - val_loss: 17.8485 - val_mae: 3.4361\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.2865 - mae: 5.3714 - val_loss: 17.4541 - val_mae: 3.3893\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.3925 - mae: 5.5264 - val_loss: 19.1186 - val_mae: 3.6127\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1164 - mae: 5.5870 - val_loss: 16.7253 - val_mae: 3.3189\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.9188 - mae: 5.3051 - val_loss: 16.6194 - val_mae: 3.3130\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.9228 - mae: 5.4509 - val_loss: 18.2671 - val_mae: 3.5460\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.2752 - mae: 5.2895 - val_loss: 15.7240 - val_mae: 3.2312\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.3046 - mae: 5.5989 - val_loss: 18.2086 - val_mae: 3.5602\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 60.8364 - mae: 5.2205 - val_loss: 15.3714 - val_mae: 3.1477\n",
      "Epoch 15: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 58.4459 - mae: 5.4636\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   1.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2362.2815 - mae: 45.6439 - val_loss: 630.9838 - val_mae: 23.6140\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.6181 - mae: 17.7123 - val_loss: 161.6922 - val_mae: 8.6057\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 238.3919 - mae: 12.0384 - val_loss: 306.9599 - val_mae: 14.5182\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 233.8945 - mae: 12.9719 - val_loss: 139.3849 - val_mae: 9.9819\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.8137 - mae: 8.5318 - val_loss: 31.2274 - val_mae: 4.4372\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.3028 - mae: 6.5486 - val_loss: 25.0790 - val_mae: 3.3442\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.2894 - mae: 6.5123 - val_loss: 22.7760 - val_mae: 3.7434\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.2217 - mae: 6.5782 - val_loss: 30.9133 - val_mae: 4.8756\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.8980 - mae: 7.0127 - val_loss: 32.3196 - val_mae: 5.0517\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.7665 - mae: 6.7754 - val_loss: 25.7044 - val_mae: 4.3097\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.4701 - mae: 6.4623 - val_loss: 22.9396 - val_mae: 4.0116\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.0038 - mae: 6.3437 - val_loss: 22.9393 - val_mae: 4.0951\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8694 - mae: 6.4154 - val_loss: 25.3280 - val_mae: 4.4400\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8464 - mae: 6.5636 - val_loss: 25.1851 - val_mae: 4.4525\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.3721 - mae: 6.3664 - val_loss: 21.5344 - val_mae: 3.9827\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.4048 - mae: 6.3374 - val_loss: 22.6779 - val_mae: 4.1707\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.9691 - mae: 6.3146 - val_loss: 21.7302 - val_mae: 4.0710\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.2743 - mae: 6.3219 - val_loss: 22.8526 - val_mae: 4.2431\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.5608 - mae: 6.2804 - val_loss: 20.9624 - val_mae: 3.9526\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.5181 - mae: 6.2630 - val_loss: 21.9358 - val_mae: 4.1132\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.1628 - mae: 6.4824 - val_loss: 23.1962 - val_mae: 4.3221\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8900 - mae: 6.2170 - val_loss: 18.3568 - val_mae: 3.6501\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.6087 - mae: 6.0488 - val_loss: 19.7505 - val_mae: 3.8551\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.4531 - mae: 6.3270 - val_loss: 23.1256 - val_mae: 4.2741\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.0446 - mae: 6.3724 - val_loss: 19.7731 - val_mae: 3.8597\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.5961 - mae: 6.0292 - val_loss: 17.7240 - val_mae: 3.5648\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8953 - mae: 6.0820 - val_loss: 21.4111 - val_mae: 4.1254\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8291 - mae: 6.2163 - val_loss: 19.8046 - val_mae: 3.8585\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3375 - mae: 6.0564 - val_loss: 18.4938 - val_mae: 3.6638\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.0145 - mae: 6.0344 - val_loss: 20.1820 - val_mae: 3.9566\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9110 - mae: 6.1556 - val_loss: 19.7946 - val_mae: 3.8822\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2147 - mae: 6.0370 - val_loss: 16.7614 - val_mae: 3.4388\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.0871 - mae: 6.0417 - val_loss: 21.7950 - val_mae: 4.1431\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.5478 - mae: 6.1900 - val_loss: 18.1430 - val_mae: 3.6357\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.8270 - mae: 5.9875 - val_loss: 18.7890 - val_mae: 3.7180\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.9984 - mae: 6.1990 - val_loss: 20.0480 - val_mae: 3.8930\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.0778 - mae: 5.9551 - val_loss: 16.9639 - val_mae: 3.4763\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9284 - mae: 5.8673 - val_loss: 18.0732 - val_mae: 3.6610\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.9626 - mae: 6.0894 - val_loss: 19.1111 - val_mae: 3.8043\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.9384 - mae: 5.8828 - val_loss: 15.7091 - val_mae: 3.3026\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.1719 - mae: 6.1520 - val_loss: 23.2151 - val_mae: 4.2815\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.4927 - mae: 6.0969 - val_loss: 16.5385 - val_mae: 3.4045\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.4654 - mae: 5.7031 - val_loss: 16.4117 - val_mae: 3.4221\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2643 - mae: 5.9671 - val_loss: 20.6143 - val_mae: 4.0014\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.8080 - mae: 6.3180 - val_loss: 18.1188 - val_mae: 3.6434\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.2620 - mae: 5.6638 - val_loss: 14.2122 - val_mae: 3.0589\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7396 - mae: 5.7893 - val_loss: 20.2583 - val_mae: 3.9565\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.8876 - mae: 6.1247 - val_loss: 16.7453 - val_mae: 3.4558\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9604 - mae: 5.6790 - val_loss: 15.3168 - val_mae: 3.2536\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.2880 - mae: 6.0515 - val_loss: 24.4292 - val_mae: 4.3981\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.5141 - mae: 5.9998 - val_loss: 14.1514 - val_mae: 3.0815\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.1720 - mae: 5.6287 - val_loss: 17.3081 - val_mae: 3.5419\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.3690 - mae: 5.9657 - val_loss: 17.9292 - val_mae: 3.6341\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.4477 - mae: 5.8653 - val_loss: 17.3316 - val_mae: 3.5582\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.5777 - mae: 5.6890 - val_loss: 15.7277 - val_mae: 3.3175\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.8051 - mae: 5.9039 - val_loss: 19.1210 - val_mae: 3.7338\n",
      "Epoch 56: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.9002 - mae: 4.7844\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   2.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 1071.7607 - mae: 28.7794 - val_loss: 551.6678 - val_mae: 20.1428\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.8071 - mae: 17.4480 - val_loss: 292.2349 - val_mae: 14.0526\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 196.3078 - mae: 10.9096 - val_loss: 158.0224 - val_mae: 9.5485\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.7702 - mae: 7.3448 - val_loss: 78.2852 - val_mae: 6.5465\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.2613 - mae: 6.5856 - val_loss: 65.6868 - val_mae: 6.1782\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.7640 - mae: 6.4787 - val_loss: 57.7014 - val_mae: 5.9664\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.2312 - mae: 6.0292 - val_loss: 52.9242 - val_mae: 5.7539\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.4289 - mae: 5.9655 - val_loss: 50.0291 - val_mae: 5.5640\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.0052 - mae: 5.5617 - val_loss: 49.2667 - val_mae: 5.3847\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.5301 - mae: 5.1927 - val_loss: 45.8005 - val_mae: 5.2422\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.9123 - mae: 5.3138 - val_loss: 43.2690 - val_mae: 5.1806\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.1912 - mae: 5.3412 - val_loss: 42.2240 - val_mae: 5.1441\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 54.8847 - mae: 5.1698 - val_loss: 41.2661 - val_mae: 5.0967\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.9156 - mae: 5.1452 - val_loss: 40.6698 - val_mae: 5.0072\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.5173 - mae: 5.2153 - val_loss: 40.3427 - val_mae: 4.9470\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 52.9110 - mae: 5.0938 - val_loss: 40.0784 - val_mae: 4.9219\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.8979 - mae: 5.1158 - val_loss: 39.4825 - val_mae: 4.8489\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.5855 - mae: 5.0198 - val_loss: 38.9624 - val_mae: 4.8738\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.1707 - mae: 4.8374 - val_loss: 37.8277 - val_mae: 4.8262\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.2755 - mae: 5.0543 - val_loss: 37.5324 - val_mae: 4.7602\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.4851 - mae: 4.8885 - val_loss: 37.2115 - val_mae: 4.7551\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 50.5136 - mae: 4.7740 - val_loss: 36.4323 - val_mae: 4.7734\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.3135 - mae: 4.8408 - val_loss: 35.7060 - val_mae: 4.6688\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48.9806 - mae: 4.9996 - val_loss: 35.1141 - val_mae: 4.5875\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.8970 - mae: 4.7554 - val_loss: 34.6008 - val_mae: 4.6114\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.6765 - mae: 4.7137 - val_loss: 33.8433 - val_mae: 4.5938\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.6344 - mae: 4.9298 - val_loss: 34.0289 - val_mae: 4.5054\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 46.7873 - mae: 4.6761 - val_loss: 33.8443 - val_mae: 4.5713\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.8809 - mae: 4.5344 - val_loss: 32.8358 - val_mae: 4.4883\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 46.7281 - mae: 4.8671 - val_loss: 32.3429 - val_mae: 4.4897\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.3345 - mae: 4.6623 - val_loss: 32.2708 - val_mae: 4.4239\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.1288 - mae: 4.4897 - val_loss: 31.8929 - val_mae: 4.4223\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.8180 - mae: 4.7861 - val_loss: 31.9783 - val_mae: 4.3746\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.1055 - mae: 4.6088 - val_loss: 31.9964 - val_mae: 4.4658\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.2840 - mae: 4.4440 - val_loss: 31.0557 - val_mae: 4.3235\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.2538 - mae: 4.7610 - val_loss: 30.6559 - val_mae: 4.3073\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.8963 - mae: 4.5790 - val_loss: 30.6306 - val_mae: 4.3647\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.7080 - mae: 4.4328 - val_loss: 30.2534 - val_mae: 4.2881\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.6537 - mae: 4.5287 - val_loss: 30.1032 - val_mae: 4.2627\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.0047 - mae: 4.4800 - val_loss: 29.7039 - val_mae: 4.2911\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.0592 - mae: 4.4307 - val_loss: 29.7087 - val_mae: 4.2099\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.5203 - mae: 4.5594 - val_loss: 29.3025 - val_mae: 4.2256\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43.9354 - mae: 4.6496 - val_loss: 29.8398 - val_mae: 4.1138\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.1127 - mae: 4.4300 - val_loss: 29.3754 - val_mae: 4.2986\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43.1389 - mae: 4.4493 - val_loss: 29.4232 - val_mae: 4.1013\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.1237 - mae: 4.4407 - val_loss: 28.6761 - val_mae: 4.1856\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.5673 - mae: 4.6326 - val_loss: 28.8720 - val_mae: 4.0607\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.7664 - mae: 4.2759 - val_loss: 27.9146 - val_mae: 4.1630\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.1560 - mae: 4.7164 - val_loss: 27.6646 - val_mae: 4.0945\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 42.2201 - mae: 4.2301 - val_loss: 27.8861 - val_mae: 4.1310\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.1818 - mae: 4.5845 - val_loss: 27.9853 - val_mae: 3.9940\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.0594 - mae: 4.2335 - val_loss: 27.6554 - val_mae: 4.0989\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 41.1074 - mae: 4.2949 - val_loss: 27.5034 - val_mae: 4.0387\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 41.6074 - mae: 4.5058 - val_loss: 26.9508 - val_mae: 4.0833\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 41.2895 - mae: 4.1710 - val_loss: 26.5227 - val_mae: 3.9959\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.9476 - mae: 4.4621 - val_loss: 26.4541 - val_mae: 3.9514\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.9451 - mae: 4.1840 - val_loss: 26.3796 - val_mae: 4.0071\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 40.7842 - mae: 4.3444 - val_loss: 26.2594 - val_mae: 3.9896\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 40.5841 - mae: 4.1498 - val_loss: 26.3480 - val_mae: 3.9721\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.1242 - mae: 4.4173 - val_loss: 25.8509 - val_mae: 3.9714\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.4331 - mae: 4.0945 - val_loss: 25.9463 - val_mae: 3.9529\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.0762 - mae: 4.5440 - val_loss: 25.7085 - val_mae: 3.9149\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.5074 - mae: 4.1296 - val_loss: 25.6073 - val_mae: 3.9587\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.4972 - mae: 4.2104 - val_loss: 25.4532 - val_mae: 3.9108\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.2993 - mae: 4.2297 - val_loss: 25.3467 - val_mae: 3.9665\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 38.8807 - mae: 4.0944 - val_loss: 25.2532 - val_mae: 3.9059\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.8802 - mae: 4.2256 - val_loss: 24.9342 - val_mae: 3.8349\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.6306 - mae: 4.1824 - val_loss: 25.1108 - val_mae: 3.9125\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39.8989 - mae: 4.0710 - val_loss: 25.6870 - val_mae: 3.8909\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.6224 - mae: 4.3079 - val_loss: 24.6071 - val_mae: 3.9158\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.2510 - mae: 3.9351 - val_loss: 24.1816 - val_mae: 3.8259\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.3553 - mae: 4.3379 - val_loss: 24.4192 - val_mae: 3.8212\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 39.2432 - mae: 3.9362 - val_loss: 24.7137 - val_mae: 3.9085\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.4254 - mae: 4.4149 - val_loss: 24.5426 - val_mae: 3.9009\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.4302 - mae: 3.9728 - val_loss: 24.6844 - val_mae: 3.8408\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 37.8540 - mae: 4.1236 - val_loss: 24.4720 - val_mae: 3.8828\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 37.3275 - mae: 4.1879 - val_loss: 24.2214 - val_mae: 3.9120\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.1158 - mae: 3.9936 - val_loss: 23.9345 - val_mae: 3.8507\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.5065 - mae: 4.3503 - val_loss: 24.8307 - val_mae: 3.9335\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.3914 - mae: 3.8974 - val_loss: 23.5924 - val_mae: 3.8195\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36.3703 - mae: 4.1969 - val_loss: 24.8740 - val_mae: 3.9826\n",
      "Epoch 81: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 68.1956 - mae: 5.1548\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 253.3387 - mae: 13.0368 - val_loss: 48.5955 - val_mae: 5.4299\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.4239 - mae: 8.9167 - val_loss: 76.1572 - val_mae: 7.6469\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9547 - mae: 6.4683 - val_loss: 28.1335 - val_mae: 4.6088\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.8926 - mae: 6.3722 - val_loss: 19.1714 - val_mae: 3.3647\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9797 - mae: 6.1678 - val_loss: 16.2080 - val_mae: 3.2114\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.3625 - mae: 5.5753 - val_loss: 15.5745 - val_mae: 3.2596\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.5051 - mae: 5.3742 - val_loss: 23.9603 - val_mae: 4.2700\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.5027 - mae: 5.2289 - val_loss: 34.7894 - val_mae: 5.1679\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.0228 - mae: 5.5992 - val_loss: 26.5562 - val_mae: 4.4891\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.7160 - mae: 6.1739 - val_loss: 13.6477 - val_mae: 3.0080\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.9217 - mae: 5.5159 - val_loss: 17.2541 - val_mae: 3.3039\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.2951 - mae: 5.4515 - val_loss: 13.3875 - val_mae: 2.9345\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.5064 - mae: 5.4417 - val_loss: 32.8878 - val_mae: 5.0331\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.3733 - mae: 5.0522 - val_loss: 16.1143 - val_mae: 3.3168\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.5066 - mae: 5.0319 - val_loss: 13.5381 - val_mae: 3.0546\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.3740 - mae: 5.3490 - val_loss: 15.3933 - val_mae: 3.2324\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.7751 - mae: 5.4801 - val_loss: 13.5203 - val_mae: 3.0431\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.9095 - mae: 5.2821 - val_loss: 13.0322 - val_mae: 3.1712\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.6625 - mae: 5.7530 - val_loss: 21.7359 - val_mae: 3.8924\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.9794 - mae: 5.5769 - val_loss: 68.6392 - val_mae: 7.2318\n",
      "Epoch 20: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 81.8445 - mae: 7.9552\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   1.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 810.4766 - mae: 23.0616 - val_loss: 67.9868 - val_mae: 6.8368\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.4783 - mae: 12.9690 - val_loss: 27.9235 - val_mae: 4.5340\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128.3672 - mae: 7.8428 - val_loss: 23.9252 - val_mae: 4.1006\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.9490 - mae: 8.2435 - val_loss: 37.0082 - val_mae: 5.2058\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.4895 - mae: 6.4460 - val_loss: 16.2588 - val_mae: 3.1849\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.8506 - mae: 7.1916 - val_loss: 21.4176 - val_mae: 3.9185\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5612 - mae: 6.0169 - val_loss: 16.9978 - val_mae: 3.4644\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.5150 - mae: 6.3473 - val_loss: 24.3772 - val_mae: 4.2697\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.7678 - mae: 6.1058 - val_loss: 15.3264 - val_mae: 3.2578\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.9194 - mae: 6.4227 - val_loss: 17.0971 - val_mae: 3.5111\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.2043 - mae: 5.8626 - val_loss: 21.8106 - val_mae: 3.9946\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.4562 - mae: 5.9754 - val_loss: 19.6799 - val_mae: 3.8094\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.2177 - mae: 5.9537 - val_loss: 19.5485 - val_mae: 3.8129\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.9476 - mae: 6.0967 - val_loss: 14.1117 - val_mae: 3.1868\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.6764 - mae: 5.6515 - val_loss: 31.4263 - val_mae: 4.7244\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9778 - mae: 6.0453 - val_loss: 13.0878 - val_mae: 2.9847\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6026 - mae: 5.6332 - val_loss: 26.5032 - val_mae: 4.3885\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.8222 - mae: 5.8304 - val_loss: 14.2921 - val_mae: 3.2519\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3346 - mae: 5.5963 - val_loss: 25.6230 - val_mae: 4.3133\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.2823 - mae: 5.6920 - val_loss: 17.9657 - val_mae: 3.6598\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.4726 - mae: 6.2635 - val_loss: 16.9453 - val_mae: 3.2173\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9837 - mae: 5.7235 - val_loss: 23.5447 - val_mae: 4.0994\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.1742 - mae: 5.5356 - val_loss: 27.0440 - val_mae: 4.4023\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.7525 - mae: 5.9136 - val_loss: 12.8863 - val_mae: 2.8631\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.1172 - mae: 5.9434 - val_loss: 11.7138 - val_mae: 2.8477\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.1460 - mae: 5.3754 - val_loss: 25.6527 - val_mae: 4.3567\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.1317 - mae: 5.4741 - val_loss: 17.5070 - val_mae: 3.5833\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.4122 - mae: 5.4481 - val_loss: 14.4878 - val_mae: 3.1634\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.0509 - mae: 5.1774 - val_loss: 17.9729 - val_mae: 3.6108\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.8953 - mae: 5.1648 - val_loss: 20.7495 - val_mae: 3.9064\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.2979 - mae: 5.3114 - val_loss: 13.9090 - val_mae: 3.0646\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.0760 - mae: 5.2004 - val_loss: 18.3368 - val_mae: 3.6336\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.5280 - mae: 5.5476 - val_loss: 11.2276 - val_mae: 2.8173\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.0283 - mae: 4.8206 - val_loss: 16.6792 - val_mae: 3.3877\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.4632 - mae: 5.0671 - val_loss: 20.0309 - val_mae: 3.6898\n",
      "Epoch 35: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 36.4495 - mae: 4.8669\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   1.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 428.2672 - mae: 15.7905 - val_loss: 120.0474 - val_mae: 8.9836\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.3354 - mae: 7.6572 - val_loss: 35.3593 - val_mae: 4.8568\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.4803 - mae: 5.2189 - val_loss: 47.3769 - val_mae: 5.3597\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.7745 - mae: 5.1669 - val_loss: 35.9047 - val_mae: 4.7113\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.4795 - mae: 5.4037 - val_loss: 33.8685 - val_mae: 4.7320\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.0814 - mae: 5.0996 - val_loss: 34.0278 - val_mae: 4.5526\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.5126 - mae: 4.7614 - val_loss: 36.3423 - val_mae: 4.6814\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.0949 - mae: 4.8760 - val_loss: 28.9987 - val_mae: 4.2647\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.8126 - mae: 4.4878 - val_loss: 29.2404 - val_mae: 4.1250\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.5751 - mae: 4.8255 - val_loss: 32.3860 - val_mae: 4.2701\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.5564 - mae: 5.2282 - val_loss: 37.3166 - val_mae: 4.6682\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.2146 - mae: 5.4014 - val_loss: 51.3032 - val_mae: 5.8666\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.1713 - mae: 5.7831 - val_loss: 55.4454 - val_mae: 6.1780\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.3658 - mae: 5.5287 - val_loss: 45.0146 - val_mae: 5.4593\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.3856 - mae: 5.1080 - val_loss: 25.2703 - val_mae: 4.0128\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.3715 - mae: 4.3004 - val_loss: 25.6201 - val_mae: 3.8400\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.2393 - mae: 4.5775 - val_loss: 34.3485 - val_mae: 4.6734\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.6289 - mae: 5.1585 - val_loss: 43.4543 - val_mae: 5.2693\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45.9998 - mae: 4.9905 - val_loss: 38.5475 - val_mae: 4.9490\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.2248 - mae: 4.4865 - val_loss: 22.4187 - val_mae: 3.9619\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.8234 - mae: 4.2511 - val_loss: 22.3166 - val_mae: 3.6823\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.3246 - mae: 3.9320 - val_loss: 35.8925 - val_mae: 4.8503\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.1679 - mae: 5.1968 - val_loss: 39.5971 - val_mae: 5.2053\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.3368 - mae: 4.6469 - val_loss: 44.1973 - val_mae: 5.5851\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.2090 - mae: 4.7423 - val_loss: 26.7528 - val_mae: 4.0805\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37.8173 - mae: 4.1510 - val_loss: 31.5864 - val_mae: 4.5204\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.0039 - mae: 4.4276 - val_loss: 19.3266 - val_mae: 3.6408\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34.4767 - mae: 3.9364 - val_loss: 20.5864 - val_mae: 3.7802\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.9488 - mae: 3.9375 - val_loss: 23.2470 - val_mae: 3.9569\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35.9959 - mae: 4.0361 - val_loss: 21.5919 - val_mae: 3.8464\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35.3168 - mae: 4.1138 - val_loss: 40.3747 - val_mae: 5.1889\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39.5272 - mae: 4.5145 - val_loss: 19.6116 - val_mae: 3.5274\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32.5201 - mae: 3.9234 - val_loss: 22.4661 - val_mae: 3.9151\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33.2391 - mae: 3.9187 - val_loss: 20.8808 - val_mae: 3.7450\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32.9145 - mae: 3.9183 - val_loss: 16.8644 - val_mae: 3.4702\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30.7569 - mae: 3.7024 - val_loss: 16.0034 - val_mae: 3.3977\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30.1168 - mae: 3.7436 - val_loss: 17.8719 - val_mae: 3.4250\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.7189 - mae: 3.7075 - val_loss: 18.9449 - val_mae: 3.6479\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33.7785 - mae: 3.9773 - val_loss: 23.2772 - val_mae: 3.8744\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36.2133 - mae: 4.2061 - val_loss: 15.9788 - val_mae: 3.2423\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.3242 - mae: 4.2935 - val_loss: 18.4779 - val_mae: 3.5957\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31.0208 - mae: 3.8690 - val_loss: 20.7989 - val_mae: 3.5968\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29.9389 - mae: 3.8666 - val_loss: 15.2344 - val_mae: 3.3208\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30.1938 - mae: 3.7782 - val_loss: 18.1308 - val_mae: 3.5581\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31.0449 - mae: 3.9253 - val_loss: 14.8458 - val_mae: 3.2902\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28.8642 - mae: 3.7322 - val_loss: 16.1180 - val_mae: 3.1881\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27.0996 - mae: 3.6684 - val_loss: 17.4523 - val_mae: 3.4160\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26.7085 - mae: 3.7000 - val_loss: 19.9618 - val_mae: 3.5070\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29.1420 - mae: 3.7760 - val_loss: 22.0226 - val_mae: 3.6896\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31.6619 - mae: 3.9104 - val_loss: 18.1929 - val_mae: 3.5883\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33.6934 - mae: 4.2533 - val_loss: 20.4072 - val_mae: 3.7450\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35.6519 - mae: 4.2858 - val_loss: 16.1723 - val_mae: 3.3335\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37.4777 - mae: 4.3488 - val_loss: 27.5665 - val_mae: 4.0770\n",
      "Epoch 53: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 64.5720 - mae: 4.9573\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=125, optimizer=adam; total time=   2.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 130763.1250 - mae: 350.4879 - val_loss: 133108.4219 - val_mae: 353.6315\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130710.0469 - mae: 350.4152 - val_loss: 133054.3594 - val_mae: 353.5585\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130656.3750 - mae: 350.3422 - val_loss: 133000.4844 - val_mae: 353.4857\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130603.0312 - mae: 350.2695 - val_loss: 132946.5625 - val_mae: 353.4128\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130550.3281 - mae: 350.1969 - val_loss: 132892.6250 - val_mae: 353.3399\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130496.3828 - mae: 350.1240 - val_loss: 132838.9844 - val_mae: 353.2674\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130443.5547 - mae: 350.0515 - val_loss: 132785.0312 - val_mae: 353.1944\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130389.8281 - mae: 349.9784 - val_loss: 132731.2656 - val_mae: 353.1217\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130336.5938 - mae: 349.9058 - val_loss: 132677.2812 - val_mae: 353.0486\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130283.1875 - mae: 349.8329 - val_loss: 132623.5938 - val_mae: 352.9760\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130230.4766 - mae: 349.7605 - val_loss: 132569.5312 - val_mae: 352.9028\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130177.0078 - mae: 349.6876 - val_loss: 132516.1719 - val_mae: 352.8306\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130123.7031 - mae: 349.6152 - val_loss: 132462.7969 - val_mae: 352.7583\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130071.4922 - mae: 349.5429 - val_loss: 132408.7812 - val_mae: 352.6852\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130017.4219 - mae: 349.4699 - val_loss: 132355.4844 - val_mae: 352.6129\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129964.3203 - mae: 349.3973 - val_loss: 132301.8281 - val_mae: 352.5402\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129911.8359 - mae: 349.3247 - val_loss: 132247.6094 - val_mae: 352.4668\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129858.6094 - mae: 349.2517 - val_loss: 132193.6406 - val_mae: 352.3937\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129805.0078 - mae: 349.1789 - val_loss: 132140.4688 - val_mae: 352.3215\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129752.1406 - mae: 349.1067 - val_loss: 132087.2656 - val_mae: 352.2494\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129699.2422 - mae: 349.0342 - val_loss: 132033.6875 - val_mae: 352.1768\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129646.3125 - mae: 348.9617 - val_loss: 131980.0625 - val_mae: 352.1040\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129593.7656 - mae: 348.8892 - val_loss: 131926.2344 - val_mae: 352.0309\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129540.4531 - mae: 348.8163 - val_loss: 131872.7344 - val_mae: 351.9584\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129487.5859 - mae: 348.7439 - val_loss: 131819.4219 - val_mae: 351.8860\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129434.5625 - mae: 348.6715 - val_loss: 131766.1406 - val_mae: 351.8136\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129381.8281 - mae: 348.5990 - val_loss: 131712.6250 - val_mae: 351.7410\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129328.9766 - mae: 348.5266 - val_loss: 131659.3125 - val_mae: 351.6685\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129276.7266 - mae: 348.4543 - val_loss: 131605.5781 - val_mae: 351.5956\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129222.8516 - mae: 348.3812 - val_loss: 131552.5156 - val_mae: 351.5235\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129170.4844 - mae: 348.3091 - val_loss: 131499.0156 - val_mae: 351.4507\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129117.6250 - mae: 348.2364 - val_loss: 131445.3750 - val_mae: 351.3778\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129065.1562 - mae: 348.1639 - val_loss: 131391.6875 - val_mae: 351.3048\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129011.6250 - mae: 348.0911 - val_loss: 131338.8906 - val_mae: 351.2330\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 128959.3281 - mae: 348.0192 - val_loss: 131285.9531 - val_mae: 351.1610\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128906.1484 - mae: 347.9470 - val_loss: 131233.2344 - val_mae: 351.0892\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128854.5312 - mae: 347.8749 - val_loss: 131178.9844 - val_mae: 351.0154\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128800.7812 - mae: 347.8015 - val_loss: 131125.5469 - val_mae: 350.9427\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128748.4062 - mae: 347.7289 - val_loss: 131071.8438 - val_mae: 350.8697\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128695.2188 - mae: 347.6562 - val_loss: 131018.6797 - val_mae: 350.7973\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128642.4219 - mae: 347.5837 - val_loss: 130965.4922 - val_mae: 350.7248\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128589.4531 - mae: 347.5112 - val_loss: 130912.6484 - val_mae: 350.6528\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128536.7422 - mae: 347.4391 - val_loss: 130859.7109 - val_mae: 350.5807\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128484.9766 - mae: 347.3669 - val_loss: 130805.8828 - val_mae: 350.5074\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128431.2969 - mae: 347.2939 - val_loss: 130753.0156 - val_mae: 350.4353\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128379.2734 - mae: 347.2219 - val_loss: 130699.8359 - val_mae: 350.3628\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128326.8047 - mae: 347.1497 - val_loss: 130646.6641 - val_mae: 350.2903\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128273.9062 - mae: 347.0771 - val_loss: 130593.8594 - val_mae: 350.2183\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128221.6172 - mae: 347.0051 - val_loss: 130540.9375 - val_mae: 350.1461\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128169.2969 - mae: 346.9329 - val_loss: 130487.6953 - val_mae: 350.0735\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128116.5625 - mae: 346.8604 - val_loss: 130434.7578 - val_mae: 350.0012\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128064.1719 - mae: 346.7881 - val_loss: 130381.4844 - val_mae: 349.9286\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 128011.4453 - mae: 346.7155 - val_loss: 130328.5625 - val_mae: 349.8563\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127958.9453 - mae: 346.6431 - val_loss: 130275.4141 - val_mae: 349.7837\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127906.6641 - mae: 346.5707 - val_loss: 130221.9453 - val_mae: 349.7107\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127853.2969 - mae: 346.4979 - val_loss: 130169.1094 - val_mae: 349.6385\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 127801.1797 - mae: 346.4257 - val_loss: 130115.9609 - val_mae: 349.5659\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127748.6875 - mae: 346.3530 - val_loss: 130062.5859 - val_mae: 349.4930\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127695.4062 - mae: 346.2802 - val_loss: 130009.7656 - val_mae: 349.4208\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 127643.8672 - mae: 346.2082 - val_loss: 129956.2812 - val_mae: 349.3477\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127590.6094 - mae: 346.1351 - val_loss: 129903.4453 - val_mae: 349.2755\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127538.2188 - mae: 346.0630 - val_loss: 129850.6328 - val_mae: 349.2032\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127485.8594 - mae: 345.9906 - val_loss: 129797.6953 - val_mae: 349.1308\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127433.3516 - mae: 345.9182 - val_loss: 129744.6094 - val_mae: 349.0582\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127380.6953 - mae: 345.8456 - val_loss: 129691.5391 - val_mae: 348.9856\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127328.5078 - mae: 345.7730 - val_loss: 129638.0078 - val_mae: 348.9123\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127275.7422 - mae: 345.7000 - val_loss: 129584.6328 - val_mae: 348.8393\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127223.0938 - mae: 345.6272 - val_loss: 129531.5547 - val_mae: 348.7666\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127170.8203 - mae: 345.5548 - val_loss: 129478.6875 - val_mae: 348.6941\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127118.2188 - mae: 345.4824 - val_loss: 129425.9688 - val_mae: 348.6219\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127065.7188 - mae: 345.4100 - val_loss: 129373.5391 - val_mae: 348.5500\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127014.0312 - mae: 345.3381 - val_loss: 129320.2109 - val_mae: 348.4770\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 126961.2422 - mae: 345.2655 - val_loss: 129267.7422 - val_mae: 348.4051\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126909.1562 - mae: 345.1932 - val_loss: 129214.9375 - val_mae: 348.3326\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 126857.2969 - mae: 345.1210 - val_loss: 129161.7344 - val_mae: 348.2597\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126804.5781 - mae: 345.0482 - val_loss: 129109.0469 - val_mae: 348.1874\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126752.0781 - mae: 344.9758 - val_loss: 129056.2812 - val_mae: 348.1151\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126699.8828 - mae: 344.9035 - val_loss: 129003.4453 - val_mae: 348.0425\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126647.6719 - mae: 344.8310 - val_loss: 128950.4609 - val_mae: 347.9698\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126595.1094 - mae: 344.7584 - val_loss: 128897.6562 - val_mae: 347.8973\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126543.0781 - mae: 344.6860 - val_loss: 128844.7500 - val_mae: 347.8247\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126490.4922 - mae: 344.6133 - val_loss: 128791.7891 - val_mae: 347.7521\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126438.4844 - mae: 344.5409 - val_loss: 128738.7656 - val_mae: 347.6792\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126386.0391 - mae: 344.4684 - val_loss: 128686.2812 - val_mae: 347.6071\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126334.0938 - mae: 344.3964 - val_loss: 128633.7812 - val_mae: 347.5350\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126281.8906 - mae: 344.3242 - val_loss: 128581.4453 - val_mae: 347.4631\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126229.8672 - mae: 344.2522 - val_loss: 128529.0859 - val_mae: 347.3911\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126178.7188 - mae: 344.1803 - val_loss: 128476.0547 - val_mae: 347.3182\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126126.5156 - mae: 344.1076 - val_loss: 128423.2031 - val_mae: 347.2455\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126074.0547 - mae: 344.0352 - val_loss: 128370.9609 - val_mae: 347.1737\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126022.6797 - mae: 343.9634 - val_loss: 128318.2500 - val_mae: 347.1011\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125969.8828 - mae: 343.8907 - val_loss: 128266.1875 - val_mae: 347.0295\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125918.0781 - mae: 343.8188 - val_loss: 128213.6016 - val_mae: 346.9572\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125866.2656 - mae: 343.7466 - val_loss: 128161.0000 - val_mae: 346.8847\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125814.2188 - mae: 343.6744 - val_loss: 128108.4062 - val_mae: 346.8123\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 125762.0547 - mae: 343.6020 - val_loss: 128055.9844 - val_mae: 346.7401\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125710.5234 - mae: 343.5298 - val_loss: 128003.0938 - val_mae: 346.6672\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125658.0000 - mae: 343.4572 - val_loss: 127950.6172 - val_mae: 346.5949\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125606.1016 - mae: 343.3848 - val_loss: 127897.9297 - val_mae: 346.5223\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125554.1875 - mae: 343.3126 - val_loss: 127845.5312 - val_mae: 346.4501\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 121024.7266 - mae: 337.4212\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=0, n_neurons=125, optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 4130.9121 - mae: 56.1572 - val_loss: 3258.1848 - val_mae: 50.4138\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4125.7256 - mae: 56.1227 - val_loss: 3254.5400 - val_mae: 50.3794\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4120.3130 - mae: 56.0866 - val_loss: 3250.9463 - val_mae: 50.3455\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4115.1426 - mae: 56.0521 - val_loss: 3247.3240 - val_mae: 50.3111\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4109.8403 - mae: 56.0149 - val_loss: 3243.7388 - val_mae: 50.2770\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4104.6631 - mae: 55.9803 - val_loss: 3240.1970 - val_mae: 50.2433\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4099.4224 - mae: 55.9443 - val_loss: 3236.7146 - val_mae: 50.2126\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4094.2158 - mae: 55.9071 - val_loss: 3233.3074 - val_mae: 50.1865\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4089.3630 - mae: 55.8752 - val_loss: 3229.8074 - val_mae: 50.1598\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4084.2039 - mae: 55.8391 - val_loss: 3226.3293 - val_mae: 50.1331\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4079.1311 - mae: 55.8039 - val_loss: 3222.8311 - val_mae: 50.1062\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4074.0012 - mae: 55.7689 - val_loss: 3219.3674 - val_mae: 50.0795\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4068.8704 - mae: 55.7342 - val_loss: 3215.9077 - val_mae: 50.0528\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4063.5945 - mae: 55.6973 - val_loss: 3212.5229 - val_mae: 50.0265\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4058.6692 - mae: 55.6633 - val_loss: 3209.0901 - val_mae: 49.9998\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4053.6760 - mae: 55.6299 - val_loss: 3205.6042 - val_mae: 49.9726\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4048.4182 - mae: 55.5943 - val_loss: 3202.2048 - val_mae: 49.9460\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4043.4482 - mae: 55.5598 - val_loss: 3198.7825 - val_mae: 49.9192\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4038.2803 - mae: 55.5245 - val_loss: 3195.4260 - val_mae: 49.8928\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4033.4136 - mae: 55.4898 - val_loss: 3192.0000 - val_mae: 49.8658\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4028.3159 - mae: 55.4563 - val_loss: 3188.6558 - val_mae: 49.8393\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4023.3787 - mae: 55.4234 - val_loss: 3185.2981 - val_mae: 49.8127\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4018.4570 - mae: 55.3901 - val_loss: 3181.9353 - val_mae: 49.7860\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4013.4163 - mae: 55.3540 - val_loss: 3178.6045 - val_mae: 49.7594\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4008.4468 - mae: 55.3226 - val_loss: 3175.2551 - val_mae: 49.7326\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4003.5171 - mae: 55.2885 - val_loss: 3171.9285 - val_mae: 49.7059\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3998.6528 - mae: 55.2564 - val_loss: 3168.6287 - val_mae: 49.6793\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3993.5837 - mae: 55.2218 - val_loss: 3165.4717 - val_mae: 49.6539\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3988.9861 - mae: 55.1925 - val_loss: 3162.2156 - val_mae: 49.6275\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3984.1255 - mae: 55.1618 - val_loss: 3158.9834 - val_mae: 49.6013\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3979.2695 - mae: 55.1301 - val_loss: 3155.7434 - val_mae: 49.5749\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3974.4546 - mae: 55.0998 - val_loss: 3152.5125 - val_mae: 49.5485\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3969.6553 - mae: 55.0680 - val_loss: 3149.2546 - val_mae: 49.5218\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3964.8196 - mae: 55.0364 - val_loss: 3146.0325 - val_mae: 49.4953\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3959.8064 - mae: 55.0042 - val_loss: 3142.9402 - val_mae: 49.4699\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3955.3513 - mae: 54.9769 - val_loss: 3139.6753 - val_mae: 49.4429\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3950.4053 - mae: 54.9440 - val_loss: 3136.5017 - val_mae: 49.4166\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3945.6453 - mae: 54.9130 - val_loss: 3133.3740 - val_mae: 49.3906\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3940.9094 - mae: 54.8824 - val_loss: 3130.2766 - val_mae: 49.3648\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3936.2466 - mae: 54.8515 - val_loss: 3127.1636 - val_mae: 49.3388\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3931.6172 - mae: 54.8236 - val_loss: 3124.0217 - val_mae: 49.3125\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3926.8677 - mae: 54.7926 - val_loss: 3120.9221 - val_mae: 49.2865\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3922.1038 - mae: 54.7617 - val_loss: 3117.8474 - val_mae: 49.2605\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3917.3770 - mae: 54.7297 - val_loss: 3114.7817 - val_mae: 49.2346\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3912.9492 - mae: 54.7022 - val_loss: 3111.6021 - val_mae: 49.2077\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3908.1013 - mae: 54.6693 - val_loss: 3108.5396 - val_mae: 49.1816\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3903.5583 - mae: 54.6407 - val_loss: 3105.4514 - val_mae: 49.1553\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3898.6965 - mae: 54.6101 - val_loss: 3102.5046 - val_mae: 49.1301\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3894.2405 - mae: 54.5801 - val_loss: 3099.4641 - val_mae: 49.1040\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3889.6553 - mae: 54.5506 - val_loss: 3096.4590 - val_mae: 49.0782\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3885.1482 - mae: 54.5207 - val_loss: 3093.4736 - val_mae: 49.0525\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3880.6365 - mae: 54.4915 - val_loss: 3090.5171 - val_mae: 49.0269\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3876.0901 - mae: 54.4606 - val_loss: 3087.5725 - val_mae: 49.0014\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3871.6960 - mae: 54.4324 - val_loss: 3084.5950 - val_mae: 48.9755\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3867.1765 - mae: 54.4029 - val_loss: 3081.6606 - val_mae: 48.9499\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3862.6401 - mae: 54.3719 - val_loss: 3078.7478 - val_mae: 48.9244\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3858.1890 - mae: 54.3422 - val_loss: 3075.7876 - val_mae: 48.8984\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3853.6353 - mae: 54.3122 - val_loss: 3072.8611 - val_mae: 48.8726\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3849.1128 - mae: 54.2830 - val_loss: 3069.9834 - val_mae: 48.8472\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3844.8066 - mae: 54.2539 - val_loss: 3066.9985 - val_mae: 48.8208\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3840.2810 - mae: 54.2237 - val_loss: 3064.0579 - val_mae: 48.7946\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3835.6973 - mae: 54.1930 - val_loss: 3061.1738 - val_mae: 48.7689\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3831.2153 - mae: 54.1638 - val_loss: 3058.3303 - val_mae: 48.7436\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3827.0010 - mae: 54.1352 - val_loss: 3055.4324 - val_mae: 48.7175\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3822.4956 - mae: 54.1039 - val_loss: 3052.5981 - val_mae: 48.6921\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3818.0325 - mae: 54.0731 - val_loss: 3049.8489 - val_mae: 48.6673\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3813.9553 - mae: 54.0455 - val_loss: 3046.9583 - val_mae: 48.6412\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3809.3213 - mae: 54.0149 - val_loss: 3044.2063 - val_mae: 48.6163\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3805.2153 - mae: 53.9865 - val_loss: 3041.3364 - val_mae: 48.5902\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3800.6775 - mae: 53.9575 - val_loss: 3038.5647 - val_mae: 48.5649\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3796.4243 - mae: 53.9285 - val_loss: 3035.7361 - val_mae: 48.5390\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3791.9524 - mae: 53.9005 - val_loss: 3032.9924 - val_mae: 48.5139\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3787.7559 - mae: 53.8734 - val_loss: 3030.1968 - val_mae: 48.4881\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3783.4294 - mae: 53.8457 - val_loss: 3027.3965 - val_mae: 48.4676\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3779.1636 - mae: 53.8172 - val_loss: 3024.6182 - val_mae: 48.4483\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3774.7126 - mae: 53.7876 - val_loss: 3021.9282 - val_mae: 48.4294\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3770.4958 - mae: 53.7591 - val_loss: 3019.2339 - val_mae: 48.4105\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3766.5181 - mae: 53.7345 - val_loss: 3016.4246 - val_mae: 48.3908\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3762.0242 - mae: 53.7025 - val_loss: 3013.7644 - val_mae: 48.3720\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3757.8960 - mae: 53.6763 - val_loss: 3011.0562 - val_mae: 48.3529\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3753.6162 - mae: 53.6483 - val_loss: 3008.3782 - val_mae: 48.3339\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3749.3860 - mae: 53.6202 - val_loss: 3005.7434 - val_mae: 48.3151\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3745.3528 - mae: 53.5945 - val_loss: 3003.0886 - val_mae: 48.2961\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3741.2764 - mae: 53.5657 - val_loss: 3000.4016 - val_mae: 48.2769\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3737.0884 - mae: 53.5380 - val_loss: 2997.7739 - val_mae: 48.2579\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3732.9001 - mae: 53.5099 - val_loss: 2995.1736 - val_mae: 48.2391\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3728.7373 - mae: 53.4829 - val_loss: 2992.6030 - val_mae: 48.2205\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3724.7097 - mae: 53.4550 - val_loss: 2989.9717 - val_mae: 48.2014\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3720.5188 - mae: 53.4263 - val_loss: 2987.3672 - val_mae: 48.1824\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3716.4866 - mae: 53.4005 - val_loss: 2984.7424 - val_mae: 48.1632\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3712.3083 - mae: 53.3713 - val_loss: 2982.2034 - val_mae: 48.1446\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3708.3943 - mae: 53.3457 - val_loss: 2979.5928 - val_mae: 48.1254\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3704.0674 - mae: 53.3162 - val_loss: 2977.0708 - val_mae: 48.1068\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3700.2153 - mae: 53.2894 - val_loss: 2974.4600 - val_mae: 48.0875\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3696.2625 - mae: 53.2634 - val_loss: 2971.8450 - val_mae: 48.0682\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3691.9490 - mae: 53.2337 - val_loss: 2969.3447 - val_mae: 48.0495\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3688.1089 - mae: 53.2075 - val_loss: 2966.7812 - val_mae: 48.0303\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3684.0669 - mae: 53.1801 - val_loss: 2964.2720 - val_mae: 48.0115\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3680.0842 - mae: 53.1522 - val_loss: 2961.7896 - val_mae: 47.9928\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3676.0642 - mae: 53.1234 - val_loss: 2959.2917 - val_mae: 47.9739\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3152.7131 - mae: 49.4799\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=0, n_neurons=125, optimizer=adam; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 19192.6973 - mae: 135.3271 - val_loss: 19913.6992 - val_mae: 140.1544\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19173.0898 - mae: 135.2549 - val_loss: 19892.9355 - val_mae: 140.0800\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19153.7969 - mae: 135.1835 - val_loss: 19872.0840 - val_mae: 140.0053\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19134.2773 - mae: 135.1115 - val_loss: 19851.2734 - val_mae: 139.9307\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19114.8496 - mae: 135.0397 - val_loss: 19830.4980 - val_mae: 139.8562\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19095.3828 - mae: 134.9676 - val_loss: 19809.7832 - val_mae: 139.7818\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19076.0977 - mae: 134.8958 - val_loss: 19789.0469 - val_mae: 139.7074\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19056.6465 - mae: 134.8241 - val_loss: 19768.3926 - val_mae: 139.6332\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19037.3145 - mae: 134.7523 - val_loss: 19747.7031 - val_mae: 139.5588\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19017.9648 - mae: 134.6807 - val_loss: 19727.0352 - val_mae: 139.4845\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18998.7773 - mae: 134.6088 - val_loss: 19706.2715 - val_mae: 139.4098\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18979.3203 - mae: 134.5370 - val_loss: 19685.6777 - val_mae: 139.3356\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18960.2676 - mae: 134.4658 - val_loss: 19664.9531 - val_mae: 139.2609\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18940.8984 - mae: 134.3937 - val_loss: 19644.3340 - val_mae: 139.1866\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18921.6387 - mae: 134.3221 - val_loss: 19623.7793 - val_mae: 139.1125\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18902.3535 - mae: 134.2504 - val_loss: 19603.3047 - val_mae: 139.0386\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18883.0059 - mae: 134.1790 - val_loss: 19582.8711 - val_mae: 138.9648\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18864.0781 - mae: 134.1078 - val_loss: 19562.2012 - val_mae: 138.8902\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18844.8965 - mae: 134.0361 - val_loss: 19541.6211 - val_mae: 138.8158\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18825.5430 - mae: 133.9645 - val_loss: 19521.2656 - val_mae: 138.7421\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18806.6621 - mae: 133.8933 - val_loss: 19500.7246 - val_mae: 138.6678\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18787.3574 - mae: 133.8219 - val_loss: 19480.3516 - val_mae: 138.5940\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18768.2852 - mae: 133.7505 - val_loss: 19459.9824 - val_mae: 138.5202\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18749.3164 - mae: 133.6794 - val_loss: 19439.5273 - val_mae: 138.4461\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18730.0801 - mae: 133.6078 - val_loss: 19419.1992 - val_mae: 138.3724\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18711.0801 - mae: 133.5364 - val_loss: 19398.8262 - val_mae: 138.2984\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18691.9727 - mae: 133.4653 - val_loss: 19378.5449 - val_mae: 138.2248\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 18673.2324 - mae: 133.3945 - val_loss: 19358.0918 - val_mae: 138.1505\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18654.0391 - mae: 133.3226 - val_loss: 19337.7754 - val_mae: 138.0767\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18634.9082 - mae: 133.2512 - val_loss: 19317.5293 - val_mae: 138.0030\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18616.1426 - mae: 133.1803 - val_loss: 19297.1035 - val_mae: 137.9287\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18597.1094 - mae: 133.1090 - val_loss: 19276.7812 - val_mae: 137.8547\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18578.0703 - mae: 133.0376 - val_loss: 19256.5781 - val_mae: 137.7811\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18559.0977 - mae: 132.9666 - val_loss: 19236.4180 - val_mae: 137.7076\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18540.3281 - mae: 132.8956 - val_loss: 19216.1484 - val_mae: 137.6337\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18521.4082 - mae: 132.8241 - val_loss: 19195.9023 - val_mae: 137.5598\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18502.3848 - mae: 132.7525 - val_loss: 19175.7539 - val_mae: 137.4863\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18483.6055 - mae: 132.6817 - val_loss: 19155.4922 - val_mae: 137.4123\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18464.7676 - mae: 132.6108 - val_loss: 19135.2266 - val_mae: 137.3382\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18445.8418 - mae: 132.5394 - val_loss: 19115.0801 - val_mae: 137.2645\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18426.8770 - mae: 132.4682 - val_loss: 19095.0645 - val_mae: 137.1912\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18408.1309 - mae: 132.3971 - val_loss: 19074.9453 - val_mae: 137.1176\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18389.3398 - mae: 132.3263 - val_loss: 19054.7852 - val_mae: 137.0437\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18370.4492 - mae: 132.2551 - val_loss: 19034.7070 - val_mae: 136.9701\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18351.7324 - mae: 132.1841 - val_loss: 19014.5625 - val_mae: 136.8963\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18332.8418 - mae: 132.1126 - val_loss: 18994.5391 - val_mae: 136.8228\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18314.1289 - mae: 132.0419 - val_loss: 18974.4844 - val_mae: 136.7491\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18295.4727 - mae: 131.9709 - val_loss: 18954.3750 - val_mae: 136.6753\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18276.8438 - mae: 131.9000 - val_loss: 18934.2246 - val_mae: 136.6012\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18257.9336 - mae: 131.8282 - val_loss: 18914.3086 - val_mae: 136.5279\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18239.2637 - mae: 131.7577 - val_loss: 18894.3770 - val_mae: 136.4546\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18220.4922 - mae: 131.6867 - val_loss: 18874.4609 - val_mae: 136.3813\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18202.0977 - mae: 131.6163 - val_loss: 18854.3652 - val_mae: 136.3073\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18183.3281 - mae: 131.5451 - val_loss: 18834.4961 - val_mae: 136.2340\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18164.6387 - mae: 131.4743 - val_loss: 18814.7266 - val_mae: 136.1611\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18146.1172 - mae: 131.4040 - val_loss: 18794.8613 - val_mae: 136.0878\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18127.5391 - mae: 131.3332 - val_loss: 18774.9590 - val_mae: 136.0143\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18108.9121 - mae: 131.2623 - val_loss: 18755.0723 - val_mae: 135.9408\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18090.2949 - mae: 131.1913 - val_loss: 18735.2305 - val_mae: 135.8675\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18071.8145 - mae: 131.1206 - val_loss: 18715.3242 - val_mae: 135.7939\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18053.2441 - mae: 131.0500 - val_loss: 18695.4863 - val_mae: 135.7205\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18034.7168 - mae: 130.9789 - val_loss: 18675.6582 - val_mae: 135.6470\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18016.1758 - mae: 130.9079 - val_loss: 18655.9023 - val_mae: 135.5739\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17997.7793 - mae: 130.8378 - val_loss: 18636.0586 - val_mae: 135.5003\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17979.0527 - mae: 130.7665 - val_loss: 18616.4453 - val_mae: 135.4276\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17960.7539 - mae: 130.6964 - val_loss: 18596.7324 - val_mae: 135.3544\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17942.3965 - mae: 130.6257 - val_loss: 18576.9531 - val_mae: 135.2809\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17923.9375 - mae: 130.5549 - val_loss: 18557.2129 - val_mae: 135.2076\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17905.3906 - mae: 130.4842 - val_loss: 18537.5293 - val_mae: 135.1344\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17887.0039 - mae: 130.4137 - val_loss: 18517.8203 - val_mae: 135.0611\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17868.6699 - mae: 130.3432 - val_loss: 18498.1035 - val_mae: 134.9878\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17850.1523 - mae: 130.2723 - val_loss: 18478.5391 - val_mae: 134.9149\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17831.9844 - mae: 130.2021 - val_loss: 18458.8633 - val_mae: 134.8416\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17813.4434 - mae: 130.1312 - val_loss: 18439.3730 - val_mae: 134.7689\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17795.2168 - mae: 130.0612 - val_loss: 18419.7129 - val_mae: 134.6956\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17776.9785 - mae: 129.9903 - val_loss: 18400.0137 - val_mae: 134.6221\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17758.5898 - mae: 129.9194 - val_loss: 18380.4492 - val_mae: 134.5490\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17740.2207 - mae: 129.8491 - val_loss: 18360.9609 - val_mae: 134.4762\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17722.0820 - mae: 129.7786 - val_loss: 18341.3848 - val_mae: 134.4030\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17703.7852 - mae: 129.7083 - val_loss: 18321.8496 - val_mae: 134.3300\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17685.4609 - mae: 129.6381 - val_loss: 18302.3477 - val_mae: 134.2570\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17667.2676 - mae: 129.5675 - val_loss: 18282.8223 - val_mae: 134.1839\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17649.0117 - mae: 129.4970 - val_loss: 18263.4180 - val_mae: 134.1112\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17630.7441 - mae: 129.4267 - val_loss: 18244.0410 - val_mae: 134.0385\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17612.5547 - mae: 129.3562 - val_loss: 18224.6230 - val_mae: 133.9657\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17594.4004 - mae: 129.2859 - val_loss: 18205.1484 - val_mae: 133.8926\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17576.3516 - mae: 129.2157 - val_loss: 18185.5332 - val_mae: 133.8189\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17558.0508 - mae: 129.1447 - val_loss: 18166.0820 - val_mae: 133.7458\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17539.7754 - mae: 129.0743 - val_loss: 18146.7617 - val_mae: 133.6732\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17521.7480 - mae: 129.0041 - val_loss: 18127.4219 - val_mae: 133.6004\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17503.6465 - mae: 128.9342 - val_loss: 18108.1289 - val_mae: 133.5278\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17485.5684 - mae: 128.8642 - val_loss: 18088.8281 - val_mae: 133.4551\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17467.5410 - mae: 128.7939 - val_loss: 18069.4629 - val_mae: 133.3821\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17449.3711 - mae: 128.7232 - val_loss: 18050.1660 - val_mae: 133.3094\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17431.3789 - mae: 128.6532 - val_loss: 18030.7656 - val_mae: 133.2362\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17413.3340 - mae: 128.5825 - val_loss: 18011.3984 - val_mae: 133.1631\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17395.2227 - mae: 128.5126 - val_loss: 17992.2031 - val_mae: 133.0906\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17377.2246 - mae: 128.4421 - val_loss: 17973.0078 - val_mae: 133.0181\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17359.3516 - mae: 128.3723 - val_loss: 17953.7266 - val_mae: 132.9451\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17341.2793 - mae: 128.3018 - val_loss: 17934.5430 - val_mae: 132.8726\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17799.5918 - mae: 130.7247\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=0, n_neurons=125, optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 2784.5632 - mae: 38.0076 - val_loss: 31.3498 - val_mae: 4.6491\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.2414 - mae: 6.8333 - val_loss: 19.1921 - val_mae: 3.5778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.7345 - mae: 6.2022 - val_loss: 18.2391 - val_mae: 3.5002\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.5271 - mae: 6.7014 - val_loss: 39.2249 - val_mae: 5.3811\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.8439 - mae: 6.5098 - val_loss: 20.2451 - val_mae: 3.4592\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.5263 - mae: 6.0997 - val_loss: 26.4758 - val_mae: 3.9442\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9211 - mae: 6.2916 - val_loss: 17.6135 - val_mae: 3.5213\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.4238 - mae: 6.2976 - val_loss: 52.8629 - val_mae: 6.4072\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.3359 - mae: 6.0421 - val_loss: 66.4993 - val_mae: 7.2213\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.4295 - mae: 5.9875 - val_loss: 32.5186 - val_mae: 4.9415\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.2503 - mae: 5.9959 - val_loss: 19.3230 - val_mae: 3.7488\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.7102 - mae: 6.0635 - val_loss: 16.8370 - val_mae: 3.2937\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.1993 - mae: 5.7599 - val_loss: 65.5161 - val_mae: 7.1850\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.0247 - mae: 6.6604 - val_loss: 19.1921 - val_mae: 3.7214\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.7445 - mae: 5.8144 - val_loss: 18.4764 - val_mae: 3.6570\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.6425 - mae: 5.8204 - val_loss: 17.8924 - val_mae: 3.2187\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.7727 - mae: 5.8174 - val_loss: 26.1390 - val_mae: 4.3848\n",
      "Epoch 17: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 65.6935 - mae: 6.3801\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=3, n_neurons=125, optimizer=momentum; total time=   1.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 3129.0083 - mae: 34.2113 - val_loss: 46.8804 - val_mae: 5.7341\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.1126 - mae: 6.9560 - val_loss: 16.9164 - val_mae: 3.5560\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.8489 - mae: 6.9176 - val_loss: 34.6997 - val_mae: 4.9134\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.1617 - mae: 6.4498 - val_loss: 37.4766 - val_mae: 5.2553\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.9450 - mae: 6.8560 - val_loss: 19.7687 - val_mae: 3.6820\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.6277 - mae: 6.7199 - val_loss: 15.8641 - val_mae: 3.1465\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.9333 - mae: 6.6633 - val_loss: 28.1338 - val_mae: 4.6946\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.9570 - mae: 7.1701 - val_loss: 61.8832 - val_mae: 6.9609\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.3799 - mae: 6.2470 - val_loss: 41.0191 - val_mae: 5.5772\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.7718 - mae: 6.2266 - val_loss: 55.8333 - val_mae: 6.5144\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.0175 - mae: 6.6866 - val_loss: 20.8574 - val_mae: 3.9356\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8752 - mae: 6.4881 - val_loss: 31.1313 - val_mae: 4.7831\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.2456 - mae: 6.2802 - val_loss: 32.5909 - val_mae: 5.0008\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.6213 - mae: 6.5529 - val_loss: 21.4020 - val_mae: 4.0019\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.1576 - mae: 6.2648 - val_loss: 16.4314 - val_mae: 3.4770\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.0057 - mae: 6.1570 - val_loss: 17.3540 - val_mae: 3.4983\n",
      "Epoch 16: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.0732 - mae: 4.3869\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=3, n_neurons=125, optimizer=momentum; total time=   1.2s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 3508.6411 - mae: 37.0281 - val_loss: 64.3134 - val_mae: 6.6282\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.3629 - mae: 6.3306 - val_loss: 46.0238 - val_mae: 5.5204\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.9190 - mae: 5.5981 - val_loss: 43.6928 - val_mae: 5.2562\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.0563 - mae: 5.4067 - val_loss: 44.6952 - val_mae: 5.4498\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.4644 - mae: 5.3789 - val_loss: 40.8344 - val_mae: 5.0213\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.0789 - mae: 5.2759 - val_loss: 39.2919 - val_mae: 5.0503\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.7227 - mae: 5.3897 - val_loss: 40.5327 - val_mae: 5.0244\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.0620 - mae: 5.3253 - val_loss: 43.6708 - val_mae: 5.0210\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.8111 - mae: 5.1052 - val_loss: 38.9349 - val_mae: 4.9820\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.5409 - mae: 5.2832 - val_loss: 37.2583 - val_mae: 4.8368\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.1825 - mae: 5.1402 - val_loss: 36.6810 - val_mae: 4.7952\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.3397 - mae: 5.1081 - val_loss: 36.5044 - val_mae: 4.7530\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.8375 - mae: 4.9974 - val_loss: 36.9403 - val_mae: 4.6854\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.8731 - mae: 4.9789 - val_loss: 36.4588 - val_mae: 4.6660\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.2007 - mae: 5.0350 - val_loss: 41.7918 - val_mae: 4.9682\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.1426 - mae: 5.1250 - val_loss: 36.7096 - val_mae: 4.6073\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.7626 - mae: 5.1033 - val_loss: 39.1941 - val_mae: 4.7435\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.2776 - mae: 5.1246 - val_loss: 37.0798 - val_mae: 4.6550\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.7790 - mae: 5.0398 - val_loss: 38.5162 - val_mae: 4.6866\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.5042 - mae: 4.8759 - val_loss: 35.2622 - val_mae: 4.7155\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.5250 - mae: 5.0918 - val_loss: 34.2685 - val_mae: 4.5859\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.7341 - mae: 4.7857 - val_loss: 39.3856 - val_mae: 4.8313\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.2248 - mae: 5.2849 - val_loss: 35.0377 - val_mae: 4.4852\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.6627 - mae: 4.7284 - val_loss: 38.0996 - val_mae: 4.7722\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.4678 - mae: 4.9820 - val_loss: 33.8455 - val_mae: 4.5046\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.4660 - mae: 4.8151 - val_loss: 37.7682 - val_mae: 4.6842\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.0332 - mae: 5.0581 - val_loss: 38.8635 - val_mae: 4.8019\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51.3114 - mae: 4.9922 - val_loss: 32.9643 - val_mae: 4.4405\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48.3144 - mae: 4.8566 - val_loss: 33.7278 - val_mae: 4.4552\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.1600 - mae: 4.7647 - val_loss: 33.0163 - val_mae: 4.3654\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.6336 - mae: 4.7786 - val_loss: 33.4006 - val_mae: 4.4838\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.6356 - mae: 4.8924 - val_loss: 35.8679 - val_mae: 4.4609\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.9385 - mae: 4.8437 - val_loss: 35.4993 - val_mae: 4.5828\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.9583 - mae: 4.8053 - val_loss: 32.7614 - val_mae: 4.3193\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.0879 - mae: 4.7263 - val_loss: 33.4919 - val_mae: 4.3324\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.3970 - mae: 4.6999 - val_loss: 32.4130 - val_mae: 4.3458\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.5775 - mae: 4.9032 - val_loss: 35.8651 - val_mae: 4.4699\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.6679 - mae: 4.8199 - val_loss: 33.0748 - val_mae: 4.3954\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.2048 - mae: 4.9120 - val_loss: 31.8723 - val_mae: 4.4441\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.5960 - mae: 4.8191 - val_loss: 33.9629 - val_mae: 4.3177\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.6712 - mae: 4.9139 - val_loss: 32.8660 - val_mae: 4.3898\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.2158 - mae: 4.5162 - val_loss: 59.7758 - val_mae: 6.1896\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.4277 - mae: 5.1516 - val_loss: 31.3432 - val_mae: 4.2682\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.5822 - mae: 4.8153 - val_loss: 32.6727 - val_mae: 4.2192\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.0948 - mae: 4.6633 - val_loss: 31.2649 - val_mae: 4.2696\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.7689 - mae: 4.6331 - val_loss: 36.7653 - val_mae: 4.5023\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45.9950 - mae: 4.7030 - val_loss: 34.1073 - val_mae: 4.4677\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.0189 - mae: 4.8274 - val_loss: 35.4492 - val_mae: 4.4593\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50.0552 - mae: 4.9009 - val_loss: 30.7651 - val_mae: 4.2152\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.1986 - mae: 4.6987 - val_loss: 36.9367 - val_mae: 4.5216\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47.9587 - mae: 4.9305 - val_loss: 30.6909 - val_mae: 4.2453\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48.3458 - mae: 4.7367 - val_loss: 31.6478 - val_mae: 4.2489\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.5362 - mae: 4.6955 - val_loss: 31.7941 - val_mae: 4.2641\n",
      "Epoch 53: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 74.5029 - mae: 5.8498\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=3, n_neurons=125, optimizer=momentum; total time=   2.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 19ms/step - loss: 604.5905 - mae: 22.6529 - val_loss: 433.9568 - val_mae: 19.8958\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.2913 - mae: 22.1601 - val_loss: 418.4708 - val_mae: 19.5028\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.1622 - mae: 21.7666 - val_loss: 403.6164 - val_mae: 19.1181\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.6786 - mae: 21.3860 - val_loss: 389.1381 - val_mae: 18.7357\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 524.5440 - mae: 21.0055 - val_loss: 375.2761 - val_mae: 18.3620\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.1463 - mae: 20.6312 - val_loss: 362.0183 - val_mae: 17.9974\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.3426 - mae: 20.2725 - val_loss: 349.2397 - val_mae: 17.6388\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.0191 - mae: 19.9205 - val_loss: 336.8723 - val_mae: 17.2847\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 466.1126 - mae: 19.5655 - val_loss: 324.8842 - val_mae: 16.9343\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.6198 - mae: 19.2164 - val_loss: 313.4535 - val_mae: 16.5934\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.7530 - mae: 18.8818 - val_loss: 302.4235 - val_mae: 16.2576\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.2630 - mae: 18.5475 - val_loss: 291.8019 - val_mae: 15.9276\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 415.2155 - mae: 18.2206 - val_loss: 281.5232 - val_mae: 15.6016\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.5274 - mae: 17.8946 - val_loss: 271.6966 - val_mae: 15.2834\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 392.3346 - mae: 17.5810 - val_loss: 262.2426 - val_mae: 14.9710\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 381.5395 - mae: 17.2743 - val_loss: 253.2188 - val_mae: 14.6665\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.1946 - mae: 16.9827 - val_loss: 244.4813 - val_mae: 14.3655\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.1205 - mae: 16.6859 - val_loss: 236.0444 - val_mae: 14.0688\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.3875 - mae: 16.4027 - val_loss: 227.9213 - val_mae: 13.7771\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.9809 - mae: 16.1143 - val_loss: 220.0846 - val_mae: 13.4897\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.8781 - mae: 15.8291 - val_loss: 212.5414 - val_mae: 13.2124\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.1046 - mae: 15.5556 - val_loss: 205.3626 - val_mae: 12.9581\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.7293 - mae: 15.2921 - val_loss: 198.4110 - val_mae: 12.7066\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.5583 - mae: 15.0279 - val_loss: 191.7041 - val_mae: 12.4587\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.6714 - mae: 14.7690 - val_loss: 185.2576 - val_mae: 12.2153\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.0609 - mae: 14.5177 - val_loss: 179.0622 - val_mae: 11.9763\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.7284 - mae: 14.2781 - val_loss: 173.1209 - val_mae: 11.7421\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.6722 - mae: 14.0420 - val_loss: 167.4188 - val_mae: 11.5125\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.8575 - mae: 13.8181 - val_loss: 161.9019 - val_mae: 11.2854\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.2519 - mae: 13.5930 - val_loss: 156.6585 - val_mae: 11.0649\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.9676 - mae: 13.3762 - val_loss: 151.6544 - val_mae: 10.8498\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 251.9175 - mae: 13.1657 - val_loss: 146.7483 - val_mae: 10.6343\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 245.9411 - mae: 12.9495 - val_loss: 142.0288 - val_mae: 10.4224\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 240.1995 - mae: 12.7441 - val_loss: 137.4943 - val_mae: 10.2141\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.6591 - mae: 12.5413 - val_loss: 133.1513 - val_mae: 10.0197\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 229.3377 - mae: 12.3406 - val_loss: 129.0258 - val_mae: 9.8375\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.2594 - mae: 12.1533 - val_loss: 125.0697 - val_mae: 9.6588\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 219.3631 - mae: 11.9684 - val_loss: 121.3019 - val_mae: 9.4848\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.6704 - mae: 11.7897 - val_loss: 117.6107 - val_mae: 9.3105\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.0368 - mae: 11.6131 - val_loss: 114.0505 - val_mae: 9.1385\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.5610 - mae: 11.4286 - val_loss: 110.6547 - val_mae: 8.9706\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.2819 - mae: 11.2580 - val_loss: 107.4103 - val_mae: 8.8178\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.1723 - mae: 11.1022 - val_loss: 104.3144 - val_mae: 8.6715\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 193.2196 - mae: 10.9455 - val_loss: 101.3157 - val_mae: 8.5266\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.3693 - mae: 10.7847 - val_loss: 98.4300 - val_mae: 8.3838\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 185.6459 - mae: 10.6305 - val_loss: 95.6876 - val_mae: 8.2515\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.1056 - mae: 10.4899 - val_loss: 93.0664 - val_mae: 8.1285\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.6714 - mae: 10.3486 - val_loss: 90.4994 - val_mae: 8.0052\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.2902 - mae: 10.2096 - val_loss: 88.0468 - val_mae: 7.8846\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 172.0625 - mae: 10.0716 - val_loss: 85.7115 - val_mae: 7.7727\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 168.9622 - mae: 9.9419 - val_loss: 83.4530 - val_mae: 7.6684\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 165.9454 - mae: 9.8087 - val_loss: 81.2916 - val_mae: 7.5661\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 163.0399 - mae: 9.6913 - val_loss: 79.2122 - val_mae: 7.4702\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.2349 - mae: 9.5738 - val_loss: 77.2701 - val_mae: 7.3851\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 157.5932 - mae: 9.4669 - val_loss: 75.3848 - val_mae: 7.3003\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 154.9888 - mae: 9.3582 - val_loss: 73.5610 - val_mae: 7.2163\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 152.4714 - mae: 9.2491 - val_loss: 71.8396 - val_mae: 7.1350\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 150.0811 - mae: 9.1466 - val_loss: 70.1605 - val_mae: 7.0537\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 147.7185 - mae: 9.0460 - val_loss: 68.5704 - val_mae: 6.9747\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 145.4808 - mae: 8.9438 - val_loss: 67.0470 - val_mae: 6.8970\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 143.3132 - mae: 8.8523 - val_loss: 65.6014 - val_mae: 6.8214\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 141.2361 - mae: 8.7622 - val_loss: 64.2115 - val_mae: 6.7468\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 139.2238 - mae: 8.6723 - val_loss: 62.8820 - val_mae: 6.6736\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 137.2792 - mae: 8.5925 - val_loss: 61.5852 - val_mae: 6.6002\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 135.3715 - mae: 8.5062 - val_loss: 60.3834 - val_mae: 6.5304\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.5952 - mae: 8.4269 - val_loss: 59.2247 - val_mae: 6.4613\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.8506 - mae: 8.3461 - val_loss: 58.1039 - val_mae: 6.3926\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.1511 - mae: 8.2666 - val_loss: 57.0134 - val_mae: 6.3239\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 128.4911 - mae: 8.1880 - val_loss: 55.9799 - val_mae: 6.2569\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126.8909 - mae: 8.1130 - val_loss: 55.0081 - val_mae: 6.1922\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125.3883 - mae: 8.0392 - val_loss: 54.1015 - val_mae: 6.1301\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 123.9592 - mae: 7.9738 - val_loss: 53.2077 - val_mae: 6.0671\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 122.5259 - mae: 7.9053 - val_loss: 52.3706 - val_mae: 6.0139\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.1843 - mae: 7.8397 - val_loss: 51.5468 - val_mae: 5.9606\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119.8331 - mae: 7.7746 - val_loss: 50.7723 - val_mae: 5.9090\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118.5756 - mae: 7.7152 - val_loss: 50.0537 - val_mae: 5.8597\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117.3721 - mae: 7.6524 - val_loss: 49.3449 - val_mae: 5.8095\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.1648 - mae: 7.5937 - val_loss: 48.6699 - val_mae: 5.7603\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.0113 - mae: 7.5386 - val_loss: 48.0318 - val_mae: 5.7123\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 113.9138 - mae: 7.4830 - val_loss: 47.4122 - val_mae: 5.6642\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.8285 - mae: 7.4321 - val_loss: 46.8524 - val_mae: 5.6193\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 111.8287 - mae: 7.3842 - val_loss: 46.3049 - val_mae: 5.5751\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.8309 - mae: 7.3401 - val_loss: 45.7772 - val_mae: 5.5376\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.8615 - mae: 7.2953 - val_loss: 45.2769 - val_mae: 5.5070\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.9365 - mae: 7.2512 - val_loss: 44.8090 - val_mae: 5.4774\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.0455 - mae: 7.2096 - val_loss: 44.3519 - val_mae: 5.4474\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.1615 - mae: 7.1661 - val_loss: 43.9298 - val_mae: 5.4236\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.3397 - mae: 7.1265 - val_loss: 43.5158 - val_mae: 5.4010\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.5121 - mae: 7.0836 - val_loss: 43.1387 - val_mae: 5.3796\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.7512 - mae: 7.0452 - val_loss: 42.7808 - val_mae: 5.3598\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.0058 - mae: 7.0122 - val_loss: 42.4376 - val_mae: 5.3448\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.2872 - mae: 6.9744 - val_loss: 42.1192 - val_mae: 5.3303\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 102.6021 - mae: 6.9422 - val_loss: 41.8183 - val_mae: 5.3161\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.9331 - mae: 6.9092 - val_loss: 41.5286 - val_mae: 5.3019\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.2764 - mae: 6.8789 - val_loss: 41.2540 - val_mae: 5.2879\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.6463 - mae: 6.8470 - val_loss: 41.0022 - val_mae: 5.2745\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 100.0531 - mae: 6.8187 - val_loss: 40.7519 - val_mae: 5.2605\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.4401 - mae: 6.7856 - val_loss: 40.5243 - val_mae: 5.2472\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.8770 - mae: 6.7588 - val_loss: 40.3061 - val_mae: 5.2339\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.3172 - mae: 6.7335 - val_loss: 40.1019 - val_mae: 5.2208\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 106.8063 - mae: 7.2411\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=momentum; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 3982058586112.0000 - mae: 718313.1875 - val_loss: 139101984.0000 - val_mae: 11794.1504\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137148240.0000 - mae: 11710.8848 - val_loss: 134235424.0000 - val_mae: 11586.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132351160.0000 - mae: 11504.2559 - val_loss: 129539016.0000 - val_mae: 11381.5186\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127721792.0000 - mae: 11301.2666 - val_loss: 125006904.0000 - val_mae: 11180.6455\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123254376.0000 - mae: 11101.8613 - val_loss: 120633352.0000 - val_mae: 10983.3203\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118943240.0000 - mae: 10905.9678 - val_loss: 116412832.0000 - val_mae: 10789.4766\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114782936.0000 - mae: 10713.5459 - val_loss: 112339976.0000 - val_mae: 10599.0547\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110768168.0000 - mae: 10524.5215 - val_loss: 108409592.0000 - val_mae: 10411.9912\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106893768.0000 - mae: 10338.8164 - val_loss: 104616632.0000 - val_mae: 10228.2246\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103154848.0000 - mae: 10156.3896 - val_loss: 100956328.0000 - val_mae: 10047.7002\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99546704.0000 - mae: 9977.1826 - val_loss: 97424136.0000 - val_mae: 9870.3643\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96064816.0000 - mae: 9801.1475 - val_loss: 94015488.0000 - val_mae: 9696.1562\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92704704.0000 - mae: 9628.2100 - val_loss: 90726080.0000 - val_mae: 9525.0225\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 89462088.0000 - mae: 9458.3232 - val_loss: 87551792.0000 - val_mae: 9356.9102\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86332968.0000 - mae: 9291.4414 - val_loss: 84488512.0000 - val_mae: 9191.7617\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83313224.0000 - mae: 9127.4902 - val_loss: 81532400.0000 - val_mae: 9029.5264\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80399112.0000 - mae: 8966.4473 - val_loss: 78679648.0000 - val_mae: 8870.1523\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77586888.0000 - mae: 8808.2344 - val_loss: 75926744.0000 - val_mae: 8713.5938\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74873096.0000 - mae: 8652.8232 - val_loss: 73270120.0000 - val_mae: 8559.7949\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72254184.0000 - mae: 8500.1416 - val_loss: 70706432.0000 - val_mae: 8408.7100\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 69726880.0000 - mae: 8350.1553 - val_loss: 68232440.0000 - val_mae: 8260.2900\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67288000.0000 - mae: 8202.8252 - val_loss: 65845044.0000 - val_mae: 8114.4937\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64934456.0000 - mae: 8058.0923 - val_loss: 63541136.0000 - val_mae: 7971.2676\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62663188.0000 - mae: 7915.9087 - val_loss: 61317776.0000 - val_mae: 7830.5645\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60471324.0000 - mae: 7776.2305 - val_loss: 59172252.0000 - val_mae: 7692.3477\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58356184.0000 - mae: 7639.0244 - val_loss: 57101772.0000 - val_mae: 7556.5693\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56315028.0000 - mae: 7504.2363 - val_loss: 55103804.0000 - val_mae: 7423.1914\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54345340.0000 - mae: 7371.8369 - val_loss: 53175724.0000 - val_mae: 7292.1655\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 52444500.0000 - mae: 7241.7646 - val_loss: 51315052.0000 - val_mae: 7163.4502\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50610132.0000 - mae: 7113.9893 - val_loss: 49519484.0000 - val_mae: 7037.0054\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48839924.0000 - mae: 6988.4663 - val_loss: 47786768.0000 - val_mae: 6912.7944\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47131672.0000 - mae: 6865.1641 - val_loss: 46114588.0000 - val_mae: 6790.7695\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45483084.0000 - mae: 6744.0259 - val_loss: 44500936.0000 - val_mae: 6670.8994\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43892184.0000 - mae: 6625.0327 - val_loss: 42943724.0000 - val_mae: 6553.1436\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 42356936.0000 - mae: 6508.1396 - val_loss: 41440988.0000 - val_mae: 6437.4644\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 40875368.0000 - mae: 6393.2964 - val_loss: 39990828.0000 - val_mae: 6323.8271\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 39445636.0000 - mae: 6280.4927 - val_loss: 38591444.0000 - val_mae: 6212.1978\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38065956.0000 - mae: 6169.6797 - val_loss: 37241024.0000 - val_mae: 6102.5396\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36734528.0000 - mae: 6060.8184 - val_loss: 35937828.0000 - val_mae: 5994.8135\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35449648.0000 - mae: 5953.8838 - val_loss: 34680216.0000 - val_mae: 5888.9878\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34209696.0000 - mae: 5848.8247 - val_loss: 33466600.0000 - val_mae: 5785.0288\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33013132.0000 - mae: 5745.6250 - val_loss: 32295458.0000 - val_mae: 5682.9058\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31858422.0000 - mae: 5644.2515 - val_loss: 31165282.0000 - val_mae: 5582.5835\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30744090.0000 - mae: 5544.6621 - val_loss: 30074632.0000 - val_mae: 5484.0308\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29668728.0000 - mae: 5446.8174 - val_loss: 29022158.0000 - val_mae: 5387.2183\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28631000.0000 - mae: 5350.7207 - val_loss: 28006520.0000 - val_mae: 5292.1147\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27629584.0000 - mae: 5256.3105 - val_loss: 27026434.0000 - val_mae: 5198.6919\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26663206.0000 - mae: 5163.5713 - val_loss: 26080606.0000 - val_mae: 5106.9136\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25730574.0000 - mae: 5072.4644 - val_loss: 25167826.0000 - val_mae: 5016.7505\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24830548.0000 - mae: 4982.9595 - val_loss: 24287028.0000 - val_mae: 4928.1831\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23962062.0000 - mae: 4895.0366 - val_loss: 23437048.0000 - val_mae: 4841.1787\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23123930.0000 - mae: 4808.6660 - val_loss: 22616804.0000 - val_mae: 4755.7085\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22315118.0000 - mae: 4723.8213 - val_loss: 21825252.0000 - val_mae: 4671.7466\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21534594.0000 - mae: 4640.4702 - val_loss: 21061424.0000 - val_mae: 4589.2686\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20781392.0000 - mae: 4558.5962 - val_loss: 20324280.0000 - val_mae: 4508.2417\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20054496.0000 - mae: 4478.1606 - val_loss: 19612930.0000 - val_mae: 4428.6440\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19353026.0000 - mae: 4399.1455 - val_loss: 18926484.0000 - val_mae: 4350.4536\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18676112.0000 - mae: 4321.5239 - val_loss: 18264058.0000 - val_mae: 4273.6421\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18022876.0000 - mae: 4245.2788 - val_loss: 17624786.0000 - val_mae: 4198.1841\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17392456.0000 - mae: 4170.3638 - val_loss: 17007880.0000 - val_mae: 4124.0562\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16784098.0000 - mae: 4096.7764 - val_loss: 16412587.0000 - val_mae: 4051.2405\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16197047.0000 - mae: 4024.4927 - val_loss: 15838129.0000 - val_mae: 3979.7097\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15630529.0000 - mae: 3953.4841 - val_loss: 15283768.0000 - val_mae: 3909.4409\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15083825.0000 - mae: 3883.7283 - val_loss: 14748799.0000 - val_mae: 3840.4114\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14556237.0000 - mae: 3815.2085 - val_loss: 14232563.0000 - val_mae: 3772.6018\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14047115.0000 - mae: 3747.8928 - val_loss: 13734368.0000 - val_mae: 3705.9856\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13555779.0000 - mae: 3681.7556 - val_loss: 13253625.0000 - val_mae: 3640.5479\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13081654.0000 - mae: 3616.7996 - val_loss: 12789678.0000 - val_mae: 3576.2605\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12624077.0000 - mae: 3552.9758 - val_loss: 12341969.0000 - val_mae: 3513.1082\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12182517.0000 - mae: 3490.2917 - val_loss: 11909927.0000 - val_mae: 3451.0708\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11756404.0000 - mae: 3428.6995 - val_loss: 11493028.0000 - val_mae: 3390.1311\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11345219.0000 - mae: 3368.2139 - val_loss: 11090694.0000 - val_mae: 3330.2637\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10948388.0000 - mae: 3308.7795 - val_loss: 10702436.0000 - val_mae: 3271.4519\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10565437.0000 - mae: 3250.3987 - val_loss: 10327758.0000 - val_mae: 3213.6770\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10195876.0000 - mae: 3193.0432 - val_loss: 9966194.0000 - val_mae: 3156.9219\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9839247.0000 - mae: 3136.7117 - val_loss: 9617302.0000 - val_mae: 3101.1709\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9495108.0000 - mae: 3081.3613 - val_loss: 9280590.0000 - val_mae: 3046.3997\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9162975.0000 - mae: 3026.9805 - val_loss: 8955688.0000 - val_mae: 2992.5989\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8842497.0000 - mae: 2973.5789 - val_loss: 8642151.0000 - val_mae: 2939.7468\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8533212.0000 - mae: 2921.1091 - val_loss: 8339575.0000 - val_mae: 2887.8252\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8234741.0000 - mae: 2869.5701 - val_loss: 8047607.5000 - val_mae: 2836.8237\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7946731.0000 - mae: 2818.9458 - val_loss: 7765851.5000 - val_mae: 2786.7207\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7668779.5000 - mae: 2769.2078 - val_loss: 7493937.0000 - val_mae: 2737.4988\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7400537.0000 - mae: 2720.3391 - val_loss: 7231551.5000 - val_mae: 2689.1475\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7141695.5000 - mae: 2672.3455 - val_loss: 6978351.0000 - val_mae: 2641.6497\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6891901.5000 - mae: 2625.1929 - val_loss: 6734009.5000 - val_mae: 2594.9900\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6650847.5000 - mae: 2578.8755 - val_loss: 6498208.0000 - val_mae: 2549.1506\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6418209.0000 - mae: 2533.3713 - val_loss: 6270650.5000 - val_mae: 2504.1191\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6193704.0000 - mae: 2488.6643 - val_loss: 6051064.5000 - val_mae: 2459.8833\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5977063.0000 - mae: 2444.7502 - val_loss: 5839181.5000 - val_mae: 2416.4321\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5768016.5000 - mae: 2401.6196 - val_loss: 5634706.0000 - val_mae: 2373.7456\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5566266.0000 - mae: 2359.2427 - val_loss: 5437385.0000 - val_mae: 2331.8120\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5371574.0000 - mae: 2317.6221 - val_loss: 5246956.0000 - val_mae: 2290.6152\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5183679.0000 - mae: 2276.7224 - val_loss: 5063204.5000 - val_mae: 2250.1479\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5002374.0000 - mae: 2236.5439 - val_loss: 4885891.5000 - val_mae: 2210.3967\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4827411.0000 - mae: 2197.0901 - val_loss: 4714781.0000 - val_mae: 2171.3459\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4658563.5000 - mae: 2158.3220 - val_loss: 4549646.0000 - val_mae: 2132.9810\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4495611.0000 - mae: 2120.2319 - val_loss: 4390301.5000 - val_mae: 2095.2957\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4338371.5000 - mae: 2082.8245 - val_loss: 4236532.0000 - val_mae: 2058.2744\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4186627.7500 - mae: 2046.0773 - val_loss: 4088155.7500 - val_mae: 2021.9094\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4093174.5000 - mae: 2023.1449\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=momentum; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1200628.0000 - mae: 404.1478 - val_loss: 302.5475 - val_mae: 15.3126\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.9879 - mae: 15.1560 - val_loss: 294.4246 - val_mae: 15.0628\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.9675 - mae: 14.8920 - val_loss: 286.5857 - val_mae: 14.8174\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.2070 - mae: 14.6380 - val_loss: 279.0500 - val_mae: 14.5772\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.7585 - mae: 14.3821 - val_loss: 271.8020 - val_mae: 14.3421\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.5925 - mae: 14.1324 - val_loss: 264.8119 - val_mae: 14.1112\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.6710 - mae: 13.8913 - val_loss: 257.9988 - val_mae: 13.8821\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.9219 - mae: 13.6441 - val_loss: 251.4526 - val_mae: 13.6580\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.4552 - mae: 13.4154 - val_loss: 245.1737 - val_mae: 13.4392\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.2340 - mae: 13.1921 - val_loss: 239.0830 - val_mae: 13.2232\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.1972 - mae: 12.9759 - val_loss: 233.2048 - val_mae: 13.0109\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 238.3923 - mae: 12.7611 - val_loss: 227.5909 - val_mae: 12.8045\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.8403 - mae: 12.5567 - val_loss: 222.1400 - val_mae: 12.6005\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.4317 - mae: 12.3517 - val_loss: 216.8595 - val_mae: 12.3994\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.2044 - mae: 12.1465 - val_loss: 211.7843 - val_mae: 12.2026\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.1769 - mae: 11.9542 - val_loss: 206.8324 - val_mae: 12.0083\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.2661 - mae: 11.7563 - val_loss: 202.0937 - val_mae: 11.8330\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.5872 - mae: 11.5687 - val_loss: 197.5394 - val_mae: 11.6616\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.0770 - mae: 11.3909 - val_loss: 193.1640 - val_mae: 11.4939\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.7424 - mae: 11.2179 - val_loss: 188.9106 - val_mae: 11.3280\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.5245 - mae: 11.0480 - val_loss: 184.8222 - val_mae: 11.1657\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.4760 - mae: 10.8837 - val_loss: 180.8662 - val_mae: 11.0058\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.5503 - mae: 10.7217 - val_loss: 177.0212 - val_mae: 10.8476\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.7287 - mae: 10.5597 - val_loss: 173.2773 - val_mae: 10.6907\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.0146 - mae: 10.4017 - val_loss: 169.6734 - val_mae: 10.5370\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.4439 - mae: 10.2529 - val_loss: 166.2106 - val_mae: 10.3865\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.0173 - mae: 10.1075 - val_loss: 162.8862 - val_mae: 10.2395\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 168.7279 - mae: 9.9680 - val_loss: 159.6544 - val_mae: 10.0940\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.5152 - mae: 9.8287 - val_loss: 156.5619 - val_mae: 9.9522\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.4558 - mae: 9.6963 - val_loss: 153.5622 - val_mae: 9.8192\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.4787 - mae: 9.5640 - val_loss: 150.6649 - val_mae: 9.6935\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.5988 - mae: 9.4377 - val_loss: 147.8606 - val_mae: 9.5695\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.8238 - mae: 9.3109 - val_loss: 145.2071 - val_mae: 9.4502\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 151.2048 - mae: 9.1951 - val_loss: 142.6354 - val_mae: 9.3324\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.6377 - mae: 9.0884 - val_loss: 140.1258 - val_mae: 9.2154\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 146.1529 - mae: 8.9856 - val_loss: 137.7618 - val_mae: 9.1032\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.8292 - mae: 8.8840 - val_loss: 135.4890 - val_mae: 8.9935\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 141.5695 - mae: 8.7958 - val_loss: 133.2910 - val_mae: 8.8924\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.3849 - mae: 8.7040 - val_loss: 131.1413 - val_mae: 8.7951\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.2328 - mae: 8.6131 - val_loss: 129.0561 - val_mae: 8.6990\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.1678 - mae: 8.5301 - val_loss: 127.0552 - val_mae: 8.6052\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.1760 - mae: 8.4501 - val_loss: 125.0524 - val_mae: 8.5095\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1697 - mae: 8.3680 - val_loss: 123.1583 - val_mae: 8.4174\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.3083 - mae: 8.2905 - val_loss: 121.3632 - val_mae: 8.3285\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.5203 - mae: 8.2192 - val_loss: 119.5987 - val_mae: 8.2395\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125.7619 - mae: 8.1459 - val_loss: 117.9197 - val_mae: 8.1533\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.1071 - mae: 8.0815 - val_loss: 116.3207 - val_mae: 8.0697\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.5168 - mae: 8.0212 - val_loss: 114.7662 - val_mae: 7.9870\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.9659 - mae: 7.9584 - val_loss: 113.2531 - val_mae: 7.9051\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4611 - mae: 7.9017 - val_loss: 111.7954 - val_mae: 7.8247\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.0136 - mae: 7.8459 - val_loss: 110.4018 - val_mae: 7.7465\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.6338 - mae: 7.7922 - val_loss: 109.0461 - val_mae: 7.6690\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2723 - mae: 7.7408 - val_loss: 107.7183 - val_mae: 7.5918\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9484 - mae: 7.6889 - val_loss: 106.4365 - val_mae: 7.5159\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6757 - mae: 7.6388 - val_loss: 105.2148 - val_mae: 7.4422\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.4682 - mae: 7.5914 - val_loss: 104.0472 - val_mae: 7.3705\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3023 - mae: 7.5457 - val_loss: 102.8999 - val_mae: 7.2988\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1526 - mae: 7.5006 - val_loss: 101.7902 - val_mae: 7.2326\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0518 - mae: 7.4584 - val_loss: 100.7053 - val_mae: 7.1696\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9713 - mae: 7.4136 - val_loss: 99.6937 - val_mae: 7.1099\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9677 - mae: 7.3728 - val_loss: 98.6922 - val_mae: 7.0496\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9610 - mae: 7.3329 - val_loss: 97.7357 - val_mae: 6.9911\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0170 - mae: 7.2956 - val_loss: 96.8345 - val_mae: 6.9349\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1228 - mae: 7.2600 - val_loss: 95.9559 - val_mae: 6.8791\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2428 - mae: 7.2215 - val_loss: 95.1144 - val_mae: 6.8253\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4058 - mae: 7.1880 - val_loss: 94.2741 - val_mae: 6.7765\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5592 - mae: 7.1537 - val_loss: 93.4685 - val_mae: 6.7289\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7632 - mae: 7.1177 - val_loss: 92.7180 - val_mae: 6.6884\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0148 - mae: 7.0899 - val_loss: 91.9561 - val_mae: 6.6479\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2466 - mae: 7.0563 - val_loss: 91.2477 - val_mae: 6.6115\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5441 - mae: 7.0251 - val_loss: 90.5592 - val_mae: 6.5794\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8524 - mae: 6.9944 - val_loss: 89.8973 - val_mae: 6.5480\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2003 - mae: 6.9654 - val_loss: 89.2660 - val_mae: 6.5175\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5660 - mae: 6.9373 - val_loss: 88.6497 - val_mae: 6.4872\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9478 - mae: 6.9083 - val_loss: 88.0539 - val_mae: 6.4578\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3502 - mae: 6.8827 - val_loss: 87.4734 - val_mae: 6.4335\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7728 - mae: 6.8551 - val_loss: 86.9171 - val_mae: 6.4099\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.2154 - mae: 6.8310 - val_loss: 86.3677 - val_mae: 6.3876\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6704 - mae: 6.8054 - val_loss: 85.8719 - val_mae: 6.3706\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1771 - mae: 6.7840 - val_loss: 85.3914 - val_mae: 6.3539\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6913 - mae: 6.7618 - val_loss: 84.8871 - val_mae: 6.3360\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1770 - mae: 6.7384 - val_loss: 84.4042 - val_mae: 6.3185\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6967 - mae: 6.7163 - val_loss: 83.9323 - val_mae: 6.3011\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2195 - mae: 6.6941 - val_loss: 83.4921 - val_mae: 6.2846\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7882 - mae: 6.6756 - val_loss: 83.0842 - val_mae: 6.2690\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3811 - mae: 6.6584 - val_loss: 82.6898 - val_mae: 6.2563\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.9842 - mae: 6.6416 - val_loss: 82.3120 - val_mae: 6.2456\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6025 - mae: 6.6243 - val_loss: 81.9434 - val_mae: 6.2350\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2325 - mae: 6.6093 - val_loss: 81.5863 - val_mae: 6.2245\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.8809 - mae: 6.5938 - val_loss: 81.2463 - val_mae: 6.2144\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5324 - mae: 6.5776 - val_loss: 80.9025 - val_mae: 6.2039\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1820 - mae: 6.5630 - val_loss: 80.5538 - val_mae: 6.1931\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8296 - mae: 6.5461 - val_loss: 80.2338 - val_mae: 6.1830\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.5190 - mae: 6.5332 - val_loss: 79.9426 - val_mae: 6.1737\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2266 - mae: 6.5215 - val_loss: 79.6455 - val_mae: 6.1639\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9247 - mae: 6.5074 - val_loss: 79.3746 - val_mae: 6.1549\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6539 - mae: 6.4963 - val_loss: 79.1056 - val_mae: 6.1482\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3818 - mae: 6.4830 - val_loss: 78.8408 - val_mae: 6.1427\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1172 - mae: 6.4719 - val_loss: 78.5856 - val_mae: 6.1373\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8610 - mae: 6.4607 - val_loss: 78.3490 - val_mae: 6.1322\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 115.0396 - mae: 7.1999\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=momentum; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 119622.8281 - mae: 342.5135 - val_loss: 111378.9375 - val_mae: 330.1738\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119572.2812 - mae: 342.4407 - val_loss: 111330.0859 - val_mae: 330.1007\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 119521.6172 - mae: 342.3676 - val_loss: 111281.3047 - val_mae: 330.0276\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119470.9922 - mae: 342.2946 - val_loss: 111232.5625 - val_mae: 329.9547\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119420.7812 - mae: 342.2220 - val_loss: 111183.7500 - val_mae: 329.8816\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119369.8906 - mae: 342.1487 - val_loss: 111135.1094 - val_mae: 329.8087\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 119319.6016 - mae: 342.0760 - val_loss: 111086.3125 - val_mae: 329.7356\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119268.6016 - mae: 342.0030 - val_loss: 111037.8672 - val_mae: 329.6630\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119218.5469 - mae: 341.9303 - val_loss: 110989.1094 - val_mae: 329.5899\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119167.9766 - mae: 341.8574 - val_loss: 110940.5469 - val_mae: 329.5171\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119117.8125 - mae: 341.7849 - val_loss: 110891.8828 - val_mae: 329.4441\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119067.2344 - mae: 341.7120 - val_loss: 110843.5391 - val_mae: 329.3715\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119016.8125 - mae: 341.6392 - val_loss: 110795.1328 - val_mae: 329.2990\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118966.6875 - mae: 341.5670 - val_loss: 110746.5156 - val_mae: 329.2260\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118915.9609 - mae: 341.4937 - val_loss: 110698.0859 - val_mae: 329.1533\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118865.4766 - mae: 341.4208 - val_loss: 110649.4453 - val_mae: 329.0802\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118815.2422 - mae: 341.3482 - val_loss: 110600.6797 - val_mae: 329.0070\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118764.9609 - mae: 341.2753 - val_loss: 110552.0156 - val_mae: 328.9339\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 118714.3750 - mae: 341.2022 - val_loss: 110503.7969 - val_mae: 328.8615\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118664.1172 - mae: 341.1297 - val_loss: 110455.5938 - val_mae: 328.7890\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118613.8438 - mae: 341.0571 - val_loss: 110407.1953 - val_mae: 328.7162\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118563.7266 - mae: 340.9843 - val_loss: 110358.5547 - val_mae: 328.6431\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118513.6250 - mae: 340.9116 - val_loss: 110309.8906 - val_mae: 328.5699\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118463.0156 - mae: 340.8386 - val_loss: 110261.5703 - val_mae: 328.4973\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 118412.8906 - mae: 340.7660 - val_loss: 110213.3125 - val_mae: 328.4246\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118362.7734 - mae: 340.6933 - val_loss: 110165.0312 - val_mae: 328.3520\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118312.5312 - mae: 340.6207 - val_loss: 110116.6953 - val_mae: 328.2792\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118262.3438 - mae: 340.5481 - val_loss: 110068.4531 - val_mae: 328.2066\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 118212.7500 - mae: 340.4756 - val_loss: 110019.7812 - val_mae: 328.1333\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118161.7422 - mae: 340.4022 - val_loss: 109971.7031 - val_mae: 328.0609\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118111.8906 - mae: 340.3298 - val_loss: 109923.4062 - val_mae: 327.9881\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118061.8516 - mae: 340.2571 - val_loss: 109874.8984 - val_mae: 327.9150\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118011.9375 - mae: 340.1844 - val_loss: 109826.3438 - val_mae: 327.8418\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 117961.2422 - mae: 340.1113 - val_loss: 109778.4609 - val_mae: 327.7697\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117911.3359 - mae: 340.0391 - val_loss: 109730.5391 - val_mae: 327.6974\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117861.4688 - mae: 339.9663 - val_loss: 109682.3672 - val_mae: 327.6248\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117811.8750 - mae: 339.8940 - val_loss: 109633.5938 - val_mae: 327.5512\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117760.9688 - mae: 339.8207 - val_loss: 109585.4688 - val_mae: 327.4785\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117711.3359 - mae: 339.7483 - val_loss: 109537.0938 - val_mae: 327.4055\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117661.0000 - mae: 339.6754 - val_loss: 109489.0312 - val_mae: 327.3329\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117611.0781 - mae: 339.6027 - val_loss: 109440.9297 - val_mae: 327.2603\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117560.8672 - mae: 339.5300 - val_loss: 109393.0703 - val_mae: 327.1880\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117511.0078 - mae: 339.4576 - val_loss: 109345.1953 - val_mae: 327.1158\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117461.4688 - mae: 339.3856 - val_loss: 109296.9375 - val_mae: 327.0428\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117411.1719 - mae: 339.3125 - val_loss: 109249.0391 - val_mae: 326.9703\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117361.7109 - mae: 339.2403 - val_loss: 109200.8906 - val_mae: 326.8976\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117312.0078 - mae: 339.1677 - val_loss: 109152.7109 - val_mae: 326.8248\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117261.6719 - mae: 339.0949 - val_loss: 109105.0391 - val_mae: 326.7527\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 117212.2578 - mae: 339.0228 - val_loss: 109057.1875 - val_mae: 326.6802\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117162.4688 - mae: 338.9505 - val_loss: 109009.2812 - val_mae: 326.6078\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117112.6797 - mae: 338.8780 - val_loss: 108961.4844 - val_mae: 326.5354\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117063.1250 - mae: 338.8057 - val_loss: 108913.4062 - val_mae: 326.4627\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117013.2734 - mae: 338.7329 - val_loss: 108865.4922 - val_mae: 326.3901\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116963.3750 - mae: 338.6604 - val_loss: 108817.5625 - val_mae: 326.3175\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116913.8906 - mae: 338.5880 - val_loss: 108769.4062 - val_mae: 326.2446\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116863.6562 - mae: 338.5150 - val_loss: 108721.6797 - val_mae: 326.1722\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116814.2344 - mae: 338.4427 - val_loss: 108673.6797 - val_mae: 326.0995\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 116764.2266 - mae: 338.3703 - val_loss: 108625.8984 - val_mae: 326.0271\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116714.3125 - mae: 338.2975 - val_loss: 108578.1641 - val_mae: 325.9547\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116665.3672 - mae: 338.2254 - val_loss: 108529.7656 - val_mae: 325.8813\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116614.8516 - mae: 338.1521 - val_loss: 108482.1328 - val_mae: 325.8090\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116565.3984 - mae: 338.0798 - val_loss: 108434.3438 - val_mae: 325.7365\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 116515.6562 - mae: 338.0073 - val_loss: 108386.5078 - val_mae: 325.6639\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116465.9375 - mae: 337.9348 - val_loss: 108338.7188 - val_mae: 325.5914\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116416.3672 - mae: 337.8622 - val_loss: 108290.7812 - val_mae: 325.5186\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116366.6172 - mae: 337.7897 - val_loss: 108242.8828 - val_mae: 325.4459\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116317.0938 - mae: 337.7170 - val_loss: 108194.8203 - val_mae: 325.3728\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116267.0625 - mae: 337.6443 - val_loss: 108147.1016 - val_mae: 325.3004\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116218.0312 - mae: 337.5718 - val_loss: 108099.0625 - val_mae: 325.2273\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116167.8203 - mae: 337.4989 - val_loss: 108051.5078 - val_mae: 325.1550\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116118.2734 - mae: 337.4264 - val_loss: 108004.0156 - val_mae: 325.0828\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116068.8672 - mae: 337.3544 - val_loss: 107956.1797 - val_mae: 325.0101\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116019.3516 - mae: 337.2817 - val_loss: 107908.5000 - val_mae: 324.9376\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115969.5547 - mae: 337.2092 - val_loss: 107860.9141 - val_mae: 324.8652\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115920.5625 - mae: 337.1370 - val_loss: 107813.0078 - val_mae: 324.7922\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115870.6797 - mae: 337.0642 - val_loss: 107765.5078 - val_mae: 324.7200\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115821.0938 - mae: 336.9917 - val_loss: 107717.9688 - val_mae: 324.6476\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115771.8672 - mae: 336.9193 - val_loss: 107670.2031 - val_mae: 324.5749\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115722.2422 - mae: 336.8468 - val_loss: 107622.5391 - val_mae: 324.5022\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115672.8047 - mae: 336.7741 - val_loss: 107574.7812 - val_mae: 324.4295\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115623.3047 - mae: 336.7016 - val_loss: 107527.1641 - val_mae: 324.3569\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115573.7422 - mae: 336.6292 - val_loss: 107479.7188 - val_mae: 324.2846\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115524.7500 - mae: 336.5569 - val_loss: 107431.9922 - val_mae: 324.2119\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115475.1250 - mae: 336.4843 - val_loss: 107384.6328 - val_mae: 324.1396\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115425.9922 - mae: 336.4121 - val_loss: 107337.2031 - val_mae: 324.0672\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115376.5859 - mae: 336.3398 - val_loss: 107289.8906 - val_mae: 323.9951\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115327.2812 - mae: 336.2675 - val_loss: 107242.6094 - val_mae: 323.9229\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115278.4453 - mae: 336.1958 - val_loss: 107194.9844 - val_mae: 323.8503\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115229.1016 - mae: 336.1232 - val_loss: 107147.4531 - val_mae: 323.7777\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115179.7188 - mae: 336.0508 - val_loss: 107100.2812 - val_mae: 323.7056\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115130.8125 - mae: 335.9789 - val_loss: 107052.8359 - val_mae: 323.6332\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115081.1406 - mae: 335.9062 - val_loss: 107005.8203 - val_mae: 323.5613\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115032.0469 - mae: 335.8342 - val_loss: 106958.5000 - val_mae: 323.4890\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114983.0234 - mae: 335.7620 - val_loss: 106911.1172 - val_mae: 323.4166\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114934.1016 - mae: 335.6896 - val_loss: 106863.5469 - val_mae: 323.3439\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114884.5312 - mae: 335.6170 - val_loss: 106816.3125 - val_mae: 323.2716\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114835.6016 - mae: 335.5450 - val_loss: 106768.7656 - val_mae: 323.1989\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 114786.4453 - mae: 335.4721 - val_loss: 106721.1953 - val_mae: 323.1262\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114736.8203 - mae: 335.3997 - val_loss: 106673.9844 - val_mae: 323.0539\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114687.8750 - mae: 335.3275 - val_loss: 106626.7109 - val_mae: 322.9816\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 108942.9062 - mae: 324.9540\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 58379.4531 - mae: 237.7702 - val_loss: 57090.1484 - val_mae: 235.6584\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58344.7891 - mae: 237.6980 - val_loss: 57055.5547 - val_mae: 235.5854\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58310.2148 - mae: 237.6259 - val_loss: 57020.9570 - val_mae: 235.5122\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58275.7656 - mae: 237.5536 - val_loss: 56986.3984 - val_mae: 235.4391\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58240.9453 - mae: 237.4814 - val_loss: 56952.0273 - val_mae: 235.3665\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58206.4492 - mae: 237.4093 - val_loss: 56917.6289 - val_mae: 235.2937\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58171.8477 - mae: 237.3373 - val_loss: 56883.2344 - val_mae: 235.2209\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58137.3047 - mae: 237.2656 - val_loss: 56848.8438 - val_mae: 235.1481\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58102.7852 - mae: 237.1933 - val_loss: 56814.4453 - val_mae: 235.0752\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58068.4531 - mae: 237.1214 - val_loss: 56779.9844 - val_mae: 235.0022\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58033.9492 - mae: 237.0492 - val_loss: 56745.5469 - val_mae: 234.9292\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57999.3555 - mae: 236.9771 - val_loss: 56711.3047 - val_mae: 234.8566\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57964.9062 - mae: 236.9051 - val_loss: 56676.9766 - val_mae: 234.7838\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57930.6133 - mae: 236.8336 - val_loss: 56642.5312 - val_mae: 234.7108\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57896.1094 - mae: 236.7614 - val_loss: 56608.2227 - val_mae: 234.6380\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57861.5039 - mae: 236.6891 - val_loss: 56573.9844 - val_mae: 234.5653\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57827.2383 - mae: 236.6174 - val_loss: 56539.6680 - val_mae: 234.4924\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57793.0859 - mae: 236.5453 - val_loss: 56505.2070 - val_mae: 234.4192\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57758.3633 - mae: 236.4732 - val_loss: 56471.1328 - val_mae: 234.3469\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57724.0234 - mae: 236.4013 - val_loss: 56437.0156 - val_mae: 234.2743\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57689.7422 - mae: 236.3295 - val_loss: 56402.6914 - val_mae: 234.2014\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57655.5195 - mae: 236.2573 - val_loss: 56368.1836 - val_mae: 234.1280\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57620.9062 - mae: 236.1849 - val_loss: 56333.8750 - val_mae: 234.0550\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57586.4609 - mae: 236.1129 - val_loss: 56299.7031 - val_mae: 233.9823\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57552.4414 - mae: 236.0409 - val_loss: 56265.3906 - val_mae: 233.9092\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57518.0234 - mae: 235.9688 - val_loss: 56231.2148 - val_mae: 233.8364\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57483.6445 - mae: 235.8968 - val_loss: 56197.1719 - val_mae: 233.7640\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57449.5586 - mae: 235.8254 - val_loss: 56163.0664 - val_mae: 233.6913\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57415.5469 - mae: 235.7534 - val_loss: 56128.8789 - val_mae: 233.6184\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57381.4609 - mae: 235.6816 - val_loss: 56094.7227 - val_mae: 233.5456\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57346.9570 - mae: 235.6095 - val_loss: 56060.8906 - val_mae: 233.4734\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57313.0703 - mae: 235.5381 - val_loss: 56026.8711 - val_mae: 233.4008\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57279.0781 - mae: 235.4663 - val_loss: 55992.8477 - val_mae: 233.3282\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57244.8555 - mae: 235.3945 - val_loss: 55959.0547 - val_mae: 233.2561\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57210.9102 - mae: 235.3235 - val_loss: 55925.2148 - val_mae: 233.1838\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57176.9102 - mae: 235.2516 - val_loss: 55891.3281 - val_mae: 233.1114\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57143.0078 - mae: 235.1802 - val_loss: 55857.1953 - val_mae: 233.0385\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57108.8555 - mae: 235.1081 - val_loss: 55823.2578 - val_mae: 232.9660\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57075.0234 - mae: 235.0366 - val_loss: 55789.2773 - val_mae: 232.8933\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57040.8281 - mae: 234.9647 - val_loss: 55755.4766 - val_mae: 232.8210\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57006.6484 - mae: 234.8931 - val_loss: 55721.8164 - val_mae: 232.7490\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56972.8828 - mae: 234.8217 - val_loss: 55687.9297 - val_mae: 232.6765\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56938.7695 - mae: 234.7499 - val_loss: 55654.0781 - val_mae: 232.6040\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56904.9180 - mae: 234.6785 - val_loss: 55620.0781 - val_mae: 232.5311\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56870.7695 - mae: 234.6062 - val_loss: 55586.2500 - val_mae: 232.4587\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56837.0156 - mae: 234.5347 - val_loss: 55552.2812 - val_mae: 232.3859\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56803.0977 - mae: 234.4626 - val_loss: 55518.3008 - val_mae: 232.3131\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56768.8984 - mae: 234.3910 - val_loss: 55484.6562 - val_mae: 232.2409\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56735.3047 - mae: 234.3197 - val_loss: 55450.8594 - val_mae: 232.1684\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56701.2305 - mae: 234.2480 - val_loss: 55417.2188 - val_mae: 232.0962\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56667.3906 - mae: 234.1763 - val_loss: 55383.4727 - val_mae: 232.0238\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56633.6133 - mae: 234.1046 - val_loss: 55349.6016 - val_mae: 231.9510\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56599.5195 - mae: 234.0327 - val_loss: 55315.9453 - val_mae: 231.8787\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56565.6289 - mae: 233.9612 - val_loss: 55282.2461 - val_mae: 231.8063\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56532.0000 - mae: 233.8896 - val_loss: 55248.4453 - val_mae: 231.7337\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56498.3281 - mae: 233.8180 - val_loss: 55214.6445 - val_mae: 231.6610\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56464.3555 - mae: 233.7463 - val_loss: 55181.0312 - val_mae: 231.5887\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56430.7148 - mae: 233.6748 - val_loss: 55147.3281 - val_mae: 231.5162\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56396.6602 - mae: 233.6030 - val_loss: 55113.7852 - val_mae: 231.4440\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56363.2695 - mae: 233.5316 - val_loss: 55079.9648 - val_mae: 231.3712\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56329.1758 - mae: 233.4595 - val_loss: 55046.4492 - val_mae: 231.2990\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56295.5977 - mae: 233.3884 - val_loss: 55012.9180 - val_mae: 231.2268\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56261.7852 - mae: 233.3168 - val_loss: 54979.4805 - val_mae: 231.1548\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56228.2578 - mae: 233.2453 - val_loss: 54945.9023 - val_mae: 231.0824\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56194.7070 - mae: 233.1739 - val_loss: 54912.1914 - val_mae: 231.0097\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56160.9805 - mae: 233.1025 - val_loss: 54878.6953 - val_mae: 230.9374\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56127.3906 - mae: 233.0306 - val_loss: 54845.2031 - val_mae: 230.8652\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56093.8750 - mae: 232.9595 - val_loss: 54811.6211 - val_mae: 230.7927\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56060.3047 - mae: 232.8877 - val_loss: 54778.0430 - val_mae: 230.7202\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56026.4883 - mae: 232.8162 - val_loss: 54744.6953 - val_mae: 230.6482\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55993.1250 - mae: 232.7449 - val_loss: 54711.2422 - val_mae: 230.5759\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55959.3594 - mae: 232.6737 - val_loss: 54677.9219 - val_mae: 230.5039\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55925.9102 - mae: 232.6021 - val_loss: 54644.5352 - val_mae: 230.4317\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55892.2227 - mae: 232.5306 - val_loss: 54611.2188 - val_mae: 230.3597\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55859.0156 - mae: 232.4593 - val_loss: 54577.5742 - val_mae: 230.2869\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55825.1914 - mae: 232.3876 - val_loss: 54544.2188 - val_mae: 230.2147\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55791.8320 - mae: 232.3165 - val_loss: 54510.8789 - val_mae: 230.1426\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55758.3008 - mae: 232.2447 - val_loss: 54477.5664 - val_mae: 230.0704\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55725.0000 - mae: 232.1736 - val_loss: 54444.0430 - val_mae: 229.9978\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55691.5508 - mae: 232.1019 - val_loss: 54410.5469 - val_mae: 229.9252\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55657.8594 - mae: 232.0303 - val_loss: 54377.3164 - val_mae: 229.8532\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55624.4492 - mae: 231.9590 - val_loss: 54344.1406 - val_mae: 229.7813\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55591.2148 - mae: 231.8878 - val_loss: 54310.8789 - val_mae: 229.7091\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55557.8516 - mae: 231.8164 - val_loss: 54277.7930 - val_mae: 229.6373\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55524.7383 - mae: 231.7456 - val_loss: 54244.5508 - val_mae: 229.5652\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55491.6133 - mae: 231.6745 - val_loss: 54211.3711 - val_mae: 229.4932\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55457.9570 - mae: 231.6032 - val_loss: 54178.3789 - val_mae: 229.4215\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55424.8320 - mae: 231.5321 - val_loss: 54145.1953 - val_mae: 229.3494\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55391.4062 - mae: 231.4610 - val_loss: 54112.1172 - val_mae: 229.2775\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55358.3320 - mae: 231.3897 - val_loss: 54078.8711 - val_mae: 229.2053\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55325.1875 - mae: 231.3186 - val_loss: 54045.4648 - val_mae: 229.1326\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55291.4375 - mae: 231.2465 - val_loss: 54012.5703 - val_mae: 229.0611\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55258.2266 - mae: 231.1759 - val_loss: 53979.5781 - val_mae: 228.9893\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55225.4414 - mae: 231.1045 - val_loss: 53946.2188 - val_mae: 228.9167\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55192.0234 - mae: 231.0329 - val_loss: 53913.1602 - val_mae: 228.8447\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55158.7852 - mae: 230.9620 - val_loss: 53880.2461 - val_mae: 228.7730\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55125.5469 - mae: 230.8908 - val_loss: 53847.3164 - val_mae: 228.7013\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55092.7930 - mae: 230.8198 - val_loss: 53813.9922 - val_mae: 228.6286\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55059.2148 - mae: 230.7481 - val_loss: 53781.0039 - val_mae: 228.5567\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55026.2734 - mae: 230.6771 - val_loss: 53747.8438 - val_mae: 228.4844\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 54753.0273 - mae: 230.5184\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=adam; total time=   3.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 40175.2344 - mae: 192.3785 - val_loss: 39592.8320 - val_mae: 192.2960\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40150.1523 - mae: 192.3190 - val_loss: 39565.4336 - val_mae: 192.2218\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40125.3008 - mae: 192.2607 - val_loss: 39537.9688 - val_mae: 192.1474\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40100.0820 - mae: 192.2002 - val_loss: 39510.5664 - val_mae: 192.0732\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40075.0039 - mae: 192.1411 - val_loss: 39483.2422 - val_mae: 191.9991\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40050.1641 - mae: 192.0813 - val_loss: 39455.8438 - val_mae: 191.9249\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40025.3984 - mae: 192.0232 - val_loss: 39428.4219 - val_mae: 191.8505\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40000.1602 - mae: 191.9630 - val_loss: 39401.2734 - val_mae: 191.7768\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39975.5234 - mae: 191.9050 - val_loss: 39373.8242 - val_mae: 191.7023\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39950.4492 - mae: 191.8450 - val_loss: 39346.6445 - val_mae: 191.6285\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39925.8789 - mae: 191.7868 - val_loss: 39319.1289 - val_mae: 191.5537\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39900.7773 - mae: 191.7272 - val_loss: 39291.8711 - val_mae: 191.4796\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39876.0352 - mae: 191.6685 - val_loss: 39264.5977 - val_mae: 191.4054\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39851.1875 - mae: 191.6090 - val_loss: 39237.3672 - val_mae: 191.3313\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39826.4570 - mae: 191.5495 - val_loss: 39210.1289 - val_mae: 191.2572\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39801.5664 - mae: 191.4907 - val_loss: 39183.0078 - val_mae: 191.1834\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39776.5312 - mae: 191.4303 - val_loss: 39155.9727 - val_mae: 191.1098\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39752.1328 - mae: 191.3729 - val_loss: 39128.5898 - val_mae: 191.0351\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39727.5039 - mae: 191.3147 - val_loss: 39101.3984 - val_mae: 190.9610\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39702.3984 - mae: 191.2534 - val_loss: 39074.7539 - val_mae: 190.8884\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39678.4648 - mae: 191.1974 - val_loss: 39047.4219 - val_mae: 190.8138\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39653.2266 - mae: 191.1360 - val_loss: 39020.5898 - val_mae: 190.7405\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39628.7578 - mae: 191.0773 - val_loss: 38993.6328 - val_mae: 190.6670\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39604.2578 - mae: 191.0192 - val_loss: 38966.4492 - val_mae: 190.5927\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39579.3750 - mae: 190.9591 - val_loss: 38939.4531 - val_mae: 190.5190\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39554.8203 - mae: 190.9001 - val_loss: 38912.2969 - val_mae: 190.4447\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39529.8750 - mae: 190.8407 - val_loss: 38885.5742 - val_mae: 190.3716\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39505.8359 - mae: 190.7836 - val_loss: 38858.4688 - val_mae: 190.2975\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39481.0781 - mae: 190.7241 - val_loss: 38831.3789 - val_mae: 190.2233\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39456.1758 - mae: 190.6634 - val_loss: 38804.5156 - val_mae: 190.1498\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39431.9844 - mae: 190.6062 - val_loss: 38777.3672 - val_mae: 190.0754\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39407.2305 - mae: 190.5471 - val_loss: 38750.4336 - val_mae: 190.0016\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39382.7227 - mae: 190.4877 - val_loss: 38723.6016 - val_mae: 189.9280\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 39358.0547 - mae: 190.4279 - val_loss: 38696.9336 - val_mae: 189.8549\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39333.7969 - mae: 190.3694 - val_loss: 38670.0664 - val_mae: 189.7811\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39309.4883 - mae: 190.3117 - val_loss: 38642.9922 - val_mae: 189.7068\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39284.7969 - mae: 190.2514 - val_loss: 38616.2422 - val_mae: 189.6333\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39260.5352 - mae: 190.1934 - val_loss: 38589.3711 - val_mae: 189.5595\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39236.1484 - mae: 190.1355 - val_loss: 38562.5586 - val_mae: 189.4857\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39211.6211 - mae: 190.0763 - val_loss: 38535.9570 - val_mae: 189.4126\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39187.3242 - mae: 190.0173 - val_loss: 38509.2969 - val_mae: 189.3393\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39163.0039 - mae: 189.9585 - val_loss: 38482.5508 - val_mae: 189.2656\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39138.4766 - mae: 189.8990 - val_loss: 38455.9102 - val_mae: 189.1923\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39114.1055 - mae: 189.8402 - val_loss: 38429.2773 - val_mae: 189.1190\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39089.8320 - mae: 189.7816 - val_loss: 38402.4961 - val_mae: 189.0451\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39065.5508 - mae: 189.7226 - val_loss: 38375.6758 - val_mae: 188.9712\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39041.0195 - mae: 189.6630 - val_loss: 38349.1328 - val_mae: 188.8980\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39016.8867 - mae: 189.6054 - val_loss: 38322.4648 - val_mae: 188.8244\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38992.7773 - mae: 189.5484 - val_loss: 38295.6172 - val_mae: 188.7502\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38968.4766 - mae: 189.4884 - val_loss: 38269.0039 - val_mae: 188.6767\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38944.2031 - mae: 189.4295 - val_loss: 38242.4961 - val_mae: 188.6035\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38919.8984 - mae: 189.3707 - val_loss: 38216.0156 - val_mae: 188.5303\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38895.9727 - mae: 189.3135 - val_loss: 38189.3438 - val_mae: 188.4565\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38871.6680 - mae: 189.2540 - val_loss: 38163.0195 - val_mae: 188.3837\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38847.5039 - mae: 189.1947 - val_loss: 38136.7734 - val_mae: 188.3112\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38823.2969 - mae: 189.1356 - val_loss: 38110.4922 - val_mae: 188.2384\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38799.3594 - mae: 189.0785 - val_loss: 38083.9180 - val_mae: 188.1648\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38775.1055 - mae: 189.0199 - val_loss: 38057.2773 - val_mae: 188.0910\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38750.8047 - mae: 188.9604 - val_loss: 38030.7344 - val_mae: 188.0174\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38726.7812 - mae: 188.9021 - val_loss: 38004.0820 - val_mae: 187.9435\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38702.3789 - mae: 188.8427 - val_loss: 37977.7266 - val_mae: 187.8704\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38678.5742 - mae: 188.7850 - val_loss: 37950.9961 - val_mae: 187.7962\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38654.3125 - mae: 188.7260 - val_loss: 37924.5430 - val_mae: 187.7228\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38630.1836 - mae: 188.6677 - val_loss: 37898.1797 - val_mae: 187.6495\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38606.0352 - mae: 188.6078 - val_loss: 37871.9883 - val_mae: 187.5768\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38582.2148 - mae: 188.5501 - val_loss: 37845.7188 - val_mae: 187.5038\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38558.3672 - mae: 188.4924 - val_loss: 37819.2422 - val_mae: 187.4301\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38534.2148 - mae: 188.4330 - val_loss: 37792.9805 - val_mae: 187.3570\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38510.2461 - mae: 188.3750 - val_loss: 37766.6094 - val_mae: 187.2836\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38486.0781 - mae: 188.3157 - val_loss: 37740.2422 - val_mae: 187.2102\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38462.1758 - mae: 188.2572 - val_loss: 37713.8672 - val_mae: 187.1367\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38438.0781 - mae: 188.1983 - val_loss: 37687.6328 - val_mae: 187.0636\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38414.4023 - mae: 188.1408 - val_loss: 37661.2266 - val_mae: 186.9899\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38390.2969 - mae: 188.0815 - val_loss: 37635.2227 - val_mae: 186.9174\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38366.4023 - mae: 188.0229 - val_loss: 37609.1172 - val_mae: 186.8446\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38342.9844 - mae: 187.9662 - val_loss: 37582.5938 - val_mae: 186.7705\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38318.8789 - mae: 187.9065 - val_loss: 37556.4375 - val_mae: 186.6975\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38294.9375 - mae: 187.8478 - val_loss: 37530.3750 - val_mae: 186.6246\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38271.3672 - mae: 187.7898 - val_loss: 37504.1484 - val_mae: 186.5514\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38247.3984 - mae: 187.7318 - val_loss: 37478.1797 - val_mae: 186.4787\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38223.4492 - mae: 187.6734 - val_loss: 37452.2812 - val_mae: 186.4062\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38200.0234 - mae: 187.6156 - val_loss: 37425.9414 - val_mae: 186.3325\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38176.0039 - mae: 187.5567 - val_loss: 37399.8984 - val_mae: 186.2596\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38151.9883 - mae: 187.4968 - val_loss: 37373.8984 - val_mae: 186.1868\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38128.3867 - mae: 187.4389 - val_loss: 37347.6758 - val_mae: 186.1133\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38104.4961 - mae: 187.3798 - val_loss: 37321.5117 - val_mae: 186.0400\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38080.9102 - mae: 187.3231 - val_loss: 37295.1289 - val_mae: 185.9659\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38056.9805 - mae: 187.2637 - val_loss: 37269.0820 - val_mae: 185.8929\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38033.1016 - mae: 187.2046 - val_loss: 37243.1836 - val_mae: 185.8201\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38009.6914 - mae: 187.1476 - val_loss: 37217.2852 - val_mae: 185.7475\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37986.0039 - mae: 187.0888 - val_loss: 37191.7070 - val_mae: 185.6756\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37962.4570 - mae: 187.0309 - val_loss: 37165.9258 - val_mae: 185.6031\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37938.9531 - mae: 186.9733 - val_loss: 37139.8906 - val_mae: 185.5299\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37915.3633 - mae: 186.9145 - val_loss: 37113.8047 - val_mae: 185.4566\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37891.5703 - mae: 186.8566 - val_loss: 37087.9258 - val_mae: 185.3837\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37868.3398 - mae: 186.7994 - val_loss: 37061.7773 - val_mae: 185.3101\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37844.2109 - mae: 186.7391 - val_loss: 37036.3477 - val_mae: 185.2385\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37821.1094 - mae: 186.6815 - val_loss: 37010.4336 - val_mae: 185.1655\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37797.5859 - mae: 186.6239 - val_loss: 36984.4414 - val_mae: 185.0922\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37773.9805 - mae: 186.5655 - val_loss: 36958.4297 - val_mae: 185.0189\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 37737.7500 - mae: 185.6035\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=adam; total time=   3.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 773556544108412713897315350347776.0000 - mae: 10121531740913664.0000 - val_loss: 288399514348123586878767104.0000 - val_mae: 16982332145664.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 287982156763455908273455104.0000 - mae: 16970035494912.0000 - val_loss: 287381530776415925272838144.0000 - val_mae: 16952330289152.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286960742097350536690925568.0000 - mae: 16939913052160.0000 - val_loss: 286361388935651639649370112.0000 - val_mae: 16922216235008.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285942094442856221541138432.0000 - mae: 16909821018112.0000 - val_loss: 285344881103469874807570432.0000 - val_mae: 16892154609664.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284927099243688500882571264.0000 - mae: 16879780364288.0000 - val_loss: 284332025726614704456990720.0000 - val_mae: 16862148558848.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283915682712871079877017600.0000 - mae: 16849795284992.0000 - val_loss: 283322712124621686340321280.0000 - val_mae: 16832192839680.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282907863297148032234029056.0000 - mae: 16819863683072.0000 - val_loss: 282316977190978967876665344.0000 - val_mae: 16802290597888.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281903604103031210534502400.0000 - mae: 16789983461376.0000 - val_loss: 281314876265918770194677760.0000 - val_mae: 16772442882048.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280902905130520614778437632.0000 - mae: 16760155668480.0000 - val_loss: 280316261775488503617945600.0000 - val_mae: 16742647595008.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279905821719848466094489600.0000 - mae: 16730384498688.0000 - val_loss: 279321207506664462984675328.0000 - val_mae: 16712905785344.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278912206297062174806245376.0000 - mae: 16700662611968.0000 - val_loss: 278329676565958500875763712.0000 - val_mae: 16683215355904.0000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 277922132649138035751911424.0000 - mae: 16670994202624.0000 - val_loss: 277341650506626543581659136.0000 - val_mae: 16653577355264.0000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276935619222820122641039360.0000 - mae: 16641381367808.0000 - val_loss: 276357166222156738521464832.0000 - val_mae: 16623992832000.0000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275952536890899919506767872.0000 - mae: 16611818864640.0000 - val_loss: 275376205265805011985629184.0000 - val_mae: 16594463883264.0000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 274972977887097794896855040.0000 - mae: 16582307741696.0000 - val_loss: 274398675403850995426394112.0000 - val_mae: 16564984217600.0000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273996905317925601392197632.0000 - mae: 16552849047552.0000 - val_loss: 273424668870015057391517696.0000 - val_mae: 16535556980736.0000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273024300736639265283244032.0000 - mae: 16523444879360.0000 - val_loss: 272454019643600534495035392.0000 - val_mae: 16506182172672.0000\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272055145696494712860442624.0000 - mae: 16494092091392.0000 - val_loss: 271486912192048163832463360.0000 - val_mae: 16476860841984.0000\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271089403304003796704690176.0000 - mae: 16464790683648.0000 - val_loss: 270523217388149429436940288.0000 - val_mae: 16447590891520.0000\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270127110452654664235089920.0000 - mae: 16435541704704.0000 - val_loss: 269562953678648405018017792.0000 - val_mae: 16418371272704.0000\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 269168230248959168032538624.0000 - mae: 16406346203136.0000 - val_loss: 268606047276568795737489408.0000 - val_mae: 16389206179840.0000\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 268212762692917308097036288.0000 - mae: 16377199984640.0000 - val_loss: 267652535075398749014458368.0000 - val_mae: 16360091418624.0000\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 267260670891040937009479680.0000 - mae: 16348107243520.0000 - val_loss: 266702472415370485977579520.0000 - val_mae: 16331028037632.0000\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 266311991736818202188972032.0000 - mae: 16319065882624.0000 - val_loss: 265755767062763638079094784.0000 - val_mae: 16302017085440.0000\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 265366632996528735087755264.0000 - mae: 16290076950528.0000 - val_loss: 264812400570834131609452544.0000 - val_mae: 16273058562048.0000\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 264424650010404756834484224.0000 - mae: 16261137301504.0000 - val_loss: 263872428279814187697307648.0000 - val_mae: 16244150370304.0000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263486042778446267429158912.0000 - mae: 16232252178432.0000 - val_loss: 262935721062495290375798784.0000 - val_mae: 16215293558784.0000\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262550737513676972033572864.0000 - mae: 16203416338432.0000 - val_loss: 262002371152597808192684032.0000 - val_mae: 16186489176064.0000\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 261618789556329091776380928.0000 - mae: 16174631878656.0000 - val_loss: 261072360103377667438411776.0000 - val_mae: 16157734076416.0000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 260690106672682258109825024.0000 - mae: 16145897750528.0000 - val_loss: 260145595681114499565223936.0000 - val_mae: 16129030356992.0000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259764707309480544743456768.0000 - mae: 16117215002624.0000 - val_loss: 259222170119528673120878592.0000 - val_mae: 16100378017792.0000\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258842609913468025386827776.0000 - mae: 16088584683520.0000 - val_loss: 258301991184899819557617664.0000 - val_mae: 16071777058816.0000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257923832931388773749489664.0000 - mae: 16060003647488.0000 - val_loss: 257385114217460160004096000.0000 - val_mae: 16043226431488.0000\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257008247236034273864581120.0000 - mae: 16031475040256.0000 - val_loss: 256471465430233399622107136.0000 - val_mae: 16014726135808.0000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 256095926614380820570308608.0000 - mae: 16002995716096.0000 - val_loss: 255561026376475464702099456.0000 - val_mae: 15986276171776.0000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255186797279452119028465664.0000 - mae: 15974566723584.0000 - val_loss: 254653815502930428953624576.0000 - val_mae: 15957876539392.0000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 254280951464968537786810368.0000 - mae: 15946187014144.0000 - val_loss: 253749888149830513505337344.0000 - val_mae: 15929529335808.0000\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253378389170930076845342720.0000 - mae: 15917860782080.0000 - val_loss: 252849188976943497228582912.0000 - val_mae: 15901232463872.0000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252478962823384146527649792.0000 - mae: 15889583833088.0000 - val_loss: 251951662644037158994706432.0000 - val_mae: 15872983826432.0000\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251582709315818894252834816.0000 - mae: 15861358264320.0000 - val_loss: 251057272257623351384604672.0000 - val_mae: 15844786569216.0000\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250689647094978393730449408.0000 - mae: 15833180930048.0000 - val_loss: 250166054711190221817380864.0000 - val_mae: 15816638595072.0000\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249799776160862644960493568.0000 - mae: 15805053927424.0000 - val_loss: 249278028451481844002586624.0000 - val_mae: 15788540952576.0000\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248913022726495353104760832.0000 - mae: 15776975159296.0000 - val_loss: 248393175031754144230670336.0000 - val_mae: 15760492593152.0000\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248029479025596886711009280.0000 - mae: 15748950917120.0000 - val_loss: 247511457558518975082528768.0000 - val_mae: 15732497711104.0000\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247149071271190950941032448.0000 - mae: 15720973860864.0000 - val_loss: 246632839138288189139058688.0000 - val_mae: 15704548966400.0000\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246271744123045324666175488.0000 - mae: 15693046087680.0000 - val_loss: 245757375111294007528914944.0000 - val_mae: 15676650553344.0000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 245397534474648155305541632.0000 - mae: 15665167597568.0000 - val_loss: 244885010137304209123442688.0000 - val_mae: 15648802471936.0000\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244526479219487590278234112.0000 - mae: 15637341536256.0000 - val_loss: 244015762663062867632193536.0000 - val_mae: 15621004722176.0000\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243658467677099187326943232.0000 - mae: 15609560563712.0000 - val_loss: 243149577348337761926512640.0000 - val_mae: 15593254158336.0000\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 242793536740971093870772224.0000 - mae: 15581833068544.0000 - val_loss: 242286435746384818296848384.0000 - val_mae: 15565551828992.0000\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241931686411103309909721088.0000 - mae: 15554151710720.0000 - val_loss: 241426393197436257871855616.0000 - val_mae: 15537901928448.0000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 241072898240751761734238208.0000 - mae: 15526520684544.0000 - val_loss: 240569375914515785813327872.0000 - val_mae: 15510300262400.0000\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 240217153783172375634771968.0000 - mae: 15498938941440.0000 - val_loss: 239715457684599696959471616.0000 - val_mae: 15482745782272.0000\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 239364471485109225320873984.0000 - mae: 15471406481408.0000 - val_loss: 238864527827223549052977152.0000 - val_mae: 15455240585216.0000\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 238514796006330089663889408.0000 - mae: 15443921207296.0000 - val_loss: 238016641682619563222499328.0000 - val_mae: 15427788865536.0000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 237668127346834968663818240.0000 - mae: 15416487313408.0000 - val_loss: 237171743910555518339383296.0000 - val_mae: 15400379088896.0000\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 236824465506623862320660480.0000 - mae: 15389101654016.0000 - val_loss: 236329852957775488113180672.0000 - val_mae: 15373022789632.0000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235983828932440844343967744.0000 - mae: 15361763180544.0000 - val_loss: 235490968824279472543891456.0000 - val_mae: 15345715773440.0000\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235146143837309619895533568.0000 - mae: 15334475038720.0000 - val_loss: 234655017723091176793309184.0000 - val_mae: 15318452797440.0000\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 234311447114718336394461184.0000 - mae: 15307234082816.0000 - val_loss: 233822091887930969409191936.0000 - val_mae: 15291243298816.0000\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 233479720317922920131198976.0000 - mae: 15280041361408.0000 - val_loss: 232992099085078481843781632.0000 - val_mae: 15264077840384.0000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 232650908106691149977092096.0000 - mae: 15252897923072.0000 - val_loss: 232165002421045566677975040.0000 - val_mae: 15236960616448.0000\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 231825065821255247060795392.0000 - mae: 15225800622080.0000 - val_loss: 231340894129552592459530240.0000 - val_mae: 15209895821312.0000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 231002193461615211382308864.0000 - mae: 15198754701312.0000 - val_loss: 230519718870367338059792384.0000 - val_mae: 15182876114944.0000\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 230182198794050674393874432.0000 - mae: 15171754917888.0000 - val_loss: 229701439750001656059658240.0000 - val_mae: 15155905691648.0000\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 229365118712049783514595328.0000 - mae: 15144803368960.0000 - val_loss: 228886056768455546459127808.0000 - val_mae: 15128981405696.0000\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 228550934768868465034919936.0000 - mae: 15117899005952.0000 - val_loss: 228073625265961230386855936.0000 - val_mae: 15102106402816.0000\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 227739683857994866373951488.0000 - mae: 15091043926016.0000 - val_loss: 227264016115310191875981312.0000 - val_mae: 15075277537280.0000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226931255298964545274380288.0000 - mae: 15064234983424.0000 - val_loss: 226457284656734652055158784.0000 - val_mae: 15048499003392.0000\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226125704432009722864861184.0000 - mae: 15037474275328.0000 - val_loss: 225653430890234610924388352.0000 - val_mae: 15021764509696.0000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 225323031257130399145394176.0000 - mae: 15010761801728.0000 - val_loss: 224852417922321921064566784.0000 - val_mae: 14995080347648.0000\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 224523198880838426696876032.0000 - mae: 14984096514048.0000 - val_loss: 224054282646484729894797312.0000 - val_mae: 14968442322944.0000\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 223726207303133805519306752.0000 - mae: 14957478412288.0000 - val_loss: 223258951275746742576873472.0000 - val_mae: 14941853581312.0000\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222932056524016535612686336.0000 - mae: 14930908545024.0000 - val_loss: 222466442256852032820346880.0000 - val_mae: 14915307831296.0000\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222140691203254395848359936.0000 - mae: 14904383766528.0000 - val_loss: 221676737143056526915665920.0000 - val_mae: 14888812412928.0000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 221352166681079607354982400.0000 - mae: 14877907222528.0000 - val_loss: 220889854381104298572382208.0000 - val_mae: 14862364180480.0000\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220566427617259949003898880.0000 - mae: 14851476815872.0000 - val_loss: 220105738630763126661840896.0000 - val_mae: 14835959988224.0000\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 219783455565051347085557760.0000 - mae: 14825093595136.0000 - val_loss: 219324426785521158603145216.0000 - val_mae: 14809606127616.0000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 219003268971197875309510656.0000 - mae: 14798758608896.0000 - val_loss: 218545881951890246977191936.0000 - val_mae: 14783297355776.0000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 218225886282443607385309184.0000 - mae: 14772467662848.0000 - val_loss: 217770122576614465493532672.0000 - val_mae: 14757036818432.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217451215265068174765195264.0000 - mae: 14746225999872.0000 - val_loss: 216997074872717519313960960.0000 - val_mae: 14730820321280.0000\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 216679348152791945996926976.0000 - mae: 14720029425664.0000 - val_loss: 216226794180431629567131648.0000 - val_mae: 14704652058624.0000\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 215910192711894552532746240.0000 - mae: 14693882134528.0000 - val_loss: 215459243606268648833941504.0000 - val_mae: 14678529933312.0000\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 215143748942375994372653056.0000 - mae: 14667777835008.0000 - val_loss: 214694460043716724533493760.0000 - val_mae: 14652454993920.0000\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214380053737724418935750656.0000 - mae: 14641721769984.0000 - val_loss: 213932314365567340698927104.0000 - val_mae: 14626425143296.0000\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 213619070204451678802935808.0000 - mae: 14615711842304.0000 - val_loss: 213172917252284939587551232.0000 - val_mae: 14600441430016.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212860779895813700264656896.0000 - mae: 14589748051968.0000 - val_loss: 212416194916893226361159680.0000 - val_mae: 14574503854080.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212105164365066409611362304.0000 - mae: 14563830398976.0000 - val_loss: 211662202699624422148407296.0000 - val_mae: 14548615561216.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 211352260505697954262155264.0000 - mae: 14537958883328.0000 - val_loss: 210910811473270010982432768.0000 - val_mae: 14522769211392.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 210602012977476113088380928.0000 - mae: 14512132456448.0000 - val_loss: 210162168811782582539649024.0000 - val_mae: 14496971096064.0000\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209854458673889033509142528.0000 - mae: 14486352166912.0000 - val_loss: 209416145587953620853194752.0000 - val_mae: 14471219118080.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209109505361216346976681984.0000 - mae: 14460619063296.0000 - val_loss: 208672760248527199632621568.0000 - val_mae: 14445510131712.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 208367245273178422038757376.0000 - mae: 14434928951296.0000 - val_loss: 207932049686991466297032704.0000 - val_mae: 14419849379840.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 207627623069543037566713856.0000 - mae: 14409286025216.0000 - val_loss: 207193958563114199717773312.0000 - val_mae: 14394233716736.0000\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 206890564963333898722344960.0000 - mae: 14383690285056.0000 - val_loss: 206458449983407252475740160.0000 - val_mae: 14368661045248.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206156144741527300343857152.0000 - mae: 14358136487936.0000 - val_loss: 205725616181590993118691328.0000 - val_mae: 14343137656832.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 205424380850867316140802048.0000 - mae: 14332630925312.0000 - val_loss: 204995346477200979389317120.0000 - val_mae: 14317657260032.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204695217951121724984524800.0000 - mae: 14307169402880.0000 - val_loss: 204267659316981284997169152.0000 - val_mae: 14292223000576.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203968563808570158327267328.0000 - mae: 14281755066368.0000 - val_loss: 203542573147675983651799040.0000 - val_mae: 14266834878464.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203244529103677058426339328.0000 - mae: 14256383721472.0000 - val_loss: 202820051075796927934103552.0000 - val_mae: 14241488699392.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 202820032629052854224551936.0000 - mae: 14241489747968.0000\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   4.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 44601836.0000 - mae: 3071.8965 - val_loss: 348.8294 - val_mae: 17.6272\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.1755 - mae: 20.4572 - val_loss: 347.5534 - val_mae: 17.5909\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.6942 - mae: 20.4213 - val_loss: 346.2718 - val_mae: 17.5545\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 518.2043 - mae: 20.3846 - val_loss: 344.9939 - val_mae: 17.5180\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.7226 - mae: 20.3485 - val_loss: 343.7271 - val_mae: 17.4818\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.2555 - mae: 20.3116 - val_loss: 342.4722 - val_mae: 17.4459\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 513.7989 - mae: 20.2762 - val_loss: 341.2245 - val_mae: 17.4101\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.3495 - mae: 20.2413 - val_loss: 339.9745 - val_mae: 17.3742\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 510.8929 - mae: 20.2046 - val_loss: 338.7194 - val_mae: 17.3380\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.4327 - mae: 20.1683 - val_loss: 337.4690 - val_mae: 17.3019\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.9811 - mae: 20.1323 - val_loss: 336.2355 - val_mae: 17.2662\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.5484 - mae: 20.0971 - val_loss: 335.0000 - val_mae: 17.2304\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 505.1087 - mae: 20.0612 - val_loss: 333.7680 - val_mae: 17.1946\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.6768 - mae: 20.0254 - val_loss: 332.5477 - val_mae: 17.1591\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.2566 - mae: 19.9902 - val_loss: 331.3252 - val_mae: 17.1234\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.8315 - mae: 19.9539 - val_loss: 330.1099 - val_mae: 17.0879\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.4167 - mae: 19.9191 - val_loss: 328.8922 - val_mae: 17.0523\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.9968 - mae: 19.8831 - val_loss: 327.6865 - val_mae: 17.0169\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.5940 - mae: 19.8484 - val_loss: 326.4818 - val_mae: 16.9814\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.1878 - mae: 19.8125 - val_loss: 325.2839 - val_mae: 16.9461\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 493.7923 - mae: 19.7767 - val_loss: 324.0927 - val_mae: 16.9109\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.4037 - mae: 19.7421 - val_loss: 322.9102 - val_mae: 16.8759\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.0243 - mae: 19.7071 - val_loss: 321.7266 - val_mae: 16.8408\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.6406 - mae: 19.6718 - val_loss: 320.5375 - val_mae: 16.8055\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.2511 - mae: 19.6362 - val_loss: 319.3629 - val_mae: 16.7705\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.8823 - mae: 19.6015 - val_loss: 318.1918 - val_mae: 16.7356\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.5159 - mae: 19.5666 - val_loss: 317.0403 - val_mae: 16.7011\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 484.1741 - mae: 19.5325 - val_loss: 315.8896 - val_mae: 16.6666\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.8256 - mae: 19.4978 - val_loss: 314.7396 - val_mae: 16.6321\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.4807 - mae: 19.4633 - val_loss: 313.5909 - val_mae: 16.5975\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.1382 - mae: 19.4287 - val_loss: 312.4565 - val_mae: 16.5633\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.8110 - mae: 19.3947 - val_loss: 311.3083 - val_mae: 16.5286\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.4618 - mae: 19.3596 - val_loss: 310.1668 - val_mae: 16.4941\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 476.1287 - mae: 19.3253 - val_loss: 309.0342 - val_mae: 16.4597\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.8015 - mae: 19.2913 - val_loss: 307.8991 - val_mae: 16.4252\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.4709 - mae: 19.2560 - val_loss: 306.7710 - val_mae: 16.3908\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.1519 - mae: 19.2221 - val_loss: 305.6583 - val_mae: 16.3568\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 470.8503 - mae: 19.1882 - val_loss: 304.5514 - val_mae: 16.3229\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.5510 - mae: 19.1540 - val_loss: 303.4424 - val_mae: 16.2889\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.2487 - mae: 19.1206 - val_loss: 302.3342 - val_mae: 16.2549\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.9488 - mae: 19.0859 - val_loss: 301.2314 - val_mae: 16.2209\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.6555 - mae: 19.0520 - val_loss: 300.1357 - val_mae: 16.1871\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.3692 - mae: 19.0187 - val_loss: 299.0426 - val_mae: 16.1533\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 463.0844 - mae: 18.9849 - val_loss: 297.9504 - val_mae: 16.1195\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.8030 - mae: 18.9500 - val_loss: 296.8658 - val_mae: 16.0858\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.5295 - mae: 18.9173 - val_loss: 295.7922 - val_mae: 16.0524\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.2690 - mae: 18.8837 - val_loss: 294.7262 - val_mae: 16.0192\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 458.0149 - mae: 18.8508 - val_loss: 293.6519 - val_mae: 15.9856\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.7464 - mae: 18.8174 - val_loss: 292.5730 - val_mae: 15.9518\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.4785 - mae: 18.7836 - val_loss: 291.5131 - val_mae: 15.9186\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.2346 - mae: 18.7502 - val_loss: 290.4542 - val_mae: 15.8853\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.9870 - mae: 18.7168 - val_loss: 289.3974 - val_mae: 15.8520\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.7411 - mae: 18.6837 - val_loss: 288.3446 - val_mae: 15.8187\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.5030 - mae: 18.6502 - val_loss: 287.3043 - val_mae: 15.7858\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.2772 - mae: 18.6176 - val_loss: 286.2572 - val_mae: 15.7526\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.0395 - mae: 18.5843 - val_loss: 285.2121 - val_mae: 15.7194\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.8086 - mae: 18.5513 - val_loss: 284.1770 - val_mae: 15.6864\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.5887 - mae: 18.5182 - val_loss: 283.1475 - val_mae: 15.6536\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.3734 - mae: 18.4859 - val_loss: 282.1125 - val_mae: 15.6205\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.1491 - mae: 18.4521 - val_loss: 281.0810 - val_mae: 15.5874\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.9340 - mae: 18.4190 - val_loss: 280.0642 - val_mae: 15.5548\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.7348 - mae: 18.3865 - val_loss: 279.0534 - val_mae: 15.5223\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.5404 - mae: 18.3540 - val_loss: 278.0448 - val_mae: 15.4897\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.3478 - mae: 18.3215 - val_loss: 277.0385 - val_mae: 15.4572\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.1597 - mae: 18.2896 - val_loss: 276.0413 - val_mae: 15.4249\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.9795 - mae: 18.2572 - val_loss: 275.0393 - val_mae: 15.3924\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.7930 - mae: 18.2241 - val_loss: 274.0501 - val_mae: 15.3602\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.6243 - mae: 18.1923 - val_loss: 273.0537 - val_mae: 15.3278\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.4423 - mae: 18.1593 - val_loss: 272.0636 - val_mae: 15.2954\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.2708 - mae: 18.1277 - val_loss: 271.0789 - val_mae: 15.2632\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.1059 - mae: 18.0947 - val_loss: 270.1064 - val_mae: 15.2313\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.9545 - mae: 18.0638 - val_loss: 269.1296 - val_mae: 15.1992\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.7931 - mae: 18.0313 - val_loss: 268.1530 - val_mae: 15.1671\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.6349 - mae: 17.9993 - val_loss: 267.1772 - val_mae: 15.1349\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.4771 - mae: 17.9669 - val_loss: 266.2068 - val_mae: 15.1028\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.3289 - mae: 17.9358 - val_loss: 265.2502 - val_mae: 15.0711\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.1924 - mae: 17.9035 - val_loss: 264.2830 - val_mae: 15.0390\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.0425 - mae: 17.8704 - val_loss: 263.3334 - val_mae: 15.0073\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.9186 - mae: 17.8395 - val_loss: 262.3849 - val_mae: 14.9757\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.7902 - mae: 17.8076 - val_loss: 261.4353 - val_mae: 14.9440\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.6620 - mae: 17.7762 - val_loss: 260.4985 - val_mae: 14.9126\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.5497 - mae: 17.7453 - val_loss: 259.5620 - val_mae: 14.8812\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.4330 - mae: 17.7138 - val_loss: 258.6201 - val_mae: 14.8495\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.3117 - mae: 17.6816 - val_loss: 257.6894 - val_mae: 14.8181\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.2064 - mae: 17.6507 - val_loss: 256.7622 - val_mae: 14.7868\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 413.1020 - mae: 17.6193 - val_loss: 255.8404 - val_mae: 14.7556\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.0042 - mae: 17.5883 - val_loss: 254.9147 - val_mae: 14.7242\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.8987 - mae: 17.5570 - val_loss: 253.9877 - val_mae: 14.6927\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.7938 - mae: 17.5250 - val_loss: 253.0683 - val_mae: 14.6614\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.7005 - mae: 17.4936 - val_loss: 252.1624 - val_mae: 14.6304\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.6218 - mae: 17.4631 - val_loss: 251.2547 - val_mae: 14.5994\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.5376 - mae: 17.4319 - val_loss: 250.3512 - val_mae: 14.5684\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.4586 - mae: 17.4016 - val_loss: 249.4436 - val_mae: 14.5372\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.3738 - mae: 17.3701 - val_loss: 248.5466 - val_mae: 14.5063\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.3054 - mae: 17.3385 - val_loss: 247.6562 - val_mae: 14.4756\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.2415 - mae: 17.3086 - val_loss: 246.7689 - val_mae: 14.4449\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.1796 - mae: 17.2777 - val_loss: 245.8751 - val_mae: 14.4140\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.1101 - mae: 17.2462 - val_loss: 244.9922 - val_mae: 14.3833\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.0568 - mae: 17.2159 - val_loss: 244.1116 - val_mae: 14.3527\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.0029 - mae: 17.1856 - val_loss: 243.2418 - val_mae: 14.3223\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 301.0074 - mae: 15.5862\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   3.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 125378088.0000 - mae: 4689.5122 - val_loss: 344.5166 - val_mae: 16.5383\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.1081 - mae: 16.5635 - val_loss: 343.5429 - val_mae: 16.5109\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 351.1339 - mae: 16.5340 - val_loss: 342.5724 - val_mae: 16.4837\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.1609 - mae: 16.5053 - val_loss: 341.6088 - val_mae: 16.4565\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.1961 - mae: 16.4760 - val_loss: 340.6512 - val_mae: 16.4295\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 348.2371 - mae: 16.4470 - val_loss: 339.6975 - val_mae: 16.4026\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.2809 - mae: 16.4184 - val_loss: 338.7391 - val_mae: 16.3754\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.3196 - mae: 16.3887 - val_loss: 337.7873 - val_mae: 16.3484\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.3673 - mae: 16.3604 - val_loss: 336.8438 - val_mae: 16.3216\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.4211 - mae: 16.3318 - val_loss: 335.8997 - val_mae: 16.2948\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.4740 - mae: 16.3030 - val_loss: 334.9588 - val_mae: 16.2679\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.5328 - mae: 16.2743 - val_loss: 334.0289 - val_mae: 16.2414\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.6017 - mae: 16.2458 - val_loss: 333.0979 - val_mae: 16.2147\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.6672 - mae: 16.2173 - val_loss: 332.1675 - val_mae: 16.1881\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.7349 - mae: 16.1882 - val_loss: 331.2430 - val_mae: 16.1615\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.8081 - mae: 16.1601 - val_loss: 330.3142 - val_mae: 16.1348\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.8763 - mae: 16.1310 - val_loss: 329.3941 - val_mae: 16.1083\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.9563 - mae: 16.1028 - val_loss: 328.4800 - val_mae: 16.0819\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 336.0405 - mae: 16.0749 - val_loss: 327.5722 - val_mae: 16.0556\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.1306 - mae: 16.0469 - val_loss: 326.6631 - val_mae: 16.0293\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.2189 - mae: 16.0184 - val_loss: 325.7595 - val_mae: 16.0031\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.3139 - mae: 15.9908 - val_loss: 324.8577 - val_mae: 15.9768\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.4091 - mae: 15.9630 - val_loss: 323.9551 - val_mae: 15.9505\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.5028 - mae: 15.9346 - val_loss: 323.0500 - val_mae: 15.9241\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.5951 - mae: 15.9060 - val_loss: 322.1494 - val_mae: 15.8978\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.6930 - mae: 15.8780 - val_loss: 321.2545 - val_mae: 15.8716\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.7968 - mae: 15.8497 - val_loss: 320.3653 - val_mae: 15.8455\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.9064 - mae: 15.8217 - val_loss: 319.4752 - val_mae: 15.8193\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.0132 - mae: 15.7940 - val_loss: 318.5927 - val_mae: 15.7934\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 326.1299 - mae: 15.7659 - val_loss: 317.7105 - val_mae: 15.7673\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.2449 - mae: 15.7379 - val_loss: 316.8308 - val_mae: 15.7413\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.3626 - mae: 15.7105 - val_loss: 315.9530 - val_mae: 15.7154\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.4838 - mae: 15.6823 - val_loss: 315.0875 - val_mae: 15.6897\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.6186 - mae: 15.6550 - val_loss: 314.2230 - val_mae: 15.6640\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 321.7498 - mae: 15.6278 - val_loss: 313.3566 - val_mae: 15.6382\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 320.8821 - mae: 15.6001 - val_loss: 312.5040 - val_mae: 15.6128\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 320.0312 - mae: 15.5726 - val_loss: 311.6559 - val_mae: 15.5875\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.1807 - mae: 15.5459 - val_loss: 310.8101 - val_mae: 15.5622\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 318.3324 - mae: 15.5192 - val_loss: 309.9618 - val_mae: 15.5367\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.4795 - mae: 15.4924 - val_loss: 309.1145 - val_mae: 15.5113\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.6310 - mae: 15.4653 - val_loss: 308.2724 - val_mae: 15.4860\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.7858 - mae: 15.4388 - val_loss: 307.4185 - val_mae: 15.4602\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 314.9267 - mae: 15.4112 - val_loss: 306.5754 - val_mae: 15.4348\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.0857 - mae: 15.3843 - val_loss: 305.7423 - val_mae: 15.4096\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.2501 - mae: 15.3574 - val_loss: 304.9052 - val_mae: 15.3842\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 312.4098 - mae: 15.3304 - val_loss: 304.0761 - val_mae: 15.3591\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 311.5815 - mae: 15.3035 - val_loss: 303.2546 - val_mae: 15.3341\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.7582 - mae: 15.2774 - val_loss: 302.4337 - val_mae: 15.3091\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.9340 - mae: 15.2506 - val_loss: 301.6126 - val_mae: 15.2841\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.1107 - mae: 15.2239 - val_loss: 300.7949 - val_mae: 15.2591\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 308.2916 - mae: 15.1971 - val_loss: 299.9832 - val_mae: 15.2342\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 307.4788 - mae: 15.1710 - val_loss: 299.1717 - val_mae: 15.2093\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.6633 - mae: 15.1450 - val_loss: 298.3584 - val_mae: 15.1843\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 305.8472 - mae: 15.1182 - val_loss: 297.5476 - val_mae: 15.1594\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 305.0351 - mae: 15.0919 - val_loss: 296.7437 - val_mae: 15.1346\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.2310 - mae: 15.0656 - val_loss: 295.9456 - val_mae: 15.1099\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.4305 - mae: 15.0394 - val_loss: 295.1449 - val_mae: 15.0851\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 302.6260 - mae: 15.0130 - val_loss: 294.3461 - val_mae: 15.0604\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 301.8256 - mae: 14.9870 - val_loss: 293.5464 - val_mae: 15.0355\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 301.0241 - mae: 14.9602 - val_loss: 292.7592 - val_mae: 15.0110\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.2363 - mae: 14.9346 - val_loss: 291.9676 - val_mae: 14.9863\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 299.4405 - mae: 14.9080 - val_loss: 291.1814 - val_mae: 14.9618\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 298.6548 - mae: 14.8820 - val_loss: 290.4043 - val_mae: 14.9375\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 297.8766 - mae: 14.8567 - val_loss: 289.6276 - val_mae: 14.9131\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 297.0971 - mae: 14.8302 - val_loss: 288.8553 - val_mae: 14.8889\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.3230 - mae: 14.8047 - val_loss: 288.0772 - val_mae: 14.8644\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.5407 - mae: 14.7789 - val_loss: 287.3034 - val_mae: 14.8400\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 294.7673 - mae: 14.7527 - val_loss: 286.5408 - val_mae: 14.8160\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 294.0028 - mae: 14.7277 - val_loss: 285.7688 - val_mae: 14.7916\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.2266 - mae: 14.7015 - val_loss: 285.0083 - val_mae: 14.7675\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.4664 - mae: 14.6762 - val_loss: 284.2488 - val_mae: 14.7434\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.7039 - mae: 14.6505 - val_loss: 283.4928 - val_mae: 14.7193\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.9474 - mae: 14.6253 - val_loss: 282.7423 - val_mae: 14.6954\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 290.1946 - mae: 14.5994 - val_loss: 281.9917 - val_mae: 14.6715\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.4416 - mae: 14.5741 - val_loss: 281.2434 - val_mae: 14.6476\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 288.6910 - mae: 14.5485 - val_loss: 280.4957 - val_mae: 14.6236\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 287.9413 - mae: 14.5231 - val_loss: 279.7518 - val_mae: 14.5998\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 287.1955 - mae: 14.4976 - val_loss: 279.0059 - val_mae: 14.5758\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286.4484 - mae: 14.4715 - val_loss: 278.2752 - val_mae: 14.5523\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.7185 - mae: 14.4472 - val_loss: 277.5468 - val_mae: 14.5288\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284.9853 - mae: 14.4225 - val_loss: 276.8052 - val_mae: 14.5048\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284.2385 - mae: 14.3967 - val_loss: 276.0673 - val_mae: 14.4810\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283.4998 - mae: 14.3718 - val_loss: 275.3297 - val_mae: 14.4570\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.7595 - mae: 14.3464 - val_loss: 274.6007 - val_mae: 14.4334\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.0315 - mae: 14.3209 - val_loss: 273.8811 - val_mae: 14.4099\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.3111 - mae: 14.2962 - val_loss: 273.1639 - val_mae: 14.3866\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.5917 - mae: 14.2714 - val_loss: 272.4505 - val_mae: 14.3633\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.8763 - mae: 14.2468 - val_loss: 271.7378 - val_mae: 14.3400\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 279.1612 - mae: 14.2220 - val_loss: 271.0271 - val_mae: 14.3167\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 278.4495 - mae: 14.1974 - val_loss: 270.3210 - val_mae: 14.2935\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.7404 - mae: 14.1730 - val_loss: 269.6104 - val_mae: 14.2701\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.0252 - mae: 14.1482 - val_loss: 268.8940 - val_mae: 14.2465\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.3064 - mae: 14.1226 - val_loss: 268.1877 - val_mae: 14.2232\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275.6020 - mae: 14.0975 - val_loss: 267.4923 - val_mae: 14.2002\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 274.9048 - mae: 14.0735 - val_loss: 266.7916 - val_mae: 14.1770\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.2009 - mae: 14.0485 - val_loss: 266.1011 - val_mae: 14.1541\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273.5103 - mae: 14.0247 - val_loss: 265.4093 - val_mae: 14.1311\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.8149 - mae: 14.0000 - val_loss: 264.7170 - val_mae: 14.1080\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.1210 - mae: 13.9755 - val_loss: 264.0274 - val_mae: 14.0850\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.4301 - mae: 13.9507 - val_loss: 263.3453 - val_mae: 14.0622\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 335.5985 - mae: 15.4508\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1091.2275 - mae: 23.7899 - val_loss: 72.7685 - val_mae: 7.0471\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.2592 - mae: 7.1605 - val_loss: 33.4320 - val_mae: 4.3634\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5568 - mae: 6.6123 - val_loss: 31.1445 - val_mae: 4.2540\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9999 - mae: 6.3730 - val_loss: 38.8775 - val_mae: 5.2112\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.7794 - mae: 6.3094 - val_loss: 27.6374 - val_mae: 4.0163\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.1855 - mae: 6.2161 - val_loss: 28.4756 - val_mae: 4.0701\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.4201 - mae: 6.2785 - val_loss: 24.5546 - val_mae: 3.7726\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.6181 - mae: 6.1370 - val_loss: 33.4775 - val_mae: 4.8133\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.5484 - mae: 6.0235 - val_loss: 43.4557 - val_mae: 5.6894\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.6236 - mae: 6.1840 - val_loss: 25.5762 - val_mae: 4.0304\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.0131 - mae: 6.0592 - val_loss: 22.1484 - val_mae: 3.6788\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.8638 - mae: 5.9730 - val_loss: 21.3645 - val_mae: 3.5867\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.1931 - mae: 6.1256 - val_loss: 26.2863 - val_mae: 4.1387\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.1492 - mae: 6.4854 - val_loss: 20.9078 - val_mae: 3.5760\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 61.9861 - mae: 5.7949 - val_loss: 26.1011 - val_mae: 4.1782\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.2590 - mae: 6.1604 - val_loss: 25.6317 - val_mae: 4.0435\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.4966 - mae: 5.7413 - val_loss: 24.5160 - val_mae: 4.0001\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.4060 - mae: 5.8384 - val_loss: 21.2081 - val_mae: 3.6943\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.0602 - mae: 5.5868 - val_loss: 20.6134 - val_mae: 3.5602\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.2441 - mae: 5.7401 - val_loss: 33.5010 - val_mae: 4.9030\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.4023 - mae: 5.7065 - val_loss: 17.9703 - val_mae: 3.3067\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0934 - mae: 5.8303 - val_loss: 25.2985 - val_mae: 4.1047\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2105 - mae: 5.6627 - val_loss: 19.1789 - val_mae: 3.4291\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.7473 - mae: 5.4370 - val_loss: 28.9773 - val_mae: 4.5162\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.2699 - mae: 5.7839 - val_loss: 19.8656 - val_mae: 3.5149\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2400 - mae: 5.5065 - val_loss: 22.4678 - val_mae: 3.8436\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0733 - mae: 5.6331 - val_loss: 18.8009 - val_mae: 3.3749\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3262 - mae: 6.0585 - val_loss: 18.5675 - val_mae: 3.3532\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1928 - mae: 5.4778 - val_loss: 22.5846 - val_mae: 3.8808\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1899 - mae: 5.5372 - val_loss: 18.5197 - val_mae: 3.4611\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1130 - mae: 5.4673 - val_loss: 20.8218 - val_mae: 3.6450\n",
      "Epoch 31: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 62.4671 - mae: 5.2176\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   1.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 23257.2871 - mae: 100.5874 - val_loss: 271.7751 - val_mae: 13.9782\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.1866 - mae: 14.3828 - val_loss: 92.5970 - val_mae: 8.3057\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.6747 - mae: 9.1137 - val_loss: 45.1035 - val_mae: 5.2890\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2156 - mae: 7.6420 - val_loss: 32.5885 - val_mae: 4.4449\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9830 - mae: 7.2984 - val_loss: 22.6448 - val_mae: 4.0015\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3425 - mae: 7.1425 - val_loss: 19.9110 - val_mae: 3.7244\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0114 - mae: 6.9537 - val_loss: 20.1099 - val_mae: 3.6551\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9641 - mae: 7.3495 - val_loss: 26.1894 - val_mae: 4.2531\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9991 - mae: 6.6279 - val_loss: 41.9500 - val_mae: 5.3386\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0119 - mae: 6.8359 - val_loss: 56.8880 - val_mae: 6.2779\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9420 - mae: 7.0486 - val_loss: 20.6504 - val_mae: 3.7353\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1532 - mae: 6.8067 - val_loss: 43.3410 - val_mae: 5.5171\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5146 - mae: 6.7352 - val_loss: 51.4560 - val_mae: 6.0196\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8780 - mae: 7.1147 - val_loss: 18.4065 - val_mae: 3.3946\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5677 - mae: 6.4835 - val_loss: 26.6862 - val_mae: 4.4533\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7499 - mae: 6.5823 - val_loss: 22.2203 - val_mae: 4.0328\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7466 - mae: 6.4942 - val_loss: 41.5208 - val_mae: 5.5274\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.3411 - mae: 6.7499 - val_loss: 18.4314 - val_mae: 3.5061\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5160 - mae: 6.3239 - val_loss: 27.7600 - val_mae: 4.6025\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.1319 - mae: 6.5417 - val_loss: 40.2142 - val_mae: 5.4262\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4776 - mae: 6.5987 - val_loss: 17.6788 - val_mae: 3.4495\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4655 - mae: 6.3802 - val_loss: 18.0441 - val_mae: 3.4185\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.0424 - mae: 6.2434 - val_loss: 30.0422 - val_mae: 4.7602\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3890 - mae: 6.4061 - val_loss: 20.0099 - val_mae: 3.8079\n",
      "Epoch 24: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.1740 - mae: 4.8890\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   1.2s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 28320.4961 - mae: 113.2136 - val_loss: 548.6666 - val_mae: 21.8374\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.1327 - mae: 22.2687 - val_loss: 548.5095 - val_mae: 21.8338\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.3079 - mae: 22.0457 - val_loss: 548.3550 - val_mae: 21.8303\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 559.5860 - mae: 21.9889 - val_loss: 548.2015 - val_mae: 21.8268\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.5909 - mae: 21.9554 - val_loss: 548.0484 - val_mae: 21.8233\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.8651 - mae: 21.9306 - val_loss: 547.8954 - val_mae: 21.8198\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2358 - mae: 21.9086 - val_loss: 547.7416 - val_mae: 21.8163\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.7613 - mae: 21.8924 - val_loss: 547.5886 - val_mae: 21.8127\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.4034 - mae: 21.8804 - val_loss: 547.4363 - val_mae: 21.8093\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.1341 - mae: 21.8724 - val_loss: 547.2833 - val_mae: 21.8057\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 555.9007 - mae: 21.8656 - val_loss: 547.1305 - val_mae: 21.8022\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 555.7185 - mae: 21.8610 - val_loss: 546.9790 - val_mae: 21.7988\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5485 - mae: 21.8567 - val_loss: 546.8265 - val_mae: 21.7953\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.3848 - mae: 21.8527 - val_loss: 546.6739 - val_mae: 21.7918\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.2308 - mae: 21.8491 - val_loss: 546.5218 - val_mae: 21.7883\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.0771 - mae: 21.8456 - val_loss: 546.3684 - val_mae: 21.7848\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.9223 - mae: 21.8420 - val_loss: 546.2164 - val_mae: 21.7813\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.7688 - mae: 21.8384 - val_loss: 546.0644 - val_mae: 21.7778\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.6154 - mae: 21.8349 - val_loss: 545.9129 - val_mae: 21.7743\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.4623 - mae: 21.8314 - val_loss: 545.7606 - val_mae: 21.7708\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3087 - mae: 21.8278 - val_loss: 545.6091 - val_mae: 21.7673\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.1564 - mae: 21.8243 - val_loss: 545.4572 - val_mae: 21.7638\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.0040 - mae: 21.8209 - val_loss: 545.3047 - val_mae: 21.7603\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.8511 - mae: 21.8173 - val_loss: 545.1516 - val_mae: 21.7568\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.6978 - mae: 21.8138 - val_loss: 544.9990 - val_mae: 21.7533\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.5446 - mae: 21.8103 - val_loss: 544.8466 - val_mae: 21.7498\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.3919 - mae: 21.8068 - val_loss: 544.6946 - val_mae: 21.7463\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.2396 - mae: 21.8033 - val_loss: 544.5420 - val_mae: 21.7428\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.0865 - mae: 21.7998 - val_loss: 544.3903 - val_mae: 21.7393\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 552.9344 - mae: 21.7963 - val_loss: 544.2380 - val_mae: 21.7358\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.7817 - mae: 21.7928 - val_loss: 544.0857 - val_mae: 21.7323\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.6290 - mae: 21.7893 - val_loss: 543.9333 - val_mae: 21.7288\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4763 - mae: 21.7858 - val_loss: 543.7825 - val_mae: 21.7253\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.3252 - mae: 21.7823 - val_loss: 543.6310 - val_mae: 21.7218\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 552.1732 - mae: 21.7788 - val_loss: 543.4789 - val_mae: 21.7183\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.0209 - mae: 21.7753 - val_loss: 543.3289 - val_mae: 21.7149\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.8704 - mae: 21.7718 - val_loss: 543.1786 - val_mae: 21.7114\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 551.7197 - mae: 21.7684 - val_loss: 543.0282 - val_mae: 21.7080\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.5689 - mae: 21.7649 - val_loss: 542.8770 - val_mae: 21.7045\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.4172 - mae: 21.7615 - val_loss: 542.7258 - val_mae: 21.7010\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.2657 - mae: 21.7580 - val_loss: 542.5750 - val_mae: 21.6975\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.1144 - mae: 21.7545 - val_loss: 542.4217 - val_mae: 21.6940\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 550.9608 - mae: 21.7510 - val_loss: 542.2706 - val_mae: 21.6905\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.8093 - mae: 21.7475 - val_loss: 542.1199 - val_mae: 21.6870\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 550.6583 - mae: 21.7440 - val_loss: 541.9681 - val_mae: 21.6835\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5060 - mae: 21.7405 - val_loss: 541.8175 - val_mae: 21.6801\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.3551 - mae: 21.7370 - val_loss: 541.6674 - val_mae: 21.6766\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.2046 - mae: 21.7336 - val_loss: 541.5167 - val_mae: 21.6731\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.0536 - mae: 21.7301 - val_loss: 541.3658 - val_mae: 21.6696\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.9023 - mae: 21.7266 - val_loss: 541.2151 - val_mae: 21.6662\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.7512 - mae: 21.7231 - val_loss: 541.0650 - val_mae: 21.6627\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.6007 - mae: 21.7197 - val_loss: 540.9143 - val_mae: 21.6592\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.4495 - mae: 21.7162 - val_loss: 540.7630 - val_mae: 21.6557\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.2979 - mae: 21.7127 - val_loss: 540.6119 - val_mae: 21.6522\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.1464 - mae: 21.7092 - val_loss: 540.4615 - val_mae: 21.6488\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.9956 - mae: 21.7058 - val_loss: 540.3115 - val_mae: 21.6453\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8451 - mae: 21.7023 - val_loss: 540.1604 - val_mae: 21.6418\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.6937 - mae: 21.6988 - val_loss: 540.0096 - val_mae: 21.6383\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.5424 - mae: 21.6954 - val_loss: 539.8582 - val_mae: 21.6348\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.3907 - mae: 21.6918 - val_loss: 539.7086 - val_mae: 21.6314\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2407 - mae: 21.6884 - val_loss: 539.5571 - val_mae: 21.6279\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.0890 - mae: 21.6848 - val_loss: 539.4070 - val_mae: 21.6244\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.9385 - mae: 21.6814 - val_loss: 539.2575 - val_mae: 21.6209\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.7886 - mae: 21.6780 - val_loss: 539.1074 - val_mae: 21.6175\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.6381 - mae: 21.6744 - val_loss: 538.9579 - val_mae: 21.6140\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.4882 - mae: 21.6710 - val_loss: 538.8068 - val_mae: 21.6105\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.3367 - mae: 21.6675 - val_loss: 538.6566 - val_mae: 21.6070\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.1862 - mae: 21.6640 - val_loss: 538.5075 - val_mae: 21.6036\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.0365 - mae: 21.6606 - val_loss: 538.3561 - val_mae: 21.6001\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.8849 - mae: 21.6571 - val_loss: 538.2070 - val_mae: 21.5966\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7353 - mae: 21.6537 - val_loss: 538.0569 - val_mae: 21.5932\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.5849 - mae: 21.6502 - val_loss: 537.9073 - val_mae: 21.5897\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.4350 - mae: 21.6467 - val_loss: 537.7582 - val_mae: 21.5862\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.2853 - mae: 21.6432 - val_loss: 537.6085 - val_mae: 21.5828\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.1353 - mae: 21.6398 - val_loss: 537.4589 - val_mae: 21.5793\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.9853 - mae: 21.6363 - val_loss: 537.3091 - val_mae: 21.5758\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.8351 - mae: 21.6328 - val_loss: 537.1595 - val_mae: 21.5724\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.6851 - mae: 21.6294 - val_loss: 537.0091 - val_mae: 21.5689\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.5345 - mae: 21.6258 - val_loss: 536.8613 - val_mae: 21.5655\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.3862 - mae: 21.6224 - val_loss: 536.7126 - val_mae: 21.5620\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.2370 - mae: 21.6190 - val_loss: 536.5615 - val_mae: 21.5585\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.0855 - mae: 21.6155 - val_loss: 536.4114 - val_mae: 21.5550\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.9350 - mae: 21.6120 - val_loss: 536.2606 - val_mae: 21.5515\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.7838 - mae: 21.6085 - val_loss: 536.1112 - val_mae: 21.5480\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 544.6342 - mae: 21.6050 - val_loss: 535.9626 - val_mae: 21.5446\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.4852 - mae: 21.6016 - val_loss: 535.8137 - val_mae: 21.5411\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.3360 - mae: 21.5981 - val_loss: 535.6653 - val_mae: 21.5377\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.1871 - mae: 21.5947 - val_loss: 535.5165 - val_mae: 21.5342\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.0380 - mae: 21.5912 - val_loss: 535.3677 - val_mae: 21.5308\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.8889 - mae: 21.5878 - val_loss: 535.2194 - val_mae: 21.5273\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 543.7400 - mae: 21.5844 - val_loss: 535.0698 - val_mae: 21.5239\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 543.5898 - mae: 21.5809 - val_loss: 534.9191 - val_mae: 21.5204\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.4388 - mae: 21.5774 - val_loss: 534.7701 - val_mae: 21.5169\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.2896 - mae: 21.5739 - val_loss: 534.6222 - val_mae: 21.5135\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.1412 - mae: 21.5705 - val_loss: 534.4725 - val_mae: 21.5100\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.9913 - mae: 21.5670 - val_loss: 534.3250 - val_mae: 21.5066\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 542.8433 - mae: 21.5636 - val_loss: 534.1761 - val_mae: 21.5031\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.6940 - mae: 21.5601 - val_loss: 534.0272 - val_mae: 21.4996\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.5447 - mae: 21.5566 - val_loss: 533.8784 - val_mae: 21.4962\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 542.3956 - mae: 21.5531 - val_loss: 533.7305 - val_mae: 21.4927\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 630.1104 - mae: 23.0691\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   4.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 587.7315 - mae: 22.0672 - val_loss: 437.7066 - val_mae: 19.9898\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 579.1555 - mae: 22.2695 - val_loss: 423.6258 - val_mae: 19.6345\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.5646 - mae: 21.9134 - val_loss: 410.0774 - val_mae: 19.2864\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.5126 - mae: 21.5685 - val_loss: 396.7614 - val_mae: 18.9380\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.7123 - mae: 21.2227 - val_loss: 384.0439 - val_mae: 18.5992\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.5500 - mae: 20.8823 - val_loss: 371.8143 - val_mae: 18.2675\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 505.8839 - mae: 20.5554 - val_loss: 359.9592 - val_mae: 17.9401\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.6125 - mae: 20.2340 - val_loss: 348.4352 - val_mae: 17.6160\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.6789 - mae: 19.9093 - val_loss: 337.2207 - val_mae: 17.2947\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 467.0832 - mae: 19.5893 - val_loss: 326.5347 - val_mae: 16.9830\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.0390 - mae: 19.2822 - val_loss: 316.1335 - val_mae: 16.6740\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.2963 - mae: 18.9748 - val_loss: 306.0992 - val_mae: 16.3703\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.9341 - mae: 18.6737 - val_loss: 296.3326 - val_mae: 16.0692\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 420.8693 - mae: 18.3728 - val_loss: 286.9910 - val_mae: 15.7759\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.2354 - mae: 18.0803 - val_loss: 277.9475 - val_mae: 15.4866\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.9391 - mae: 17.7919 - val_loss: 269.3024 - val_mae: 15.2049\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.0455 - mae: 17.5202 - val_loss: 260.8569 - val_mae: 14.9246\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.3676 - mae: 17.2442 - val_loss: 252.6914 - val_mae: 14.6485\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.9884 - mae: 16.9804 - val_loss: 244.7978 - val_mae: 14.3765\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.8921 - mae: 16.7115 - val_loss: 237.1491 - val_mae: 14.1080\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 353.0571 - mae: 16.4451 - val_loss: 229.7622 - val_mae: 13.8437\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 344.5120 - mae: 16.1887 - val_loss: 222.7215 - val_mae: 13.5871\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.3251 - mae: 15.9405 - val_loss: 215.8410 - val_mae: 13.3315\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.3082 - mae: 15.6887 - val_loss: 209.1912 - val_mae: 13.0944\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 320.5426 - mae: 15.4411 - val_loss: 202.7773 - val_mae: 12.8652\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.0247 - mae: 15.2024 - val_loss: 196.5846 - val_mae: 12.6396\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 305.7534 - mae: 14.9727 - val_loss: 190.6260 - val_mae: 12.4184\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.7320 - mae: 14.7387 - val_loss: 184.8796 - val_mae: 12.2009\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.9262 - mae: 14.5166 - val_loss: 179.2870 - val_mae: 11.9851\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.3026 - mae: 14.2936 - val_loss: 173.9756 - val_mae: 11.7761\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 278.9799 - mae: 14.0853 - val_loss: 168.8692 - val_mae: 11.5714\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.8716 - mae: 13.8840 - val_loss: 163.8142 - val_mae: 11.3647\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 266.8152 - mae: 13.6776 - val_loss: 158.9648 - val_mae: 11.1625\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.9808 - mae: 13.4811 - val_loss: 154.2768 - val_mae: 10.9631\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.3289 - mae: 13.2856 - val_loss: 149.7725 - val_mae: 10.7677\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.8780 - mae: 13.0914 - val_loss: 145.4819 - val_mae: 10.5779\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.6582 - mae: 12.9059 - val_loss: 141.3347 - val_mae: 10.3908\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 239.6044 - mae: 12.7209 - val_loss: 137.3751 - val_mae: 10.2086\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.7442 - mae: 12.5455 - val_loss: 133.4542 - val_mae: 10.0330\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 229.9289 - mae: 12.3695 - val_loss: 129.6781 - val_mae: 9.8666\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 225.2638 - mae: 12.1880 - val_loss: 126.0668 - val_mae: 9.7042\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220.7872 - mae: 12.0176 - val_loss: 122.5935 - val_mae: 9.5449\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 216.4692 - mae: 11.8587 - val_loss: 119.2657 - val_mae: 9.3891\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212.3028 - mae: 11.6981 - val_loss: 116.0155 - val_mae: 9.2339\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 208.2274 - mae: 11.5343 - val_loss: 112.8843 - val_mae: 9.0812\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.2769 - mae: 11.3754 - val_loss: 109.8982 - val_mae: 8.9330\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 200.5043 - mae: 11.2320 - val_loss: 107.0221 - val_mae: 8.7997\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 196.8312 - mae: 11.0884 - val_loss: 104.1852 - val_mae: 8.6654\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 193.2054 - mae: 10.9451 - val_loss: 101.4792 - val_mae: 8.5346\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 189.7313 - mae: 10.8015 - val_loss: 98.8867 - val_mae: 8.4066\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.3820 - mae: 10.6677 - val_loss: 96.3587 - val_mae: 8.2825\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 183.1099 - mae: 10.5283 - val_loss: 93.9376 - val_mae: 8.1697\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 179.9500 - mae: 10.4010 - val_loss: 91.5895 - val_mae: 8.0580\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 176.8831 - mae: 10.2725 - val_loss: 89.4014 - val_mae: 7.9516\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 173.9882 - mae: 10.1531 - val_loss: 87.2395 - val_mae: 7.8442\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 171.1221 - mae: 10.0335 - val_loss: 85.1497 - val_mae: 7.7470\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 168.3431 - mae: 9.9139 - val_loss: 83.1739 - val_mae: 7.6554\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 165.6932 - mae: 9.7988 - val_loss: 81.2217 - val_mae: 7.5628\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 163.0663 - mae: 9.6909 - val_loss: 79.3793 - val_mae: 7.4775\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 160.5686 - mae: 9.5841 - val_loss: 77.5955 - val_mae: 7.3995\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 158.1413 - mae: 9.4884 - val_loss: 75.8962 - val_mae: 7.3235\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 155.8030 - mae: 9.3915 - val_loss: 74.2501 - val_mae: 7.2483\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 153.5316 - mae: 9.2945 - val_loss: 72.6685 - val_mae: 7.1744\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 151.3303 - mae: 9.2035 - val_loss: 71.1128 - val_mae: 7.1001\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 149.1637 - mae: 9.1114 - val_loss: 69.6779 - val_mae: 7.0299\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 147.1367 - mae: 9.0227 - val_loss: 68.2685 - val_mae: 6.9594\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 145.1375 - mae: 8.9337 - val_loss: 66.9030 - val_mae: 6.8896\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 143.1865 - mae: 8.8464 - val_loss: 65.5659 - val_mae: 6.8195\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 141.2729 - mae: 8.7637 - val_loss: 64.3001 - val_mae: 6.7516\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 139.4290 - mae: 8.6831 - val_loss: 63.0976 - val_mae: 6.6856\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 137.6809 - mae: 8.6032 - val_loss: 61.9700 - val_mae: 6.6222\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 136.0144 - mae: 8.5328 - val_loss: 60.8370 - val_mae: 6.5570\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 134.3373 - mae: 8.4579 - val_loss: 59.7872 - val_mae: 6.4951\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 132.7632 - mae: 8.3862 - val_loss: 58.7313 - val_mae: 6.4313\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1742 - mae: 8.3144 - val_loss: 57.7465 - val_mae: 6.3703\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129.6862 - mae: 8.2477 - val_loss: 56.8216 - val_mae: 6.3116\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 128.2584 - mae: 8.1758 - val_loss: 55.8941 - val_mae: 6.2513\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 126.8217 - mae: 8.1091 - val_loss: 55.0153 - val_mae: 6.1927\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125.4472 - mae: 8.0449 - val_loss: 54.1754 - val_mae: 6.1352\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 124.1297 - mae: 7.9808 - val_loss: 53.3513 - val_mae: 6.0773\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 122.8250 - mae: 7.9208 - val_loss: 52.6106 - val_mae: 6.0292\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.6188 - mae: 7.8615 - val_loss: 51.8640 - val_mae: 5.9813\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.4089 - mae: 7.8046 - val_loss: 51.1477 - val_mae: 5.9342\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.2323 - mae: 7.7469 - val_loss: 50.4636 - val_mae: 5.8880\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118.1041 - mae: 7.6916 - val_loss: 49.8178 - val_mae: 5.8432\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 117.0135 - mae: 7.6378 - val_loss: 49.1781 - val_mae: 5.7975\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115.9297 - mae: 7.5830 - val_loss: 48.5886 - val_mae: 5.7543\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 114.9170 - mae: 7.5346 - val_loss: 47.9964 - val_mae: 5.7096\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.8954 - mae: 7.4810 - val_loss: 47.4613 - val_mae: 5.6680\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.9491 - mae: 7.4351 - val_loss: 46.9401 - val_mae: 5.6264\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.0203 - mae: 7.3946 - val_loss: 46.4364 - val_mae: 5.5850\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.1190 - mae: 7.3514 - val_loss: 45.9672 - val_mae: 5.5508\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 110.2584 - mae: 7.3119 - val_loss: 45.5145 - val_mae: 5.5217\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.4147 - mae: 7.2729 - val_loss: 45.0747 - val_mae: 5.4943\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.5866 - mae: 7.2354 - val_loss: 44.6545 - val_mae: 5.4674\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.7878 - mae: 7.1960 - val_loss: 44.2650 - val_mae: 5.4416\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.0309 - mae: 7.1593 - val_loss: 43.8682 - val_mae: 5.4203\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.2514 - mae: 7.1207 - val_loss: 43.5097 - val_mae: 5.4006\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.5320 - mae: 7.0863 - val_loss: 43.1547 - val_mae: 5.3805\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.8138 - mae: 7.0535 - val_loss: 42.8211 - val_mae: 5.3615\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 112.5455 - mae: 7.3994\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   4.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 147566.2344 - mae: 190.4218 - val_loss: 494.6656 - val_mae: 21.3671\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2468 - mae: 24.0503 - val_loss: 478.4290 - val_mae: 20.9837\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.0578 - mae: 23.6721 - val_loss: 462.5877 - val_mae: 20.6028\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.2868 - mae: 23.2918 - val_loss: 447.3111 - val_mae: 20.2286\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1140 - mae: 22.9226 - val_loss: 432.6228 - val_mae: 19.8623\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.5801 - mae: 22.5524 - val_loss: 418.5058 - val_mae: 19.5037\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.6221 - mae: 22.1997 - val_loss: 404.8683 - val_mae: 19.1509\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.1805 - mae: 21.8570 - val_loss: 391.5950 - val_mae: 18.8011\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.1005 - mae: 21.5034 - val_loss: 378.6836 - val_mae: 18.4546\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.4143 - mae: 21.1582 - val_loss: 366.2340 - val_mae: 18.1141\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.2280 - mae: 20.8205 - val_loss: 354.3448 - val_mae: 17.7829\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.6235 - mae: 20.4949 - val_loss: 342.7405 - val_mae: 17.4536\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.3226 - mae: 20.1671 - val_loss: 331.5528 - val_mae: 17.1301\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.4756 - mae: 19.8454 - val_loss: 320.8172 - val_mae: 16.8138\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.0906 - mae: 19.5336 - val_loss: 310.3525 - val_mae: 16.4997\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.0027 - mae: 19.2159 - val_loss: 300.3041 - val_mae: 16.1923\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.3522 - mae: 18.9163 - val_loss: 290.5028 - val_mae: 15.8868\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.9745 - mae: 18.6105 - val_loss: 281.1443 - val_mae: 15.5895\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.0629 - mae: 18.3205 - val_loss: 272.0393 - val_mae: 15.2947\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.4214 - mae: 18.0229 - val_loss: 263.2903 - val_mae: 15.0059\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.1664 - mae: 17.7317 - val_loss: 254.8560 - val_mae: 14.7222\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.2530 - mae: 17.4543 - val_loss: 246.7465 - val_mae: 14.4442\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.6818 - mae: 17.1783 - val_loss: 238.8547 - val_mae: 14.1683\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.3419 - mae: 16.9023 - val_loss: 231.1573 - val_mae: 13.8940\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.2094 - mae: 16.6297 - val_loss: 223.8453 - val_mae: 13.6284\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.4976 - mae: 16.3683 - val_loss: 216.7452 - val_mae: 13.3653\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.0321 - mae: 16.1092 - val_loss: 210.0418 - val_mae: 13.1244\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 353.9874 - mae: 15.8628 - val_loss: 203.4949 - val_mae: 12.8910\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.1016 - mae: 15.6154 - val_loss: 197.1646 - val_mae: 12.6609\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.4594 - mae: 15.3759 - val_loss: 191.0325 - val_mae: 12.4336\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.0403 - mae: 15.1360 - val_loss: 185.2054 - val_mae: 12.2133\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.9369 - mae: 14.9075 - val_loss: 179.4040 - val_mae: 11.9896\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.8555 - mae: 14.6761 - val_loss: 173.8794 - val_mae: 11.7723\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.0883 - mae: 14.4585 - val_loss: 168.5633 - val_mae: 11.5590\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 303.5410 - mae: 14.2441 - val_loss: 163.3776 - val_mae: 11.3467\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 297.1422 - mae: 14.0319 - val_loss: 158.4177 - val_mae: 11.1394\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.9945 - mae: 13.8269 - val_loss: 153.7040 - val_mae: 10.9385\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.1246 - mae: 13.6274 - val_loss: 149.1485 - val_mae: 10.7403\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.4203 - mae: 13.4311 - val_loss: 144.7122 - val_mae: 10.5434\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.8474 - mae: 13.2426 - val_loss: 140.4196 - val_mae: 10.3490\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.4366 - mae: 13.0464 - val_loss: 136.2978 - val_mae: 10.1584\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.2115 - mae: 12.8571 - val_loss: 132.3371 - val_mae: 9.9841\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.1651 - mae: 12.6794 - val_loss: 128.5021 - val_mae: 9.8141\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.2581 - mae: 12.5008 - val_loss: 124.7888 - val_mae: 9.6460\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.4989 - mae: 12.3219 - val_loss: 121.2429 - val_mae: 9.4820\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.9113 - mae: 12.1595 - val_loss: 117.8544 - val_mae: 9.3221\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.5161 - mae: 11.9974 - val_loss: 114.6033 - val_mae: 9.1654\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.2718 - mae: 11.8400 - val_loss: 111.3887 - val_mae: 9.0072\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 231.0464 - mae: 11.6827 - val_loss: 108.2626 - val_mae: 8.8575\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.9373 - mae: 11.5263 - val_loss: 105.3499 - val_mae: 8.7208\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.0688 - mae: 11.3773 - val_loss: 102.4977 - val_mae: 8.5841\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.2773 - mae: 11.2298 - val_loss: 99.7545 - val_mae: 8.4497\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.5840 - mae: 11.0882 - val_loss: 97.1094 - val_mae: 8.3173\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.0298 - mae: 10.9485 - val_loss: 94.6129 - val_mae: 8.2014\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 208.6292 - mae: 10.8186 - val_loss: 92.1339 - val_mae: 8.0841\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.2525 - mae: 10.6829 - val_loss: 89.7591 - val_mae: 7.9691\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.9941 - mae: 10.5530 - val_loss: 87.5020 - val_mae: 7.8574\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.8694 - mae: 10.4254 - val_loss: 85.3308 - val_mae: 7.7553\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.8501 - mae: 10.3105 - val_loss: 83.1926 - val_mae: 7.6562\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.8552 - mae: 10.1912 - val_loss: 81.1509 - val_mae: 7.5594\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.9866 - mae: 10.0772 - val_loss: 79.2323 - val_mae: 7.4711\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.2543 - mae: 9.9709 - val_loss: 77.3868 - val_mae: 7.3902\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.6128 - mae: 9.8651 - val_loss: 75.6029 - val_mae: 7.3103\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 182.0434 - mae: 9.7674 - val_loss: 73.8834 - val_mae: 7.2313\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.5597 - mae: 9.6730 - val_loss: 72.2537 - val_mae: 7.1548\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.1643 - mae: 9.5771 - val_loss: 70.6434 - val_mae: 7.0773\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 174.7991 - mae: 9.4862 - val_loss: 69.1477 - val_mae: 7.0036\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.5733 - mae: 9.4007 - val_loss: 67.6496 - val_mae: 6.9280\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.3372 - mae: 9.3130 - val_loss: 66.2402 - val_mae: 6.8550\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 168.2004 - mae: 9.2321 - val_loss: 64.8818 - val_mae: 6.7830\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.1405 - mae: 9.1512 - val_loss: 63.6142 - val_mae: 6.7141\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.1855 - mae: 9.0804 - val_loss: 62.3535 - val_mae: 6.6439\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.2318 - mae: 9.0095 - val_loss: 61.1446 - val_mae: 6.5748\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.3372 - mae: 8.9370 - val_loss: 59.9738 - val_mae: 6.5062\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.4900 - mae: 8.8689 - val_loss: 58.8605 - val_mae: 6.4392\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.7286 - mae: 8.8071 - val_loss: 57.8226 - val_mae: 6.3751\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 155.0396 - mae: 8.7411 - val_loss: 56.7738 - val_mae: 6.3085\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 153.3408 - mae: 8.6800 - val_loss: 55.8301 - val_mae: 6.2471\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 151.7827 - mae: 8.6219 - val_loss: 54.8995 - val_mae: 6.1848\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.2435 - mae: 8.5683 - val_loss: 54.0009 - val_mae: 6.1231\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.7321 - mae: 8.5154 - val_loss: 53.1701 - val_mae: 6.0644\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 147.3122 - mae: 8.4617 - val_loss: 52.3548 - val_mae: 6.0129\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.9084 - mae: 8.4128 - val_loss: 51.5545 - val_mae: 5.9611\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 144.5175 - mae: 8.3602 - val_loss: 50.8175 - val_mae: 5.9121\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.2140 - mae: 8.3143 - val_loss: 50.1030 - val_mae: 5.8631\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 141.9377 - mae: 8.2679 - val_loss: 49.4285 - val_mae: 5.8155\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.7155 - mae: 8.2207 - val_loss: 48.7614 - val_mae: 5.7671\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.4926 - mae: 8.1812 - val_loss: 48.1185 - val_mae: 5.7189\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.2978 - mae: 8.1327 - val_loss: 47.5168 - val_mae: 5.6724\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.1659 - mae: 8.0911 - val_loss: 46.9640 - val_mae: 5.6283\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.1028 - mae: 8.0564 - val_loss: 46.4177 - val_mae: 5.5834\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.0484 - mae: 8.0184 - val_loss: 45.9040 - val_mae: 5.5462\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.0226 - mae: 7.9835 - val_loss: 45.3951 - val_mae: 5.5143\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.0041 - mae: 7.9469 - val_loss: 44.9315 - val_mae: 5.4852\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.0538 - mae: 7.9142 - val_loss: 44.4918 - val_mae: 5.4567\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1367 - mae: 7.8790 - val_loss: 44.0707 - val_mae: 5.4312\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.2451 - mae: 7.8498 - val_loss: 43.6535 - val_mae: 5.4086\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 129.3472 - mae: 7.8172 - val_loss: 43.2752 - val_mae: 5.3874\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.5185 - mae: 7.7890 - val_loss: 42.9097 - val_mae: 5.3662\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.6952 - mae: 7.7586 - val_loss: 42.5768 - val_mae: 5.3509\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 70.1714 - mae: 6.0644\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 12526.9482 - mae: 61.0319 - val_loss: 496.4185 - val_mae: 20.6065\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.4812 - mae: 20.3658 - val_loss: 465.3731 - val_mae: 19.8389\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.3799 - mae: 19.5052 - val_loss: 425.9762 - val_mae: 18.8198\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 413.7061 - mae: 18.3408 - val_loss: 373.5205 - val_mae: 17.3703\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.7887 - mae: 16.6398 - val_loss: 306.4313 - val_mae: 15.4304\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.9449 - mae: 14.3306 - val_loss: 230.8978 - val_mae: 12.9265\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.2872 - mae: 11.6135 - val_loss: 160.7481 - val_mae: 10.1435\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 146.2330 - mae: 8.9645 - val_loss: 113.1823 - val_mae: 7.9012\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8431 - mae: 7.4689 - val_loss: 87.8806 - val_mae: 6.4506\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9230 - mae: 6.6493 - val_loss: 76.9443 - val_mae: 6.1049\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3673 - mae: 6.3461 - val_loss: 73.2538 - val_mae: 6.1439\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0834 - mae: 6.3179 - val_loss: 72.2922 - val_mae: 6.1997\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3064 - mae: 6.3079 - val_loss: 71.9048 - val_mae: 6.2410\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1155 - mae: 6.3374 - val_loss: 71.8068 - val_mae: 6.2663\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9707 - mae: 6.3701 - val_loss: 71.8087 - val_mae: 6.2649\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.0043 - mae: 6.3604 - val_loss: 71.7933 - val_mae: 6.2929\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.9924 - mae: 6.3804 - val_loss: 71.8002 - val_mae: 6.2723\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.0209 - mae: 6.3581 - val_loss: 71.8032 - val_mae: 6.2694\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.0093 - mae: 6.3627 - val_loss: 71.8042 - val_mae: 6.2685\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.9791 - mae: 6.3525 - val_loss: 71.7930 - val_mae: 6.2854\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.0851 - mae: 6.3703 - val_loss: 71.7975 - val_mae: 6.2755\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9515 - mae: 6.3486 - val_loss: 71.7928 - val_mae: 6.2901\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.0279 - mae: 6.3502 - val_loss: 71.8140 - val_mae: 6.3154\n",
      "Epoch 23: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 99.9715 - mae: 7.0102\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   1.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 85944.2422 - mae: 125.0431 - val_loss: 454.4077 - val_mae: 20.4033\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 603.7437 - mae: 22.8139 - val_loss: 452.9227 - val_mae: 20.3669\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 602.0850 - mae: 22.7772 - val_loss: 451.4494 - val_mae: 20.3307\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 600.4366 - mae: 22.7411 - val_loss: 449.9574 - val_mae: 20.2940\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.7698 - mae: 22.7045 - val_loss: 448.4869 - val_mae: 20.2577\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 597.1265 - mae: 22.6678 - val_loss: 447.0280 - val_mae: 20.2217\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.4941 - mae: 22.6321 - val_loss: 445.5702 - val_mae: 20.1856\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 593.8632 - mae: 22.5964 - val_loss: 444.1100 - val_mae: 20.1494\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 592.2285 - mae: 22.5600 - val_loss: 442.6455 - val_mae: 20.1130\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 590.5907 - mae: 22.5235 - val_loss: 441.2034 - val_mae: 20.0771\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 588.9762 - mae: 22.4879 - val_loss: 439.7574 - val_mae: 20.0411\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 587.3577 - mae: 22.4519 - val_loss: 438.3181 - val_mae: 20.0051\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 585.7455 - mae: 22.4160 - val_loss: 436.8748 - val_mae: 19.9690\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 584.1309 - mae: 22.3797 - val_loss: 435.4481 - val_mae: 19.9333\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 582.5317 - mae: 22.3439 - val_loss: 434.0237 - val_mae: 19.8975\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 580.9376 - mae: 22.3080 - val_loss: 432.6161 - val_mae: 19.8621\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 579.3589 - mae: 22.2731 - val_loss: 431.2011 - val_mae: 19.8265\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 577.7730 - mae: 22.2375 - val_loss: 429.7899 - val_mae: 19.7908\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 576.1913 - mae: 22.2023 - val_loss: 428.3828 - val_mae: 19.7553\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 574.6131 - mae: 22.1664 - val_loss: 426.9769 - val_mae: 19.7196\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 573.0363 - mae: 22.1305 - val_loss: 425.5754 - val_mae: 19.6841\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.4658 - mae: 22.0951 - val_loss: 424.1922 - val_mae: 19.6489\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.9128 - mae: 22.0603 - val_loss: 422.8020 - val_mae: 19.6135\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 568.3526 - mae: 22.0247 - val_loss: 421.4155 - val_mae: 19.5781\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 566.7968 - mae: 21.9890 - val_loss: 420.0345 - val_mae: 19.5428\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 565.2463 - mae: 21.9539 - val_loss: 418.6582 - val_mae: 19.5076\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 563.7020 - mae: 21.9190 - val_loss: 417.2900 - val_mae: 19.4725\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 562.1656 - mae: 21.8837 - val_loss: 415.9272 - val_mae: 19.4374\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 560.6339 - mae: 21.8489 - val_loss: 414.5617 - val_mae: 19.4023\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 559.1014 - mae: 21.8132 - val_loss: 413.2150 - val_mae: 19.3676\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.5883 - mae: 21.7786 - val_loss: 411.8765 - val_mae: 19.3330\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.0823 - mae: 21.7443 - val_loss: 410.5211 - val_mae: 19.2979\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.5590 - mae: 21.7091 - val_loss: 409.1751 - val_mae: 19.2630\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.0454 - mae: 21.6744 - val_loss: 407.8323 - val_mae: 19.2281\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 551.5360 - mae: 21.6396 - val_loss: 406.4975 - val_mae: 19.1933\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 550.0353 - mae: 21.6042 - val_loss: 405.1770 - val_mae: 19.1589\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.5494 - mae: 21.5702 - val_loss: 403.8600 - val_mae: 19.1245\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.0684 - mae: 21.5360 - val_loss: 402.5555 - val_mae: 19.0904\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.5986 - mae: 21.5019 - val_loss: 401.2361 - val_mae: 19.0558\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.1140 - mae: 21.4677 - val_loss: 399.9222 - val_mae: 19.0213\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.6346 - mae: 21.4325 - val_loss: 398.6188 - val_mae: 18.9870\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 541.1667 - mae: 21.3984 - val_loss: 397.3217 - val_mae: 18.9528\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 539.7064 - mae: 21.3641 - val_loss: 396.0337 - val_mae: 18.9188\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 538.2544 - mae: 21.3304 - val_loss: 394.7415 - val_mae: 18.8846\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 536.7988 - mae: 21.2959 - val_loss: 393.4540 - val_mae: 18.8505\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 535.3478 - mae: 21.2618 - val_loss: 392.1782 - val_mae: 18.8166\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.9105 - mae: 21.2281 - val_loss: 390.9076 - val_mae: 18.7828\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.4758 - mae: 21.1943 - val_loss: 389.6264 - val_mae: 18.7487\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 531.0314 - mae: 21.1604 - val_loss: 388.3563 - val_mae: 18.7148\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 529.5990 - mae: 21.1266 - val_loss: 387.0941 - val_mae: 18.6810\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 528.1744 - mae: 21.0929 - val_loss: 385.8291 - val_mae: 18.6472\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 526.7477 - mae: 21.0588 - val_loss: 384.5718 - val_mae: 18.6134\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 525.3281 - mae: 21.0252 - val_loss: 383.3149 - val_mae: 18.5796\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 523.9111 - mae: 20.9909 - val_loss: 382.0811 - val_mae: 18.5464\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 522.5161 - mae: 20.9582 - val_loss: 380.8376 - val_mae: 18.5128\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 521.1113 - mae: 20.9246 - val_loss: 379.5962 - val_mae: 18.4793\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.7100 - mae: 20.8910 - val_loss: 378.3691 - val_mae: 18.4460\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 518.3225 - mae: 20.8581 - val_loss: 377.1325 - val_mae: 18.4125\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 516.9259 - mae: 20.8241 - val_loss: 375.9103 - val_mae: 18.3793\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 515.5443 - mae: 20.7910 - val_loss: 374.6896 - val_mae: 18.3460\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.1648 - mae: 20.7580 - val_loss: 373.4782 - val_mae: 18.3130\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 512.7941 - mae: 20.7244 - val_loss: 372.2676 - val_mae: 18.2799\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 511.4251 - mae: 20.6916 - val_loss: 371.0620 - val_mae: 18.2469\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 510.0603 - mae: 20.6588 - val_loss: 369.8500 - val_mae: 18.2137\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 508.6908 - mae: 20.6258 - val_loss: 368.6619 - val_mae: 18.1810\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 507.3450 - mae: 20.5930 - val_loss: 367.4684 - val_mae: 18.1482\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 505.9937 - mae: 20.5602 - val_loss: 366.2756 - val_mae: 18.1153\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 504.6425 - mae: 20.5273 - val_loss: 365.0785 - val_mae: 18.0822\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 503.2880 - mae: 20.4936 - val_loss: 363.8920 - val_mae: 18.0494\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 501.9433 - mae: 20.4614 - val_loss: 362.7147 - val_mae: 18.0167\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 500.6109 - mae: 20.4283 - val_loss: 361.5517 - val_mae: 17.9844\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 499.2911 - mae: 20.3967 - val_loss: 360.3746 - val_mae: 17.9517\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 497.9580 - mae: 20.3634 - val_loss: 359.2160 - val_mae: 17.9194\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 496.6430 - mae: 20.3315 - val_loss: 358.0430 - val_mae: 17.8866\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 495.3138 - mae: 20.2987 - val_loss: 356.8856 - val_mae: 17.8542\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 494.0024 - mae: 20.2668 - val_loss: 355.7408 - val_mae: 17.8221\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.7017 - mae: 20.2340 - val_loss: 354.5831 - val_mae: 17.7896\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.3882 - mae: 20.2014 - val_loss: 353.4340 - val_mae: 17.7573\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 490.0839 - mae: 20.1694 - val_loss: 352.2904 - val_mae: 17.7251\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488.7858 - mae: 20.1371 - val_loss: 351.1422 - val_mae: 17.6926\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 487.4842 - mae: 20.1045 - val_loss: 350.0208 - val_mae: 17.6609\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.2080 - mae: 20.0734 - val_loss: 348.8864 - val_mae: 17.6288\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.9197 - mae: 20.0410 - val_loss: 347.7554 - val_mae: 17.5967\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 483.6345 - mae: 20.0090 - val_loss: 346.6294 - val_mae: 17.5646\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 482.3559 - mae: 19.9773 - val_loss: 345.5121 - val_mae: 17.5328\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 481.0844 - mae: 19.9454 - val_loss: 344.3876 - val_mae: 17.5007\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.8068 - mae: 19.9129 - val_loss: 343.2789 - val_mae: 17.4690\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.5448 - mae: 19.8816 - val_loss: 342.1587 - val_mae: 17.4369\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 477.2725 - mae: 19.8496 - val_loss: 341.0600 - val_mae: 17.4054\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 476.0215 - mae: 19.8175 - val_loss: 339.9594 - val_mae: 17.3737\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 474.7689 - mae: 19.7863 - val_loss: 338.8594 - val_mae: 17.3420\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 473.5182 - mae: 19.7544 - val_loss: 337.7707 - val_mae: 17.3106\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 472.2783 - mae: 19.7234 - val_loss: 336.6831 - val_mae: 17.2792\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.0389 - mae: 19.6920 - val_loss: 335.5945 - val_mae: 17.2477\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.7987 - mae: 19.6600 - val_loss: 334.5089 - val_mae: 17.2162\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.5629 - mae: 19.6289 - val_loss: 333.4350 - val_mae: 17.1849\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 467.3378 - mae: 19.5979 - val_loss: 332.3469 - val_mae: 17.1533\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.0986 - mae: 19.5654 - val_loss: 331.2762 - val_mae: 17.1220\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.8772 - mae: 19.5346 - val_loss: 330.1992 - val_mae: 17.0905\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 463.6497 - mae: 19.5038 - val_loss: 329.1293 - val_mae: 17.0592\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 458.0582 - mae: 19.0474\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 40959828.0000 - mae: 2268.6182 - val_loss: 322.6135 - val_mae: 16.8671\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.7348 - mae: 19.6992 - val_loss: 321.5556 - val_mae: 16.8358\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.4989 - mae: 19.6681 - val_loss: 320.4892 - val_mae: 16.8041\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.2539 - mae: 19.6362 - val_loss: 319.4290 - val_mae: 16.7725\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 487.0162 - mae: 19.6049 - val_loss: 318.3785 - val_mae: 16.7411\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 485.7907 - mae: 19.5730 - val_loss: 317.3380 - val_mae: 16.7100\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.5737 - mae: 19.5422 - val_loss: 316.3015 - val_mae: 16.6790\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.3624 - mae: 19.5120 - val_loss: 315.2606 - val_mae: 16.6478\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.1435 - mae: 19.4802 - val_loss: 314.2150 - val_mae: 16.6163\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.9210 - mae: 19.4487 - val_loss: 313.1750 - val_mae: 16.5850\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 479.7057 - mae: 19.4174 - val_loss: 312.1515 - val_mae: 16.5541\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.5069 - mae: 19.3869 - val_loss: 311.1204 - val_mae: 16.5229\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.3002 - mae: 19.3557 - val_loss: 310.0948 - val_mae: 16.4919\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 476.1005 - mae: 19.3246 - val_loss: 309.0797 - val_mae: 16.4611\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.9103 - mae: 19.2941 - val_loss: 308.0587 - val_mae: 16.4300\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.7145 - mae: 19.2625 - val_loss: 307.0469 - val_mae: 16.3992\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.5283 - mae: 19.2323 - val_loss: 306.0288 - val_mae: 16.3681\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.3360 - mae: 19.2010 - val_loss: 305.0251 - val_mae: 16.3375\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 470.1589 - mae: 19.1708 - val_loss: 304.0180 - val_mae: 16.3066\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.9776 - mae: 19.1395 - val_loss: 303.0186 - val_mae: 16.2759\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.8053 - mae: 19.1085 - val_loss: 302.0240 - val_mae: 16.2453\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.6387 - mae: 19.0783 - val_loss: 301.0368 - val_mae: 16.2149\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.4793 - mae: 19.0480 - val_loss: 300.0459 - val_mae: 16.1843\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.3156 - mae: 19.0172 - val_loss: 299.0492 - val_mae: 16.1535\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.1455 - mae: 18.9862 - val_loss: 298.0696 - val_mae: 16.1232\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.9944 - mae: 18.9560 - val_loss: 297.0884 - val_mae: 16.0927\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.8434 - mae: 18.9256 - val_loss: 296.1288 - val_mae: 16.0629\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.7148 - mae: 18.8960 - val_loss: 295.1633 - val_mae: 16.0328\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.5786 - mae: 18.8658 - val_loss: 294.1996 - val_mae: 16.0027\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.4454 - mae: 18.8357 - val_loss: 293.2363 - val_mae: 15.9726\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.3134 - mae: 18.8055 - val_loss: 292.2881 - val_mae: 15.9429\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.1956 - mae: 18.7760 - val_loss: 291.3196 - val_mae: 15.9125\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.0557 - mae: 18.7454 - val_loss: 290.3639 - val_mae: 15.8824\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.9309 - mae: 18.7155 - val_loss: 289.4135 - val_mae: 15.8525\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.8108 - mae: 18.6858 - val_loss: 288.4584 - val_mae: 15.8223\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.6862 - mae: 18.6550 - val_loss: 287.5121 - val_mae: 15.7924\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.5719 - mae: 18.6255 - val_loss: 286.5796 - val_mae: 15.7628\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.4727 - mae: 18.5959 - val_loss: 285.6490 - val_mae: 15.7333\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.3744 - mae: 18.5662 - val_loss: 284.7149 - val_mae: 15.7036\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.2728 - mae: 18.5370 - val_loss: 283.7821 - val_mae: 15.6738\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.1727 - mae: 18.5067 - val_loss: 282.8548 - val_mae: 15.6442\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.0784 - mae: 18.4771 - val_loss: 281.9329 - val_mae: 15.6147\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.9897 - mae: 18.4480 - val_loss: 281.0115 - val_mae: 15.5852\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.9016 - mae: 18.4186 - val_loss: 280.0907 - val_mae: 15.5556\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.8152 - mae: 18.3880 - val_loss: 279.1780 - val_mae: 15.5263\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.7365 - mae: 18.3595 - val_loss: 278.2739 - val_mae: 15.4971\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.6683 - mae: 18.3302 - val_loss: 277.3755 - val_mae: 15.4681\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.6054 - mae: 18.3014 - val_loss: 276.4656 - val_mae: 15.4387\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.5284 - mae: 18.2723 - val_loss: 275.5535 - val_mae: 15.4091\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.4514 - mae: 18.2427 - val_loss: 274.6629 - val_mae: 15.3802\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.3964 - mae: 18.2135 - val_loss: 273.7664 - val_mae: 15.3510\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.3364 - mae: 18.1843 - val_loss: 272.8736 - val_mae: 15.3219\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.2778 - mae: 18.1553 - val_loss: 271.9833 - val_mae: 15.2928\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.2251 - mae: 18.1261 - val_loss: 271.1062 - val_mae: 15.2641\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.1840 - mae: 18.0975 - val_loss: 270.2166 - val_mae: 15.2350\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.1306 - mae: 18.0684 - val_loss: 269.3324 - val_mae: 15.2059\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.0830 - mae: 18.0396 - val_loss: 268.4575 - val_mae: 15.1771\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.0450 - mae: 18.0106 - val_loss: 267.5856 - val_mae: 15.1484\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.0105 - mae: 17.9823 - val_loss: 266.7059 - val_mae: 15.1193\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.9668 - mae: 17.9527 - val_loss: 265.8323 - val_mae: 15.0904\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.9315 - mae: 17.9237 - val_loss: 264.9723 - val_mae: 15.0619\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.9096 - mae: 17.8952 - val_loss: 264.1151 - val_mae: 15.0334\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.8914 - mae: 17.8668 - val_loss: 263.2587 - val_mae: 15.0049\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.8741 - mae: 17.8383 - val_loss: 262.4043 - val_mae: 14.9764\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.8603 - mae: 17.8103 - val_loss: 261.5589 - val_mae: 14.9481\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.8536 - mae: 17.7820 - val_loss: 260.7051 - val_mae: 14.9195\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.8397 - mae: 17.7529 - val_loss: 259.8676 - val_mae: 14.8914\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.8425 - mae: 17.7251 - val_loss: 259.0167 - val_mae: 14.8628\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.8312 - mae: 17.6961 - val_loss: 258.1766 - val_mae: 14.8345\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.8305 - mae: 17.6684 - val_loss: 257.3382 - val_mae: 14.8063\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 413.8339 - mae: 17.6394 - val_loss: 256.5132 - val_mae: 14.7784\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.8500 - mae: 17.6124 - val_loss: 255.6784 - val_mae: 14.7501\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.8558 - mae: 17.5838 - val_loss: 254.8466 - val_mae: 14.7219\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.8642 - mae: 17.5557 - val_loss: 254.0141 - val_mae: 14.6936\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.8723 - mae: 17.5273 - val_loss: 253.1875 - val_mae: 14.6654\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.8889 - mae: 17.5000 - val_loss: 252.3738 - val_mae: 14.6377\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.9158 - mae: 17.4716 - val_loss: 251.5446 - val_mae: 14.6093\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.9284 - mae: 17.4425 - val_loss: 250.7391 - val_mae: 14.5817\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.9661 - mae: 17.4154 - val_loss: 249.9273 - val_mae: 14.5538\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.9977 - mae: 17.3873 - val_loss: 249.1156 - val_mae: 14.5259\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.0291 - mae: 17.3597 - val_loss: 248.3179 - val_mae: 14.4985\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.0752 - mae: 17.3327 - val_loss: 247.5157 - val_mae: 14.4708\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.1161 - mae: 17.3049 - val_loss: 246.7083 - val_mae: 14.4428\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.1520 - mae: 17.2766 - val_loss: 245.9150 - val_mae: 14.4153\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.2029 - mae: 17.2495 - val_loss: 245.1206 - val_mae: 14.3878\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.2530 - mae: 17.2218 - val_loss: 244.3326 - val_mae: 14.3604\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.3096 - mae: 17.1946 - val_loss: 243.5375 - val_mae: 14.3326\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.3581 - mae: 17.1670 - val_loss: 242.7426 - val_mae: 14.3049\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.4068 - mae: 17.1389 - val_loss: 241.9556 - val_mae: 14.2774\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.4654 - mae: 17.1112 - val_loss: 241.1815 - val_mae: 14.2502\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.5372 - mae: 17.0843 - val_loss: 240.4009 - val_mae: 14.2228\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.6029 - mae: 17.0568 - val_loss: 239.6266 - val_mae: 14.1956\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.6732 - mae: 17.0302 - val_loss: 238.8451 - val_mae: 14.1680\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.7372 - mae: 17.0024 - val_loss: 238.0773 - val_mae: 14.1409\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.8160 - mae: 16.9746 - val_loss: 237.3129 - val_mae: 14.1138\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.8986 - mae: 16.9482 - val_loss: 236.5498 - val_mae: 14.0868\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.9821 - mae: 16.9210 - val_loss: 235.7793 - val_mae: 14.0594\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.0580 - mae: 16.8932 - val_loss: 235.0223 - val_mae: 14.0324\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.1489 - mae: 16.8665 - val_loss: 234.2639 - val_mae: 14.0054\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 386.2381 - mae: 16.8398 - val_loss: 233.5174 - val_mae: 13.9787\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 290.4339 - mae: 15.2528\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=sgd; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2503.0559 - mae: 33.4904 - val_loss: 546.5685 - val_mae: 21.7894\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.5498 - mae: 21.8335 - val_loss: 545.0464 - val_mae: 21.7544\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.0261 - mae: 21.7984 - val_loss: 543.5269 - val_mae: 21.7194\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.5044 - mae: 21.7639 - val_loss: 542.0178 - val_mae: 21.6847\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.9932 - mae: 21.7288 - val_loss: 540.5162 - val_mae: 21.6500\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.4897 - mae: 21.6941 - val_loss: 539.0193 - val_mae: 21.6154\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.9902 - mae: 21.6597 - val_loss: 537.5150 - val_mae: 21.5806\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.4846 - mae: 21.6244 - val_loss: 536.0240 - val_mae: 21.5460\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.9918 - mae: 21.5902 - val_loss: 534.5422 - val_mae: 21.5116\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.5068 - mae: 21.5560 - val_loss: 533.0582 - val_mae: 21.4771\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.0208 - mae: 21.5214 - val_loss: 531.5808 - val_mae: 21.4427\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.5427 - mae: 21.4870 - val_loss: 530.1193 - val_mae: 21.4086\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.0781 - mae: 21.4530 - val_loss: 528.6526 - val_mae: 21.3743\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.6093 - mae: 21.4187 - val_loss: 527.1892 - val_mae: 21.3400\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 535.1440 - mae: 21.3841 - val_loss: 525.7349 - val_mae: 21.3059\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.6868 - mae: 21.3501 - val_loss: 524.2719 - val_mae: 21.2716\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.2228 - mae: 21.3154 - val_loss: 522.8265 - val_mae: 21.2376\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.7754 - mae: 21.2816 - val_loss: 521.3855 - val_mae: 21.2036\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 529.3326 - mae: 21.2480 - val_loss: 519.9542 - val_mae: 21.1698\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.8985 - mae: 21.2143 - val_loss: 518.5185 - val_mae: 21.1359\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 526.4615 - mae: 21.1802 - val_loss: 517.0945 - val_mae: 21.1022\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.0348 - mae: 21.1468 - val_loss: 515.6698 - val_mae: 21.0684\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.6080 - mae: 21.1134 - val_loss: 514.2454 - val_mae: 21.0346\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.1806 - mae: 21.0792 - val_loss: 512.8183 - val_mae: 21.0006\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.7520 - mae: 21.0451 - val_loss: 511.3996 - val_mae: 20.9668\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.3310 - mae: 21.0115 - val_loss: 509.9879 - val_mae: 20.9331\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.9177 - mae: 20.9777 - val_loss: 508.5846 - val_mae: 20.8996\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.5121 - mae: 20.9441 - val_loss: 507.1779 - val_mae: 20.8659\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.1037 - mae: 20.9106 - val_loss: 505.7849 - val_mae: 20.8325\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.7083 - mae: 20.8769 - val_loss: 504.3892 - val_mae: 20.7990\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.3110 - mae: 20.8433 - val_loss: 502.9992 - val_mae: 20.7655\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 510.9181 - mae: 20.8104 - val_loss: 501.6111 - val_mae: 20.7321\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.5294 - mae: 20.7765 - val_loss: 500.2430 - val_mae: 20.6990\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.1588 - mae: 20.7435 - val_loss: 498.8712 - val_mae: 20.6659\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.7839 - mae: 20.7107 - val_loss: 497.4979 - val_mae: 20.6326\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.4105 - mae: 20.6773 - val_loss: 496.1482 - val_mae: 20.5999\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 504.0589 - mae: 20.6439 - val_loss: 494.7992 - val_mae: 20.5671\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 502.7079 - mae: 20.6115 - val_loss: 493.4544 - val_mae: 20.5344\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 501.3604 - mae: 20.5789 - val_loss: 492.1049 - val_mae: 20.5015\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 500.0081 - mae: 20.5464 - val_loss: 490.7596 - val_mae: 20.4687\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 498.6613 - mae: 20.5135 - val_loss: 489.4226 - val_mae: 20.4360\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.3205 - mae: 20.4812 - val_loss: 488.0645 - val_mae: 20.4027\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 495.9617 - mae: 20.4478 - val_loss: 486.7313 - val_mae: 20.3700\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 494.6269 - mae: 20.4149 - val_loss: 485.4070 - val_mae: 20.3375\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 493.2992 - mae: 20.3826 - val_loss: 484.0745 - val_mae: 20.3047\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.9656 - mae: 20.3497 - val_loss: 482.7582 - val_mae: 20.2723\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 490.6476 - mae: 20.3168 - val_loss: 481.4498 - val_mae: 20.2400\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.3367 - mae: 20.2851 - val_loss: 480.1403 - val_mae: 20.2076\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 488.0249 - mae: 20.2525 - val_loss: 478.8318 - val_mae: 20.1752\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.7147 - mae: 20.2200 - val_loss: 477.5294 - val_mae: 20.1429\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 485.4105 - mae: 20.1876 - val_loss: 476.2355 - val_mae: 20.1108\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 484.1147 - mae: 20.1557 - val_loss: 474.9400 - val_mae: 20.0785\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 482.8161 - mae: 20.1238 - val_loss: 473.6432 - val_mae: 20.0462\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 481.5173 - mae: 20.0912 - val_loss: 472.3517 - val_mae: 20.0140\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 480.2243 - mae: 20.0593 - val_loss: 471.0701 - val_mae: 19.9819\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.9412 - mae: 20.0271 - val_loss: 469.7958 - val_mae: 19.9500\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 477.6637 - mae: 19.9954 - val_loss: 468.5156 - val_mae: 19.9179\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 476.3815 - mae: 19.9631 - val_loss: 467.2411 - val_mae: 19.8859\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 475.1050 - mae: 19.9315 - val_loss: 465.9645 - val_mae: 19.8538\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 473.8276 - mae: 19.8991 - val_loss: 464.7090 - val_mae: 19.8221\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 472.5686 - mae: 19.8676 - val_loss: 463.4406 - val_mae: 19.7901\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.2987 - mae: 19.8352 - val_loss: 462.1863 - val_mae: 19.7584\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 470.0429 - mae: 19.8035 - val_loss: 460.9426 - val_mae: 19.7269\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 468.7970 - mae: 19.7725 - val_loss: 459.6964 - val_mae: 19.6953\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.5491 - mae: 19.7404 - val_loss: 458.4598 - val_mae: 19.6639\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.3094 - mae: 19.7092 - val_loss: 457.2113 - val_mae: 19.6321\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 465.0594 - mae: 19.6776 - val_loss: 455.9745 - val_mae: 19.6006\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 463.8214 - mae: 19.6459 - val_loss: 454.7524 - val_mae: 19.5694\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.5955 - mae: 19.6151 - val_loss: 453.5118 - val_mae: 19.5376\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.3544 - mae: 19.5832 - val_loss: 452.2957 - val_mae: 19.5065\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 460.1353 - mae: 19.5522 - val_loss: 451.0746 - val_mae: 19.4752\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 458.9124 - mae: 19.5208 - val_loss: 449.8616 - val_mae: 19.4440\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 457.6982 - mae: 19.4900 - val_loss: 448.6551 - val_mae: 19.4129\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.4889 - mae: 19.4586 - val_loss: 447.4481 - val_mae: 19.3818\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 455.2799 - mae: 19.4276 - val_loss: 446.2452 - val_mae: 19.3508\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 454.0746 - mae: 19.3964 - val_loss: 445.0429 - val_mae: 19.3197\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.8708 - mae: 19.3652 - val_loss: 443.8474 - val_mae: 19.2887\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.6725 - mae: 19.3342 - val_loss: 442.6474 - val_mae: 19.2576\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.4724 - mae: 19.3024 - val_loss: 441.4738 - val_mae: 19.2271\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.2959 - mae: 19.2726 - val_loss: 440.2961 - val_mae: 19.1964\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.1147 - mae: 19.2422 - val_loss: 439.0995 - val_mae: 19.1653\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 446.9166 - mae: 19.2107 - val_loss: 437.9161 - val_mae: 19.1343\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.7307 - mae: 19.1803 - val_loss: 436.7294 - val_mae: 19.1033\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.5426 - mae: 19.1492 - val_loss: 435.5582 - val_mae: 19.0726\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 443.3702 - mae: 19.1180 - val_loss: 434.3982 - val_mae: 19.0422\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.2078 - mae: 19.0877 - val_loss: 433.2390 - val_mae: 19.0117\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.0468 - mae: 19.0575 - val_loss: 432.0867 - val_mae: 18.9814\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.8918 - mae: 19.0271 - val_loss: 430.9340 - val_mae: 18.9510\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.7373 - mae: 18.9969 - val_loss: 429.7855 - val_mae: 18.9207\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.5876 - mae: 18.9666 - val_loss: 428.6436 - val_mae: 18.8905\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.4422 - mae: 18.9366 - val_loss: 427.4934 - val_mae: 18.8600\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.2893 - mae: 18.9062 - val_loss: 426.3375 - val_mae: 18.8294\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.1323 - mae: 18.8752 - val_loss: 425.2003 - val_mae: 18.7991\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.9942 - mae: 18.8446 - val_loss: 424.0753 - val_mae: 18.7692\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.8659 - mae: 18.8150 - val_loss: 422.9385 - val_mae: 18.7389\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.7285 - mae: 18.7845 - val_loss: 421.8228 - val_mae: 18.7091\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.6096 - mae: 18.7550 - val_loss: 420.6990 - val_mae: 18.6790\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.4840 - mae: 18.7246 - val_loss: 419.5783 - val_mae: 18.6490\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.3614 - mae: 18.6947 - val_loss: 418.4612 - val_mae: 18.6190\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.2428 - mae: 18.6644 - val_loss: 417.3559 - val_mae: 18.5893\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 504.5820 - mae: 20.1657\n",
      "[CV] END learning_rate=0.0001, momentum=0.1, n_hidden=1, n_neurons=5, optimizer=sgd; total time=   4.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 102146.9688 - mae: 303.4811 - val_loss: 105027.7891 - val_mae: 308.9328\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97558.7734 - mae: 296.2278 - val_loss: 100331.6172 - val_mae: 301.6622\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 93041.8047 - mae: 288.9828 - val_loss: 95789.6406 - val_mae: 294.4612\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88697.7734 - mae: 281.8092 - val_loss: 91385.0078 - val_mae: 287.3118\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84550.6875 - mae: 274.7254 - val_loss: 87132.1484 - val_mae: 280.2383\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80446.1250 - mae: 267.6825 - val_loss: 83057.3203 - val_mae: 273.2911\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76586.1797 - mae: 260.7769 - val_loss: 79098.7188 - val_mae: 266.3756\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72803.6250 - mae: 253.8885 - val_loss: 75301.2656 - val_mae: 259.5759\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69196.1875 - mae: 247.1396 - val_loss: 71634.6406 - val_mae: 252.8385\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65716.9062 - mae: 240.4563 - val_loss: 68137.3828 - val_mae: 246.2444\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62439.4609 - mae: 233.9179 - val_loss: 64745.6758 - val_mae: 239.6861\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59229.8828 - mae: 227.4329 - val_loss: 61540.0898 - val_mae: 233.3180\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56168.8398 - mae: 221.0876 - val_loss: 58461.7656 - val_mae: 227.0385\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53307.2891 - mae: 214.8451 - val_loss: 55467.2344 - val_mae: 220.7696\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50441.3320 - mae: 208.6345 - val_loss: 52644.0195 - val_mae: 214.6898\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47762.7930 - mae: 202.5608 - val_loss: 49917.4922 - val_mae: 208.6566\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45243.4102 - mae: 196.5764 - val_loss: 47269.6719 - val_mae: 202.6391\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42783.2773 - mae: 190.6443 - val_loss: 44754.0234 - val_mae: 196.7550\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 40419.3359 - mae: 184.8325 - val_loss: 42394.2930 - val_mae: 191.0732\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38197.6992 - mae: 179.1877 - val_loss: 40136.0977 - val_mae: 185.4809\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36079.9844 - mae: 173.6287 - val_loss: 37972.1445 - val_mae: 179.9655\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34068.1328 - mae: 168.1534 - val_loss: 35900.2969 - val_mae: 174.5241\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32168.7109 - mae: 162.7706 - val_loss: 33910.9805 - val_mae: 169.1457\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30315.2520 - mae: 157.4732 - val_loss: 32041.2344 - val_mae: 163.9396\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28586.4844 - mae: 152.3110 - val_loss: 30261.7324 - val_mae: 158.8283\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26932.8301 - mae: 147.2558 - val_loss: 28574.4355 - val_mae: 153.8323\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25378.5938 - mae: 142.2898 - val_loss: 26958.2969 - val_mae: 148.9023\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23895.1758 - mae: 137.4393 - val_loss: 25436.1992 - val_mae: 144.1104\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22514.5137 - mae: 132.6964 - val_loss: 23975.3984 - val_mae: 139.3614\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21151.0508 - mae: 127.9977 - val_loss: 22611.3281 - val_mae: 134.7863\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19910.5039 - mae: 123.4613 - val_loss: 21305.2207 - val_mae: 130.2667\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18720.3340 - mae: 118.9971 - val_loss: 20066.2324 - val_mae: 125.8355\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17612.5195 - mae: 114.6354 - val_loss: 18891.2012 - val_mae: 121.4920\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16539.3633 - mae: 110.3690 - val_loss: 17807.1094 - val_mae: 117.3516\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15559.6689 - mae: 106.2778 - val_loss: 16780.3652 - val_mae: 113.3031\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14603.4121 - mae: 102.2833 - val_loss: 15823.4189 - val_mae: 109.3954\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13755.5400 - mae: 98.3757 - val_loss: 14874.9150 - val_mae: 105.3988\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12910.8018 - mae: 94.4847 - val_loss: 13992.6328 - val_mae: 101.5532\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12131.6758 - mae: 90.7660 - val_loss: 13161.1338 - val_mae: 97.7999\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11394.9756 - mae: 87.1982 - val_loss: 12388.1992 - val_mae: 94.1867\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10702.8613 - mae: 83.7591 - val_loss: 11666.3438 - val_mae: 90.6941\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10061.0723 - mae: 80.4893 - val_loss: 10990.9873 - val_mae: 87.3110\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9458.7539 - mae: 77.3481 - val_loss: 10356.0254 - val_mae: 84.0186\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8917.4023 - mae: 74.2992 - val_loss: 9739.9053 - val_mae: 80.7138\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8370.0811 - mae: 71.3718 - val_loss: 9184.2480 - val_mae: 77.6227\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7891.3047 - mae: 68.6012 - val_loss: 8658.1289 - val_mae: 74.5873\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7436.6704 - mae: 65.9381 - val_loss: 8165.5527 - val_mae: 71.6406\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7010.8945 - mae: 63.4096 - val_loss: 7704.9004 - val_mae: 68.7917\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6617.3911 - mae: 61.0033 - val_loss: 7275.7695 - val_mae: 66.0723\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6252.1943 - mae: 58.7217 - val_loss: 6868.5146 - val_mae: 63.5247\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5907.3423 - mae: 56.5478 - val_loss: 6493.3105 - val_mae: 61.0889\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5587.9819 - mae: 54.5381 - val_loss: 6140.9136 - val_mae: 58.7424\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5292.7764 - mae: 52.6562 - val_loss: 5813.3877 - val_mae: 56.6666\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5019.3652 - mae: 50.9364 - val_loss: 5506.6772 - val_mae: 54.7146\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4770.0288 - mae: 49.2502 - val_loss: 5215.4531 - val_mae: 52.8043\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4525.2056 - mae: 47.7243 - val_loss: 4952.0063 - val_mae: 51.2692\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4310.0830 - mae: 46.3508 - val_loss: 4704.9058 - val_mae: 49.8866\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4114.1870 - mae: 45.2375 - val_loss: 4467.2583 - val_mae: 48.5078\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3917.1033 - mae: 44.1108 - val_loss: 4258.2158 - val_mae: 47.2474\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3753.4285 - mae: 43.2060 - val_loss: 4058.1169 - val_mae: 46.0183\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3592.4019 - mae: 42.3360 - val_loss: 3873.5186 - val_mae: 44.9260\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3444.5330 - mae: 41.6734 - val_loss: 3703.8452 - val_mae: 43.9340\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3311.8940 - mae: 41.0906 - val_loss: 3544.2375 - val_mae: 43.0085\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3187.9424 - mae: 40.6038 - val_loss: 3393.2502 - val_mae: 42.1933\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3070.2937 - mae: 40.1252 - val_loss: 3255.4207 - val_mae: 41.4845\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2967.9009 - mae: 39.7038 - val_loss: 3120.7651 - val_mae: 40.7952\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2865.7361 - mae: 39.2452 - val_loss: 2998.3452 - val_mae: 40.1434\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2776.4448 - mae: 38.9234 - val_loss: 2883.7588 - val_mae: 39.5086\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2688.6726 - mae: 38.5785 - val_loss: 2783.8967 - val_mae: 38.9350\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2615.1453 - mae: 38.2609 - val_loss: 2688.4092 - val_mae: 38.3652\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2543.3591 - mae: 37.9460 - val_loss: 2601.2722 - val_mae: 37.8265\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2482.1577 - mae: 37.6875 - val_loss: 2513.8933 - val_mae: 37.2671\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2417.1335 - mae: 37.3881 - val_loss: 2439.8047 - val_mae: 36.7762\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2365.1057 - mae: 37.1547 - val_loss: 2365.8342 - val_mae: 36.2692\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2313.1443 - mae: 36.9363 - val_loss: 2296.4661 - val_mae: 35.7775\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2264.1560 - mae: 36.7036 - val_loss: 2232.9773 - val_mae: 35.3125\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2218.4673 - mae: 36.4925 - val_loss: 2173.2278 - val_mae: 34.8956\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2175.5679 - mae: 36.3259 - val_loss: 2118.9866 - val_mae: 34.5320\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2138.9985 - mae: 36.1711 - val_loss: 2065.7778 - val_mae: 34.1722\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2100.3267 - mae: 35.9955 - val_loss: 2018.5635 - val_mae: 33.8693\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2068.5464 - mae: 35.8627 - val_loss: 1971.2432 - val_mae: 33.5573\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2035.1659 - mae: 35.7156 - val_loss: 1924.8712 - val_mae: 33.2414\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2004.2205 - mae: 35.5761 - val_loss: 1882.4810 - val_mae: 32.9425\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1975.5437 - mae: 35.4398 - val_loss: 1844.1228 - val_mae: 32.6691\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1949.0830 - mae: 35.3057 - val_loss: 1808.6119 - val_mae: 32.4402\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1924.0151 - mae: 35.1757 - val_loss: 1774.6886 - val_mae: 32.2326\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1899.9640 - mae: 35.0453 - val_loss: 1743.1908 - val_mae: 32.0297\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1879.3342 - mae: 34.9492 - val_loss: 1710.2500 - val_mae: 31.8180\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1857.1790 - mae: 34.8296 - val_loss: 1679.2202 - val_mae: 31.6059\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1834.2759 - mae: 34.6921 - val_loss: 1651.7222 - val_mae: 31.4097\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1815.5133 - mae: 34.5896 - val_loss: 1623.7896 - val_mae: 31.2086\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1795.1769 - mae: 34.4659 - val_loss: 1597.7648 - val_mae: 31.0082\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1776.1694 - mae: 34.3495 - val_loss: 1571.8286 - val_mae: 30.8079\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1757.9504 - mae: 34.2499 - val_loss: 1546.6406 - val_mae: 30.6105\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1738.8934 - mae: 34.1326 - val_loss: 1523.9537 - val_mae: 30.4220\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1722.4349 - mae: 34.0208 - val_loss: 1500.6542 - val_mae: 30.2392\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1706.1927 - mae: 33.9207 - val_loss: 1477.4745 - val_mae: 30.0689\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1687.5583 - mae: 33.7926 - val_loss: 1458.3433 - val_mae: 29.9106\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1672.9750 - mae: 33.6915 - val_loss: 1436.2080 - val_mae: 29.7368\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1657.2029 - mae: 33.5872 - val_loss: 1415.5232 - val_mae: 29.5666\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1857.9338 - mae: 35.0290\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 10192.6133 - mae: 69.3379 - val_loss: 10877.6309 - val_mae: 76.4472\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9661.3984 - mae: 68.9122 - val_loss: 10282.1787 - val_mae: 74.9816\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9222.2393 - mae: 68.8644 - val_loss: 9774.4678 - val_mae: 73.6566\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8819.0518 - mae: 68.5571 - val_loss: 9337.2803 - val_mae: 72.5358\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8476.3652 - mae: 68.0097 - val_loss: 8938.3262 - val_mae: 71.4651\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8152.0854 - mae: 67.2479 - val_loss: 8566.2324 - val_mae: 70.3546\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7855.1616 - mae: 66.3436 - val_loss: 8212.8643 - val_mae: 69.1753\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7567.2915 - mae: 65.4805 - val_loss: 7864.0684 - val_mae: 68.0939\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7262.1694 - mae: 64.4096 - val_loss: 7549.1519 - val_mae: 66.9547\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6984.1348 - mae: 63.3502 - val_loss: 7244.4917 - val_mae: 65.8411\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6728.4766 - mae: 62.3049 - val_loss: 6937.2251 - val_mae: 64.6842\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6463.1177 - mae: 61.1489 - val_loss: 6654.5181 - val_mae: 63.5001\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6212.8452 - mae: 60.0062 - val_loss: 6379.5259 - val_mae: 62.3560\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5986.4194 - mae: 59.0344 - val_loss: 6099.7104 - val_mae: 61.2583\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5739.5825 - mae: 57.9185 - val_loss: 5838.7788 - val_mae: 60.0836\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5513.7666 - mae: 56.7259 - val_loss: 5594.8188 - val_mae: 58.8571\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5300.4292 - mae: 55.5605 - val_loss: 5354.2612 - val_mae: 57.7035\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5077.6821 - mae: 54.4076 - val_loss: 5129.4258 - val_mae: 56.5969\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4879.4712 - mae: 53.3241 - val_loss: 4901.9282 - val_mae: 55.4352\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4683.2319 - mae: 52.2140 - val_loss: 4682.1646 - val_mae: 54.3009\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4496.3086 - mae: 51.1942 - val_loss: 4470.2393 - val_mae: 53.2425\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4302.5840 - mae: 50.1936 - val_loss: 4277.4385 - val_mae: 52.2170\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4129.6357 - mae: 49.1723 - val_loss: 4090.2908 - val_mae: 51.1503\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3964.8560 - mae: 48.1921 - val_loss: 3903.1980 - val_mae: 50.0871\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3797.5667 - mae: 47.1877 - val_loss: 3730.1890 - val_mae: 49.0431\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3643.3665 - mae: 46.2056 - val_loss: 3558.4229 - val_mae: 47.9993\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3488.8618 - mae: 45.2031 - val_loss: 3396.7996 - val_mae: 46.9437\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3349.8660 - mae: 44.3355 - val_loss: 3233.5403 - val_mae: 45.9658\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3196.9060 - mae: 43.3973 - val_loss: 3088.8845 - val_mae: 44.9737\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3064.0151 - mae: 42.5199 - val_loss: 2945.2666 - val_mae: 43.9846\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2937.7039 - mae: 41.6290 - val_loss: 2807.8110 - val_mae: 42.9513\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2812.6082 - mae: 40.7128 - val_loss: 2678.9128 - val_mae: 41.9656\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2692.8760 - mae: 39.9044 - val_loss: 2554.0764 - val_mae: 41.0559\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2580.5969 - mae: 39.1249 - val_loss: 2430.8372 - val_mae: 40.0991\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2476.3914 - mae: 38.3940 - val_loss: 2305.6018 - val_mae: 39.2164\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2359.0352 - mae: 37.5926 - val_loss: 2198.9348 - val_mae: 38.3328\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2262.6521 - mae: 36.8700 - val_loss: 2094.5466 - val_mae: 37.4656\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2166.0200 - mae: 36.1456 - val_loss: 1993.5322 - val_mae: 36.6121\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2072.5808 - mae: 35.4484 - val_loss: 1897.3063 - val_mae: 35.7580\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1984.9432 - mae: 34.7134 - val_loss: 1802.9640 - val_mae: 34.8939\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1902.5063 - mae: 34.0004 - val_loss: 1709.7506 - val_mae: 34.0494\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1815.7408 - mae: 33.2958 - val_loss: 1626.9369 - val_mae: 33.2449\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1741.8396 - mae: 32.6037 - val_loss: 1546.9304 - val_mae: 32.3966\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1669.8209 - mae: 31.9471 - val_loss: 1470.0448 - val_mae: 31.6437\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1595.8220 - mae: 31.2650 - val_loss: 1399.3984 - val_mae: 30.8919\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1526.7655 - mae: 30.5970 - val_loss: 1333.3047 - val_mae: 30.1335\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1463.4933 - mae: 29.9241 - val_loss: 1269.2111 - val_mae: 29.4263\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1405.1893 - mae: 29.2792 - val_loss: 1203.4519 - val_mae: 28.7124\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1342.4569 - mae: 28.6812 - val_loss: 1143.6829 - val_mae: 28.0520\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1287.0310 - mae: 28.1166 - val_loss: 1084.7938 - val_mae: 27.3969\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1231.7272 - mae: 27.5852 - val_loss: 1029.2948 - val_mae: 26.7410\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1176.1364 - mae: 27.0000 - val_loss: 977.6816 - val_mae: 26.0921\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1129.2059 - mae: 26.4708 - val_loss: 926.8124 - val_mae: 25.4725\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1079.9323 - mae: 25.9341 - val_loss: 880.4996 - val_mae: 24.9111\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1033.7570 - mae: 25.4005 - val_loss: 836.7445 - val_mae: 24.3426\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 991.3329 - mae: 24.9013 - val_loss: 795.3534 - val_mae: 23.8052\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 950.0770 - mae: 24.3810 - val_loss: 756.3118 - val_mae: 23.2360\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 912.3015 - mae: 23.8985 - val_loss: 718.4543 - val_mae: 22.7017\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 875.6176 - mae: 23.4106 - val_loss: 681.7608 - val_mae: 22.1403\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 839.3919 - mae: 22.9183 - val_loss: 648.8555 - val_mae: 21.6370\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 806.2101 - mae: 22.4648 - val_loss: 617.4360 - val_mae: 21.1401\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 775.6635 - mae: 22.0435 - val_loss: 586.6022 - val_mae: 20.6479\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 744.2651 - mae: 21.5993 - val_loss: 557.5447 - val_mae: 20.1504\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 714.5607 - mae: 21.1757 - val_loss: 530.6664 - val_mae: 19.6779\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8417 - mae: 20.7599 - val_loss: 505.2242 - val_mae: 19.2097\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.6332 - mae: 20.3699 - val_loss: 480.2693 - val_mae: 18.7826\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.5265 - mae: 19.9775 - val_loss: 457.5494 - val_mae: 18.3528\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.3196 - mae: 19.6240 - val_loss: 435.7663 - val_mae: 17.9256\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.8917 - mae: 19.2738 - val_loss: 416.3348 - val_mae: 17.5360\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.8246 - mae: 18.9300 - val_loss: 395.7905 - val_mae: 17.0675\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.9185 - mae: 18.5742 - val_loss: 377.6483 - val_mae: 16.6751\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.5729 - mae: 18.2397 - val_loss: 359.7714 - val_mae: 16.2617\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.7112 - mae: 17.8771 - val_loss: 343.2339 - val_mae: 15.8467\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.9247 - mae: 17.5570 - val_loss: 327.4801 - val_mae: 15.4546\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.3073 - mae: 17.2771 - val_loss: 314.5188 - val_mae: 15.1569\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.6775 - mae: 17.0085 - val_loss: 300.5758 - val_mae: 14.7856\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.5060 - mae: 16.7192 - val_loss: 287.6598 - val_mae: 14.4374\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.8031 - mae: 16.4602 - val_loss: 276.3061 - val_mae: 14.1254\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 413.6873 - mae: 16.1891 - val_loss: 264.4130 - val_mae: 13.7721\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.5209 - mae: 15.8945 - val_loss: 252.6836 - val_mae: 13.4127\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.9368 - mae: 15.6568 - val_loss: 242.9482 - val_mae: 13.1499\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.0624 - mae: 15.3775 - val_loss: 232.1596 - val_mae: 12.7837\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.0426 - mae: 15.1257 - val_loss: 223.1834 - val_mae: 12.5154\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.4163 - mae: 14.8609 - val_loss: 214.5010 - val_mae: 12.2280\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.4437 - mae: 14.6463 - val_loss: 205.7370 - val_mae: 11.9204\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.0903 - mae: 14.4184 - val_loss: 198.9582 - val_mae: 11.7794\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.2422 - mae: 14.2255 - val_loss: 191.6522 - val_mae: 11.5831\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.2437 - mae: 14.0383 - val_loss: 185.5757 - val_mae: 11.4307\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.3075 - mae: 13.8593 - val_loss: 179.2689 - val_mae: 11.2464\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.5174 - mae: 13.6580 - val_loss: 173.1006 - val_mae: 11.0437\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.2865 - mae: 13.4766 - val_loss: 166.9698 - val_mae: 10.8449\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.1704 - mae: 13.2968 - val_loss: 160.6751 - val_mae: 10.6239\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.5154 - mae: 13.1226 - val_loss: 155.1839 - val_mae: 10.4331\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.5175 - mae: 12.9514 - val_loss: 151.1177 - val_mae: 10.3069\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 264.3996 - mae: 12.8167 - val_loss: 148.0284 - val_mae: 10.2204\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.7235 - mae: 12.6944 - val_loss: 144.1349 - val_mae: 10.0819\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.7412 - mae: 12.5366 - val_loss: 139.5989 - val_mae: 9.9041\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.4183 - mae: 12.3960 - val_loss: 135.8461 - val_mae: 9.7577\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 242.1639 - mae: 12.2562 - val_loss: 132.2428 - val_mae: 9.6076\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.4064 - mae: 12.1209 - val_loss: 128.2110 - val_mae: 9.4384\n",
      "5/5 [==============================] - 0s 998us/step - loss: 194.9747 - mae: 10.7285\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=adam; total time=   3.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 923.8024 - mae: 23.8009 - val_loss: 672.8547 - val_mae: 18.7908\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 692.6082 - mae: 20.9585 - val_loss: 512.6175 - val_mae: 17.4615\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 573.8945 - mae: 19.4569 - val_loss: 441.0334 - val_mae: 17.5131\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 518.0397 - mae: 18.8095 - val_loss: 416.9537 - val_mae: 17.7317\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.5432 - mae: 18.5398 - val_loss: 399.8254 - val_mae: 17.5448\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 463.5286 - mae: 18.0694 - val_loss: 378.6743 - val_mae: 17.0186\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 438.3041 - mae: 17.5179 - val_loss: 356.2997 - val_mae: 16.3568\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.8871 - mae: 16.9799 - val_loss: 336.0116 - val_mae: 15.7150\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.7253 - mae: 16.4982 - val_loss: 318.5139 - val_mae: 15.1710\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.5992 - mae: 16.1005 - val_loss: 301.8170 - val_mae: 14.6942\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.5891 - mae: 15.7053 - val_loss: 286.4368 - val_mae: 14.1940\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.9678 - mae: 15.3293 - val_loss: 272.6419 - val_mae: 13.8099\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 321.2554 - mae: 14.9793 - val_loss: 259.5248 - val_mae: 13.4407\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.8629 - mae: 14.6233 - val_loss: 247.1458 - val_mae: 13.0616\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 294.2978 - mae: 14.3186 - val_loss: 236.3254 - val_mae: 12.7562\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.5769 - mae: 14.0467 - val_loss: 226.5021 - val_mae: 12.4892\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.7118 - mae: 13.7920 - val_loss: 217.3510 - val_mae: 12.2262\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.1521 - mae: 13.5250 - val_loss: 208.9974 - val_mae: 11.9697\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.9932 - mae: 13.2752 - val_loss: 201.7589 - val_mae: 11.7272\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.2493 - mae: 13.0506 - val_loss: 194.5616 - val_mae: 11.5469\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 240.3374 - mae: 12.8439 - val_loss: 188.4406 - val_mae: 11.3947\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 234.2841 - mae: 12.6725 - val_loss: 182.1751 - val_mae: 11.2360\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 228.2200 - mae: 12.5059 - val_loss: 175.9374 - val_mae: 11.0720\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.9267 - mae: 12.3476 - val_loss: 170.8327 - val_mae: 10.9327\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217.8187 - mae: 12.1973 - val_loss: 166.0410 - val_mae: 10.8001\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 213.9757 - mae: 12.1012 - val_loss: 160.9280 - val_mae: 10.6462\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.0112 - mae: 11.9324 - val_loss: 157.5997 - val_mae: 10.5510\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.7353 - mae: 11.7794 - val_loss: 154.2777 - val_mae: 10.4428\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 200.8515 - mae: 11.6488 - val_loss: 149.8151 - val_mae: 10.3090\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.6738 - mae: 11.5789 - val_loss: 145.6106 - val_mae: 10.1728\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 193.6532 - mae: 11.4561 - val_loss: 142.7194 - val_mae: 10.0770\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 190.5862 - mae: 11.3286 - val_loss: 140.1439 - val_mae: 9.9812\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 187.1415 - mae: 11.2100 - val_loss: 137.0527 - val_mae: 9.8763\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 183.7547 - mae: 11.1119 - val_loss: 133.8920 - val_mae: 9.7686\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 181.0503 - mae: 11.0419 - val_loss: 130.6214 - val_mae: 9.6519\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 178.0648 - mae: 10.9510 - val_loss: 128.5613 - val_mae: 9.5690\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 175.8101 - mae: 10.8596 - val_loss: 125.7894 - val_mae: 9.4670\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 172.4041 - mae: 10.7346 - val_loss: 124.4482 - val_mae: 9.4005\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 170.6387 - mae: 10.6214 - val_loss: 123.5102 - val_mae: 9.3334\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 167.6328 - mae: 10.5442 - val_loss: 119.5405 - val_mae: 9.2115\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 164.9259 - mae: 10.4727 - val_loss: 117.4324 - val_mae: 9.1248\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 162.6418 - mae: 10.4039 - val_loss: 115.3735 - val_mae: 9.0405\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 160.4637 - mae: 10.3369 - val_loss: 113.3740 - val_mae: 8.9769\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 157.7317 - mae: 10.2164 - val_loss: 112.0905 - val_mae: 8.8851\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 155.3869 - mae: 10.1000 - val_loss: 110.6237 - val_mae: 8.8100\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 153.3516 - mae: 10.0232 - val_loss: 108.5608 - val_mae: 8.7330\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 151.2164 - mae: 9.9558 - val_loss: 106.8131 - val_mae: 8.6815\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 149.2164 - mae: 9.8826 - val_loss: 105.2322 - val_mae: 8.6156\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 146.9940 - mae: 9.7867 - val_loss: 104.1597 - val_mae: 8.5256\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 145.0630 - mae: 9.7007 - val_loss: 102.4660 - val_mae: 8.4682\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 143.0169 - mae: 9.6183 - val_loss: 101.5159 - val_mae: 8.4113\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 141.1738 - mae: 9.5264 - val_loss: 100.2232 - val_mae: 8.3551\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 139.1528 - mae: 9.4607 - val_loss: 98.5557 - val_mae: 8.2926\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 137.4584 - mae: 9.4229 - val_loss: 96.4683 - val_mae: 8.2369\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 135.6900 - mae: 9.3723 - val_loss: 95.0158 - val_mae: 8.1784\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 133.7018 - mae: 9.2703 - val_loss: 94.1123 - val_mae: 8.1030\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 132.1270 - mae: 9.1708 - val_loss: 93.6774 - val_mae: 8.0293\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.1800 - mae: 9.0704 - val_loss: 92.2249 - val_mae: 7.9675\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128.3770 - mae: 9.0107 - val_loss: 90.4931 - val_mae: 7.9153\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 126.9905 - mae: 8.9942 - val_loss: 88.6751 - val_mae: 7.8695\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125.2546 - mae: 8.9319 - val_loss: 88.2972 - val_mae: 7.7867\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123.4889 - mae: 8.7999 - val_loss: 87.2195 - val_mae: 7.7222\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.9509 - mae: 8.7407 - val_loss: 85.5200 - val_mae: 7.6768\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.4904 - mae: 8.6838 - val_loss: 84.8675 - val_mae: 7.6058\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119.0415 - mae: 8.6176 - val_loss: 83.2286 - val_mae: 7.5600\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117.2510 - mae: 8.5495 - val_loss: 82.6551 - val_mae: 7.4932\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.8994 - mae: 8.4617 - val_loss: 81.7689 - val_mae: 7.4300\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.5726 - mae: 8.4333 - val_loss: 80.0793 - val_mae: 7.3901\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.7302 - mae: 8.3506 - val_loss: 80.0597 - val_mae: 7.3276\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.5978 - mae: 8.2797 - val_loss: 78.2556 - val_mae: 7.2809\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.1544 - mae: 8.2241 - val_loss: 77.6183 - val_mae: 7.2130\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.7916 - mae: 8.1480 - val_loss: 76.8795 - val_mae: 7.1647\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.7804 - mae: 8.0875 - val_loss: 76.2290 - val_mae: 7.1168\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.1486 - mae: 8.0229 - val_loss: 74.8954 - val_mae: 7.0674\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.9717 - mae: 7.9932 - val_loss: 73.8847 - val_mae: 7.0314\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.1860 - mae: 7.9401 - val_loss: 73.9449 - val_mae: 6.9722\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.8057 - mae: 7.8612 - val_loss: 72.1780 - val_mae: 6.9180\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.1356 - mae: 7.8053 - val_loss: 71.7038 - val_mae: 6.8642\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.7404 - mae: 7.7979 - val_loss: 70.3131 - val_mae: 6.8193\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.6354 - mae: 7.6862 - val_loss: 70.2252 - val_mae: 6.7636\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.8989 - mae: 7.6027 - val_loss: 70.0492 - val_mae: 6.7292\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.6018 - mae: 7.5448 - val_loss: 68.1059 - val_mae: 6.6493\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.3261 - mae: 7.5180 - val_loss: 67.1457 - val_mae: 6.5973\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.2151 - mae: 7.4714 - val_loss: 66.2965 - val_mae: 6.5506\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.2682 - mae: 7.4256 - val_loss: 65.6946 - val_mae: 6.5010\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.8348 - mae: 7.3243 - val_loss: 65.4844 - val_mae: 6.4694\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.2474 - mae: 7.2667 - val_loss: 65.3154 - val_mae: 6.4354\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.1468 - mae: 7.2136 - val_loss: 63.6727 - val_mae: 6.3650\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.9577 - mae: 7.1975 - val_loss: 62.7306 - val_mae: 6.3080\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.1840 - mae: 7.1575 - val_loss: 62.1068 - val_mae: 6.2627\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.9502 - mae: 7.0791 - val_loss: 61.8022 - val_mae: 6.2289\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0147 - mae: 7.0243 - val_loss: 61.2563 - val_mae: 6.1867\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.0841 - mae: 6.9803 - val_loss: 60.4104 - val_mae: 6.1351\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.3443 - mae: 6.9593 - val_loss: 59.6175 - val_mae: 6.0815\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2558 - mae: 6.8701 - val_loss: 59.7165 - val_mae: 6.0699\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.7117 - mae: 6.8024 - val_loss: 58.4506 - val_mae: 6.0072\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.7316 - mae: 6.7945 - val_loss: 57.7671 - val_mae: 5.9473\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9549 - mae: 6.7891 - val_loss: 57.2355 - val_mae: 5.9073\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.7902 - mae: 6.6988 - val_loss: 57.1154 - val_mae: 5.8899\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.3366 - mae: 6.6257 - val_loss: 56.1800 - val_mae: 5.8343\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 110.0022 - mae: 8.0327\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=adam; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 5744832.0000 - mae: 1098.1191 - val_loss: 483.2945 - val_mae: 21.0993\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 635.9645 - mae: 23.5095 - val_loss: 481.7121 - val_mae: 21.0618\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 634.2030 - mae: 23.4717 - val_loss: 480.1416 - val_mae: 21.0245\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 632.4521 - mae: 23.4345 - val_loss: 478.5521 - val_mae: 20.9866\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 630.6827 - mae: 23.3967 - val_loss: 476.9850 - val_mae: 20.9493\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 628.9375 - mae: 23.3590 - val_loss: 475.4300 - val_mae: 20.9121\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 627.2038 - mae: 23.3221 - val_loss: 473.8763 - val_mae: 20.8749\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 625.4717 - mae: 23.2853 - val_loss: 472.3203 - val_mae: 20.8376\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 623.7358 - mae: 23.2478 - val_loss: 470.7598 - val_mae: 20.8002\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 621.9971 - mae: 23.2102 - val_loss: 469.2228 - val_mae: 20.7632\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 620.2825 - mae: 23.1736 - val_loss: 467.6819 - val_mae: 20.7260\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 618.5638 - mae: 23.1364 - val_loss: 466.1480 - val_mae: 20.6890\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 616.8519 - mae: 23.0994 - val_loss: 464.6102 - val_mae: 20.6518\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 615.1376 - mae: 23.0621 - val_loss: 463.0896 - val_mae: 20.6150\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 613.4395 - mae: 23.0252 - val_loss: 461.5716 - val_mae: 20.5781\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 611.7466 - mae: 22.9882 - val_loss: 460.0711 - val_mae: 20.5416\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 610.0698 - mae: 22.9522 - val_loss: 458.5632 - val_mae: 20.5049\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.3857 - mae: 22.9155 - val_loss: 457.0592 - val_mae: 20.4682\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.7062 - mae: 22.8792 - val_loss: 455.5596 - val_mae: 20.4315\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.0303 - mae: 22.8422 - val_loss: 454.0614 - val_mae: 20.3948\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.3561 - mae: 22.8053 - val_loss: 452.5680 - val_mae: 20.3582\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 601.6886 - mae: 22.7688 - val_loss: 451.0936 - val_mae: 20.3219\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.0394 - mae: 22.7329 - val_loss: 449.6121 - val_mae: 20.2854\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.3826 - mae: 22.6962 - val_loss: 448.1345 - val_mae: 20.2490\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.7307 - mae: 22.6594 - val_loss: 446.6628 - val_mae: 20.2126\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.0845 - mae: 22.6233 - val_loss: 445.1961 - val_mae: 20.1763\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.4446 - mae: 22.5873 - val_loss: 443.7378 - val_mae: 20.1401\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.8133 - mae: 22.5509 - val_loss: 442.2853 - val_mae: 20.1040\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.1866 - mae: 22.5150 - val_loss: 440.8302 - val_mae: 20.0678\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.5594 - mae: 22.4783 - val_loss: 439.3946 - val_mae: 20.0320\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9525 - mae: 22.4427 - val_loss: 437.9677 - val_mae: 19.9964\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.3530 - mae: 22.4072 - val_loss: 436.5233 - val_mae: 19.9602\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.7357 - mae: 22.3710 - val_loss: 435.0889 - val_mae: 19.9243\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.1287 - mae: 22.3353 - val_loss: 433.6579 - val_mae: 19.8883\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.5260 - mae: 22.2994 - val_loss: 432.2353 - val_mae: 19.8525\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.9327 - mae: 22.2630 - val_loss: 430.8276 - val_mae: 19.8170\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.3546 - mae: 22.2279 - val_loss: 429.4237 - val_mae: 19.7816\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.7817 - mae: 22.1927 - val_loss: 428.0328 - val_mae: 19.7464\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 574.2205 - mae: 22.1575 - val_loss: 426.6267 - val_mae: 19.7108\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.6441 - mae: 22.1222 - val_loss: 425.2265 - val_mae: 19.6752\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.0734 - mae: 22.0860 - val_loss: 423.8371 - val_mae: 19.6399\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.5148 - mae: 22.0509 - val_loss: 422.4545 - val_mae: 19.6046\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.9641 - mae: 22.0155 - val_loss: 421.0813 - val_mae: 19.5696\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.4218 - mae: 21.9807 - val_loss: 419.7039 - val_mae: 19.5344\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8761 - mae: 21.9452 - val_loss: 418.3316 - val_mae: 19.4992\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.3353 - mae: 21.9101 - val_loss: 416.9715 - val_mae: 19.4643\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.8089 - mae: 21.8754 - val_loss: 415.6168 - val_mae: 19.4295\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.2852 - mae: 21.8405 - val_loss: 414.2514 - val_mae: 19.3943\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.7517 - mae: 21.8056 - val_loss: 412.8975 - val_mae: 19.3594\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2307 - mae: 21.7707 - val_loss: 411.5521 - val_mae: 19.3246\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7178 - mae: 21.7361 - val_loss: 410.2037 - val_mae: 19.2897\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.2029 - mae: 21.7009 - val_loss: 408.8635 - val_mae: 19.2549\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 552.6956 - mae: 21.6662 - val_loss: 407.5238 - val_mae: 19.2201\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.1909 - mae: 21.6310 - val_loss: 406.2081 - val_mae: 19.1858\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.7091 - mae: 21.5972 - val_loss: 404.8826 - val_mae: 19.1512\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2175 - mae: 21.5625 - val_loss: 403.5593 - val_mae: 19.1167\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7296 - mae: 21.5280 - val_loss: 402.2509 - val_mae: 19.0824\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.2560 - mae: 21.4940 - val_loss: 400.9328 - val_mae: 19.0478\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.7731 - mae: 21.4591 - val_loss: 399.6299 - val_mae: 19.0136\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.3057 - mae: 21.4249 - val_loss: 398.3284 - val_mae: 18.9793\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.8408 - mae: 21.3909 - val_loss: 397.0369 - val_mae: 18.9453\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.3850 - mae: 21.3563 - val_loss: 395.7462 - val_mae: 18.9112\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.9312 - mae: 21.3224 - val_loss: 394.4608 - val_mae: 18.8772\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.4818 - mae: 21.2887 - val_loss: 393.1689 - val_mae: 18.8429\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.0276 - mae: 21.2547 - val_loss: 391.9019 - val_mae: 18.8093\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.5981 - mae: 21.2209 - val_loss: 390.6294 - val_mae: 18.7754\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 532.1630 - mae: 21.1871 - val_loss: 389.3578 - val_mae: 18.7415\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.7283 - mae: 21.1531 - val_loss: 388.0818 - val_mae: 18.7075\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 529.2902 - mae: 21.1185 - val_loss: 386.8168 - val_mae: 18.6736\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.8624 - mae: 21.0852 - val_loss: 385.5617 - val_mae: 18.6400\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.4472 - mae: 21.0512 - val_loss: 384.3213 - val_mae: 18.6067\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.0454 - mae: 21.0186 - val_loss: 383.0664 - val_mae: 18.5729\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.6298 - mae: 20.9842 - val_loss: 381.8309 - val_mae: 18.5396\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.2330 - mae: 20.9514 - val_loss: 380.5806 - val_mae: 18.5059\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.8219 - mae: 20.9176 - val_loss: 379.3464 - val_mae: 18.4725\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.4291 - mae: 20.8847 - val_loss: 378.1254 - val_mae: 18.4394\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.0475 - mae: 20.8509 - val_loss: 376.8914 - val_mae: 18.4059\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.6528 - mae: 20.8173 - val_loss: 375.6662 - val_mae: 18.3726\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.2679 - mae: 20.7844 - val_loss: 374.4468 - val_mae: 18.3394\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.8894 - mae: 20.7510 - val_loss: 373.2229 - val_mae: 18.3060\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.5074 - mae: 20.7175 - val_loss: 372.0266 - val_mae: 18.2733\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.1518 - mae: 20.6853 - val_loss: 370.8172 - val_mae: 18.2402\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 509.7836 - mae: 20.6520 - val_loss: 369.6113 - val_mae: 18.2071\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.4190 - mae: 20.6190 - val_loss: 368.4108 - val_mae: 18.1741\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.0611 - mae: 20.5863 - val_loss: 367.2193 - val_mae: 18.1413\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.7109 - mae: 20.5535 - val_loss: 366.0205 - val_mae: 18.1082\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.3543 - mae: 20.5200 - val_loss: 364.8381 - val_mae: 18.0755\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.0141 - mae: 20.4878 - val_loss: 363.6441 - val_mae: 18.0425\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.6633 - mae: 20.4547 - val_loss: 362.4721 - val_mae: 18.0100\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.3347 - mae: 20.4217 - val_loss: 361.2986 - val_mae: 17.9774\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.0044 - mae: 20.3896 - val_loss: 360.1258 - val_mae: 17.9447\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6762 - mae: 20.3567 - val_loss: 358.9647 - val_mae: 17.9123\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.3593 - mae: 20.3247 - val_loss: 357.8048 - val_mae: 17.8799\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.0432 - mae: 20.2924 - val_loss: 356.6440 - val_mae: 17.8474\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.7263 - mae: 20.2594 - val_loss: 355.4865 - val_mae: 17.8150\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.4139 - mae: 20.2273 - val_loss: 354.3411 - val_mae: 17.7828\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.1128 - mae: 20.1954 - val_loss: 353.1812 - val_mae: 17.7502\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.7973 - mae: 20.1619 - val_loss: 352.0394 - val_mae: 17.7180\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.5002 - mae: 20.1302 - val_loss: 350.8912 - val_mae: 17.6855\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 487.1970 - mae: 20.0984 - val_loss: 349.7504 - val_mae: 17.6533\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 481.0414 - mae: 19.6414\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=25, optimizer=sgd; total time=   3.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 103739600.0000 - mae: 4783.4995 - val_loss: 339.9441 - val_mae: 17.3733\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.9190 - mae: 20.2050 - val_loss: 338.8263 - val_mae: 17.3411\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.6187 - mae: 20.1731 - val_loss: 337.6999 - val_mae: 17.3086\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.3092 - mae: 20.1404 - val_loss: 336.5798 - val_mae: 17.2762\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.0072 - mae: 20.1083 - val_loss: 335.4701 - val_mae: 17.2441\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.7178 - mae: 20.0756 - val_loss: 334.3705 - val_mae: 17.2121\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.4374 - mae: 20.0440 - val_loss: 333.2753 - val_mae: 17.1803\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.1629 - mae: 20.0130 - val_loss: 332.1756 - val_mae: 17.1483\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.8807 - mae: 19.9804 - val_loss: 331.0712 - val_mae: 17.1160\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.5948 - mae: 19.9480 - val_loss: 329.9726 - val_mae: 17.0839\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.3165 - mae: 19.9160 - val_loss: 328.8910 - val_mae: 17.0522\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 498.0553 - mae: 19.8847 - val_loss: 327.8018 - val_mae: 17.0203\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.7859 - mae: 19.8527 - val_loss: 326.7183 - val_mae: 16.9884\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.5238 - mae: 19.8208 - val_loss: 325.6457 - val_mae: 16.9568\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.2718 - mae: 19.7895 - val_loss: 324.5671 - val_mae: 16.9250\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 493.0139 - mae: 19.7571 - val_loss: 323.4980 - val_mae: 16.8933\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.7660 - mae: 19.7261 - val_loss: 322.4225 - val_mae: 16.8615\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.5120 - mae: 19.6940 - val_loss: 321.3621 - val_mae: 16.8300\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.2736 - mae: 19.6631 - val_loss: 320.2981 - val_mae: 16.7984\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.0310 - mae: 19.6310 - val_loss: 319.2422 - val_mae: 16.7669\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.7978 - mae: 19.5991 - val_loss: 318.1913 - val_mae: 16.7355\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.5705 - mae: 19.5682 - val_loss: 317.1480 - val_mae: 16.7043\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.3507 - mae: 19.5371 - val_loss: 316.1011 - val_mae: 16.6730\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.1266 - mae: 19.5055 - val_loss: 315.0482 - val_mae: 16.6414\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.8960 - mae: 19.4737 - val_loss: 314.0131 - val_mae: 16.6102\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.6849 - mae: 19.4427 - val_loss: 312.9764 - val_mae: 16.5790\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 479.4743 - mae: 19.4116 - val_loss: 311.9621 - val_mae: 16.5484\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.2865 - mae: 19.3812 - val_loss: 310.9417 - val_mae: 16.5175\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.0911 - mae: 19.3502 - val_loss: 309.9233 - val_mae: 16.4867\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.8988 - mae: 19.3194 - val_loss: 308.9054 - val_mae: 16.4558\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.7080 - mae: 19.2884 - val_loss: 307.9031 - val_mae: 16.4253\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.5316 - mae: 19.2581 - val_loss: 306.8799 - val_mae: 16.3941\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.3329 - mae: 19.2267 - val_loss: 305.8701 - val_mae: 16.3633\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.1497 - mae: 19.1961 - val_loss: 304.8658 - val_mae: 16.3326\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.9713 - mae: 19.1656 - val_loss: 303.8567 - val_mae: 16.3017\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.7884 - mae: 19.1341 - val_loss: 302.8568 - val_mae: 16.2710\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.6162 - mae: 19.1037 - val_loss: 301.8711 - val_mae: 16.2406\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.4595 - mae: 19.0734 - val_loss: 300.8875 - val_mae: 16.2103\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.3040 - mae: 19.0429 - val_loss: 299.9004 - val_mae: 16.1798\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.1451 - mae: 19.0129 - val_loss: 298.9146 - val_mae: 16.1494\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.9878 - mae: 18.9819 - val_loss: 297.9347 - val_mae: 16.1190\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.8365 - mae: 18.9516 - val_loss: 296.9603 - val_mae: 16.0887\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.6912 - mae: 18.9217 - val_loss: 295.9867 - val_mae: 16.0584\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.5464 - mae: 18.8915 - val_loss: 295.0135 - val_mae: 16.0281\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.4036 - mae: 18.8602 - val_loss: 294.0490 - val_mae: 15.9980\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.2687 - mae: 18.8309 - val_loss: 293.0932 - val_mae: 15.9681\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.1447 - mae: 18.8008 - val_loss: 292.1435 - val_mae: 15.9383\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 455.0263 - mae: 18.7713 - val_loss: 291.1820 - val_mae: 15.9081\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.8934 - mae: 18.7414 - val_loss: 290.2183 - val_mae: 15.8778\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.7607 - mae: 18.7111 - val_loss: 289.2767 - val_mae: 15.8482\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.6506 - mae: 18.6812 - val_loss: 288.3293 - val_mae: 15.8182\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 450.5354 - mae: 18.6512 - val_loss: 287.3857 - val_mae: 15.7884\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 449.4219 - mae: 18.6215 - val_loss: 286.4447 - val_mae: 15.7585\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.3143 - mae: 18.5915 - val_loss: 285.5175 - val_mae: 15.7291\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.2188 - mae: 18.5622 - val_loss: 284.5775 - val_mae: 15.6992\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.1107 - mae: 18.5324 - val_loss: 283.6430 - val_mae: 15.6694\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.0089 - mae: 18.5027 - val_loss: 282.7181 - val_mae: 15.6399\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.9167 - mae: 18.4730 - val_loss: 281.7965 - val_mae: 15.6104\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.8286 - mae: 18.4440 - val_loss: 280.8670 - val_mae: 15.5806\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.7308 - mae: 18.4137 - val_loss: 279.9438 - val_mae: 15.5509\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 440.6417 - mae: 18.3839 - val_loss: 279.0346 - val_mae: 15.5217\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.5666 - mae: 18.3547 - val_loss: 278.1285 - val_mae: 15.4924\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.4953 - mae: 18.3255 - val_loss: 277.2233 - val_mae: 15.4632\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.4250 - mae: 18.2963 - val_loss: 276.3201 - val_mae: 15.4340\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.3583 - mae: 18.2676 - val_loss: 275.4263 - val_mae: 15.4050\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.2992 - mae: 18.2386 - val_loss: 274.5239 - val_mae: 15.3757\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.2327 - mae: 18.2087 - val_loss: 273.6384 - val_mae: 15.3468\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.1833 - mae: 18.1802 - val_loss: 272.7391 - val_mae: 15.3175\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.1196 - mae: 18.1505 - val_loss: 271.8511 - val_mae: 15.2885\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.0670 - mae: 18.1220 - val_loss: 270.9649 - val_mae: 15.2595\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.0183 - mae: 18.0924 - val_loss: 270.0925 - val_mae: 15.2309\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.9832 - mae: 18.0646 - val_loss: 269.2101 - val_mae: 15.2019\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 427.9371 - mae: 18.0353 - val_loss: 268.3308 - val_mae: 15.1729\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.8941 - mae: 18.0065 - val_loss: 267.4510 - val_mae: 15.1439\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.8509 - mae: 17.9773 - val_loss: 266.5774 - val_mae: 15.1150\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.8163 - mae: 17.9493 - val_loss: 265.7169 - val_mae: 15.0866\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 423.7925 - mae: 17.9202 - val_loss: 264.8407 - val_mae: 15.0575\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.7541 - mae: 17.8904 - val_loss: 263.9889 - val_mae: 15.0292\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 421.7415 - mae: 17.8625 - val_loss: 263.1307 - val_mae: 15.0006\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.7227 - mae: 17.8338 - val_loss: 262.2727 - val_mae: 14.9720\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.7038 - mae: 17.8055 - val_loss: 261.4292 - val_mae: 14.9438\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.7000 - mae: 17.7777 - val_loss: 260.5811 - val_mae: 14.9154\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.6910 - mae: 17.7492 - val_loss: 259.7277 - val_mae: 14.8867\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.6770 - mae: 17.7202 - val_loss: 258.8888 - val_mae: 14.8585\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 415.6784 - mae: 17.6923 - val_loss: 258.0490 - val_mae: 14.8302\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.6791 - mae: 17.6640 - val_loss: 257.2158 - val_mae: 14.8021\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.6865 - mae: 17.6361 - val_loss: 256.3754 - val_mae: 14.7737\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.6856 - mae: 17.6077 - val_loss: 255.5351 - val_mae: 14.7452\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.6852 - mae: 17.5789 - val_loss: 254.7032 - val_mae: 14.7170\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.6948 - mae: 17.5506 - val_loss: 253.8845 - val_mae: 14.6892\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.7181 - mae: 17.5230 - val_loss: 253.0592 - val_mae: 14.6610\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.7352 - mae: 17.4948 - val_loss: 252.2406 - val_mae: 14.6331\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.7572 - mae: 17.4675 - val_loss: 251.4145 - val_mae: 14.6049\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.7727 - mae: 17.4390 - val_loss: 250.6027 - val_mae: 14.5770\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.8036 - mae: 17.4104 - val_loss: 249.7943 - val_mae: 14.5493\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.8383 - mae: 17.3834 - val_loss: 248.9875 - val_mae: 14.5215\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.8742 - mae: 17.3555 - val_loss: 248.1731 - val_mae: 14.4935\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.9023 - mae: 17.3270 - val_loss: 247.3725 - val_mae: 14.4658\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.9458 - mae: 17.2996 - val_loss: 246.5707 - val_mae: 14.4381\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.9877 - mae: 17.2722 - val_loss: 245.7811 - val_mae: 14.4107\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 303.7652 - mae: 15.6719\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=25, optimizer=sgd; total time=   4.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1300352384.0000 - mae: 12721.0029 - val_loss: 79.5692 - val_mae: 6.1614\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.9513 - mae: 6.5093 - val_loss: 79.5437 - val_mae: 6.1606\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.9258 - mae: 6.5081 - val_loss: 79.5180 - val_mae: 6.1597\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.8991 - mae: 6.5070 - val_loss: 79.4931 - val_mae: 6.1589\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8735 - mae: 6.5057 - val_loss: 79.4686 - val_mae: 6.1581\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.8486 - mae: 6.5047 - val_loss: 79.4442 - val_mae: 6.1572\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.8239 - mae: 6.5036 - val_loss: 79.4183 - val_mae: 6.1564\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.7977 - mae: 6.5023 - val_loss: 79.3935 - val_mae: 6.1555\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.7724 - mae: 6.5013 - val_loss: 79.3694 - val_mae: 6.1547\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.7472 - mae: 6.5002 - val_loss: 79.3445 - val_mae: 6.1539\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 85.7218 - mae: 6.4990 - val_loss: 79.3199 - val_mae: 6.1531\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 116.5877 - mae: 7.2590\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=1, n_neurons=25, optimizer=sgd; total time=   0.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 688.1280 - mae: 21.9539 - val_loss: 447.1877 - val_mae: 20.1784\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.7137 - mae: 22.4551 - val_loss: 446.6625 - val_mae: 20.1533\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 593.4667 - mae: 22.4227 - val_loss: 442.8418 - val_mae: 19.7935\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.8537 - mae: 22.4867 - val_loss: 446.1862 - val_mae: 20.1349\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.2983 - mae: 22.4579 - val_loss: 446.2467 - val_mae: 20.1435\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.3918 - mae: 22.4757 - val_loss: 447.7639 - val_mae: 20.2252\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.9707 - mae: 22.4416 - val_loss: 447.8083 - val_mae: 20.2302\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.9393 - mae: 22.4327 - val_loss: 446.0823 - val_mae: 20.1479\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.7082 - mae: 22.4249 - val_loss: 445.5815 - val_mae: 20.1238\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.4510 - mae: 22.4270 - val_loss: 443.6330 - val_mae: 19.9827\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 592.1971 - mae: 22.4235 - val_loss: 443.5554 - val_mae: 19.9859\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 592.3008 - mae: 22.4381 - val_loss: 442.9215 - val_mae: 19.9292\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.0264 - mae: 22.4319 - val_loss: 443.2826 - val_mae: 19.9800\n",
      "Epoch 13: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 589.2426 - mae: 22.1702\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   1.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 25ms/step - loss: 371.0224 - mae: 15.9114 - val_loss: 140.9951 - val_mae: 10.5063\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 231.9775 - mae: 12.2192 - val_loss: 119.2480 - val_mae: 8.2824\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.0722 - mae: 15.5972 - val_loss: 97.7447 - val_mae: 9.1829\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 162.8549 - mae: 10.2762 - val_loss: 106.0489 - val_mae: 9.0059\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 142.4077 - mae: 9.5009 - val_loss: 53.9529 - val_mae: 5.6631\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.1573 - mae: 14.7635 - val_loss: 59.2216 - val_mae: 6.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 138.5862 - mae: 9.1220 - val_loss: 62.8328 - val_mae: 7.0307\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 166.5679 - mae: 10.2108 - val_loss: 52.3776 - val_mae: 6.3170\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.2652 - mae: 8.2486 - val_loss: 73.9062 - val_mae: 7.6343\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.6660 - mae: 8.3820 - val_loss: 99.4922 - val_mae: 8.5569\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115.7175 - mae: 8.5830 - val_loss: 37.8463 - val_mae: 4.8860\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7061 - mae: 7.9297 - val_loss: 62.2168 - val_mae: 6.7897\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5641 - mae: 8.2349 - val_loss: 55.4037 - val_mae: 6.3512\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.8744 - mae: 8.5052 - val_loss: 36.2852 - val_mae: 4.9229\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.2502 - mae: 7.9056 - val_loss: 37.6094 - val_mae: 5.0585\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.0502 - mae: 7.8124 - val_loss: 39.8922 - val_mae: 5.2015\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.0262 - mae: 7.9688 - val_loss: 54.6159 - val_mae: 5.9886\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7729 - mae: 8.0858 - val_loss: 40.0189 - val_mae: 5.1018\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5913 - mae: 7.7526 - val_loss: 35.9426 - val_mae: 4.7952\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.2039 - mae: 7.7894 - val_loss: 33.6987 - val_mae: 4.6245\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7545 - mae: 7.7883 - val_loss: 34.5179 - val_mae: 4.6642\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6347 - mae: 7.6638 - val_loss: 28.5699 - val_mae: 4.3775\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5549 - mae: 7.3232 - val_loss: 40.3341 - val_mae: 5.0431\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.5345 - mae: 7.5320 - val_loss: 55.9513 - val_mae: 6.0983\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7302 - mae: 7.6330 - val_loss: 31.4952 - val_mae: 4.4478\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6975 - mae: 7.6683 - val_loss: 43.1714 - val_mae: 5.2274\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.9005 - mae: 7.6311 - val_loss: 30.8873 - val_mae: 4.6546\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5545 - mae: 7.6231 - val_loss: 26.1613 - val_mae: 4.1992\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1651 - mae: 7.4988 - val_loss: 25.3651 - val_mae: 4.0892\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7503 - mae: 7.3120 - val_loss: 26.0609 - val_mae: 4.1007\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7083 - mae: 7.6303 - val_loss: 33.8593 - val_mae: 4.8079\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.7979 - mae: 7.3869 - val_loss: 59.8372 - val_mae: 6.3778\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9043 - mae: 7.3465 - val_loss: 33.9678 - val_mae: 4.6259\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6883 - mae: 7.2241 - val_loss: 33.9829 - val_mae: 4.6403\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0203 - mae: 7.1240 - val_loss: 30.8925 - val_mae: 4.4665\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7944 - mae: 7.1814 - val_loss: 30.7492 - val_mae: 4.4411\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0546 - mae: 7.2465 - val_loss: 21.4512 - val_mae: 3.7413\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4187 - mae: 7.1899 - val_loss: 20.9249 - val_mae: 3.7184\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5515 - mae: 7.0114 - val_loss: 24.3136 - val_mae: 3.9519\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.3515 - mae: 6.9847 - val_loss: 35.1728 - val_mae: 4.7114\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.7627 - mae: 7.1766 - val_loss: 21.7420 - val_mae: 3.7191\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6729 - mae: 6.9936 - val_loss: 20.8524 - val_mae: 3.6437\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3935 - mae: 6.9888 - val_loss: 27.7551 - val_mae: 4.2352\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4802 - mae: 6.9079 - val_loss: 25.1969 - val_mae: 4.0584\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8709 - mae: 7.0475 - val_loss: 20.2574 - val_mae: 3.5690\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5426 - mae: 6.9711 - val_loss: 21.6608 - val_mae: 3.7741\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6308 - mae: 6.8729 - val_loss: 19.3575 - val_mae: 3.5240\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.6021 - mae: 6.8729 - val_loss: 32.0826 - val_mae: 4.5209\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6482 - mae: 6.7778 - val_loss: 98.2284 - val_mae: 8.2823\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0441 - mae: 7.3408 - val_loss: 20.7795 - val_mae: 3.6872\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.8155 - mae: 6.9179 - val_loss: 27.3803 - val_mae: 4.2166\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.1849 - mae: 7.4190 - val_loss: 32.5253 - val_mae: 4.5386\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.1531 - mae: 6.8032 - val_loss: 22.9698 - val_mae: 3.8617\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.9107 - mae: 6.8075 - val_loss: 18.8763 - val_mae: 3.4335\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 84.6631 - mae: 6.7503 - val_loss: 44.0750 - val_mae: 5.2398\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 95.5371 - mae: 7.2481 - val_loss: 26.9948 - val_mae: 4.2013\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.8697 - mae: 6.7478 - val_loss: 23.2628 - val_mae: 3.8804\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.4354 - mae: 6.7037 - val_loss: 21.2795 - val_mae: 3.6700\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.5289 - mae: 6.6674 - val_loss: 30.7665 - val_mae: 4.4590\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.8456 - mae: 6.7900 - val_loss: 29.3901 - val_mae: 4.3638\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.2517 - mae: 7.2430 - val_loss: 18.3435 - val_mae: 3.4347\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.1627 - mae: 6.6732 - val_loss: 19.0447 - val_mae: 3.5621\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.4281 - mae: 6.7094 - val_loss: 18.8315 - val_mae: 3.4655\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.0124 - mae: 6.6938 - val_loss: 21.6767 - val_mae: 3.7471\n",
      "Epoch 64: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.9904 - mae: 5.3175\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   3.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 17ms/step - loss: 136.7610 - mae: 8.8924 - val_loss: 137.1414 - val_mae: 8.9168\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.4752 - mae: 7.8793 - val_loss: 113.0803 - val_mae: 7.8374\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5987 - mae: 7.2755 - val_loss: 104.9738 - val_mae: 7.5054\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7438 - mae: 6.5350 - val_loss: 89.9344 - val_mae: 6.7835\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0817 - mae: 6.2568 - val_loss: 79.0260 - val_mae: 6.2198\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.9516 - mae: 5.9570 - val_loss: 73.3608 - val_mae: 6.0154\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8247 - mae: 6.1076 - val_loss: 70.1908 - val_mae: 5.9978\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5519 - mae: 6.0738 - val_loss: 63.9715 - val_mae: 5.4543\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8282 - mae: 5.8125 - val_loss: 61.3525 - val_mae: 5.5028\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5889 - mae: 5.8175 - val_loss: 58.3759 - val_mae: 5.2995\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7720 - mae: 5.7719 - val_loss: 56.9229 - val_mae: 5.2622\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8534 - mae: 5.8435 - val_loss: 55.3745 - val_mae: 5.2412\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2673 - mae: 5.7639 - val_loss: 54.2469 - val_mae: 5.1433\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1842 - mae: 5.7394 - val_loss: 53.4102 - val_mae: 5.1642\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1602 - mae: 5.8231 - val_loss: 52.1674 - val_mae: 5.1348\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1099 - mae: 5.7620 - val_loss: 52.1453 - val_mae: 5.0896\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4822 - mae: 5.8603 - val_loss: 52.5650 - val_mae: 5.1647\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3228 - mae: 5.7954 - val_loss: 50.4164 - val_mae: 5.0677\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9151 - mae: 5.8230 - val_loss: 50.5899 - val_mae: 5.0747\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.8003 - mae: 5.7378 - val_loss: 49.8313 - val_mae: 5.0669\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3325 - mae: 5.8452 - val_loss: 49.7629 - val_mae: 5.0512\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.0110 - mae: 5.7120 - val_loss: 50.0508 - val_mae: 5.1271\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.9207 - mae: 5.7885 - val_loss: 49.8010 - val_mae: 5.0232\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.4236 - mae: 5.6794 - val_loss: 51.6705 - val_mae: 5.3112\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.6721 - mae: 5.8098 - val_loss: 49.1674 - val_mae: 5.0345\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7904 - mae: 5.7192 - val_loss: 50.8128 - val_mae: 5.2642\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.0873 - mae: 5.8552 - val_loss: 49.0778 - val_mae: 5.0118\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.9635 - mae: 5.7842 - val_loss: 48.6795 - val_mae: 5.0288\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7826 - mae: 5.7060 - val_loss: 48.6682 - val_mae: 4.9807\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9892 - mae: 5.7271 - val_loss: 48.6907 - val_mae: 4.9695\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5101 - mae: 5.7001 - val_loss: 48.3254 - val_mae: 4.9820\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6637 - mae: 5.7006 - val_loss: 49.5230 - val_mae: 5.1196\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9137 - mae: 5.8070 - val_loss: 48.6281 - val_mae: 4.9980\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.2696 - mae: 5.7030 - val_loss: 47.8812 - val_mae: 5.0602\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.0101 - mae: 5.7077 - val_loss: 47.7908 - val_mae: 5.0582\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1293 - mae: 5.7622 - val_loss: 48.6832 - val_mae: 4.9712\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1087 - mae: 5.8195 - val_loss: 49.9178 - val_mae: 5.0948\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2516 - mae: 5.7649 - val_loss: 48.3852 - val_mae: 5.0086\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7870 - mae: 5.7255 - val_loss: 47.5149 - val_mae: 5.0813\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9350 - mae: 5.7157 - val_loss: 47.6888 - val_mae: 4.9984\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0731 - mae: 5.6708 - val_loss: 47.7604 - val_mae: 4.9757\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6060 - mae: 5.5772 - val_loss: 57.9226 - val_mae: 5.9503\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7281 - mae: 5.8931 - val_loss: 47.6721 - val_mae: 5.0059\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5611 - mae: 5.7306 - val_loss: 48.9168 - val_mae: 4.9950\n",
      "Epoch 44: early stopping\n",
      "5/5 [==============================] - 0s 996us/step - loss: 100.3633 - mae: 6.3880\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=5, optimizer=sgd; total time=   2.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 626.1570 - mae: 18.2238 - val_loss: 2940.6052 - val_mae: 53.0731\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3065.7776 - mae: 41.4010 - val_loss: 448.8969 - val_mae: 20.2678\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.8719 - mae: 22.6846 - val_loss: 447.9122 - val_mae: 20.2435\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.5311 - mae: 22.6551 - val_loss: 446.4951 - val_mae: 20.2085\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.8394 - mae: 22.6177 - val_loss: 444.8789 - val_mae: 20.1684\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.0013 - mae: 22.5766 - val_loss: 443.1692 - val_mae: 20.1260\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.0478 - mae: 22.5336 - val_loss: 441.4112 - val_mae: 20.0823\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.0435 - mae: 22.4896 - val_loss: 439.6161 - val_mae: 20.0375\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9966 - mae: 22.4437 - val_loss: 437.7261 - val_mae: 19.9903\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.8540 - mae: 22.3958 - val_loss: 435.7733 - val_mae: 19.9414\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.6426 - mae: 22.3467 - val_loss: 433.8111 - val_mae: 19.8922\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 580.4301 - mae: 22.2971 - val_loss: 431.8260 - val_mae: 19.8422\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 578.1962 - mae: 22.2470 - val_loss: 429.8277 - val_mae: 19.7918\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.9475 - mae: 22.1962 - val_loss: 427.8005 - val_mae: 19.7405\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 573.6742 - mae: 22.1447 - val_loss: 425.7596 - val_mae: 19.6887\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.3818 - mae: 22.0927 - val_loss: 423.6899 - val_mae: 19.6361\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.0284 - mae: 22.0401 - val_loss: 421.6253 - val_mae: 19.5835\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.6879 - mae: 21.9869 - val_loss: 419.5152 - val_mae: 19.5295\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 564.2786 - mae: 21.9328 - val_loss: 417.3804 - val_mae: 19.4748\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.8644 - mae: 21.8771 - val_loss: 415.1805 - val_mae: 19.4182\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 559.3796 - mae: 21.8198 - val_loss: 412.9271 - val_mae: 19.3601\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.8232 - mae: 21.7613 - val_loss: 410.6302 - val_mae: 19.3007\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.1965 - mae: 21.7015 - val_loss: 408.2943 - val_mae: 19.2401\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 551.5464 - mae: 21.6399 - val_loss: 405.8813 - val_mae: 19.1773\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.8171 - mae: 21.5761 - val_loss: 403.3924 - val_mae: 19.1123\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.9678 - mae: 21.5104 - val_loss: 400.8349 - val_mae: 19.0453\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.0286 - mae: 21.4426 - val_loss: 398.2047 - val_mae: 18.9761\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.0362 - mae: 21.3722 - val_loss: 395.4758 - val_mae: 18.9040\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 536.8965 - mae: 21.2991 - val_loss: 392.6558 - val_mae: 18.8293\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.6982 - mae: 21.2227 - val_loss: 389.7061 - val_mae: 18.7508\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 530.3121 - mae: 21.1430 - val_loss: 386.6561 - val_mae: 18.6693\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 526.7993 - mae: 21.0604 - val_loss: 383.5055 - val_mae: 18.5847\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 523.1674 - mae: 20.9737 - val_loss: 380.1857 - val_mae: 18.4952\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.3174 - mae: 20.8823 - val_loss: 376.7078 - val_mae: 18.4009\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 515.2978 - mae: 20.7860 - val_loss: 373.0658 - val_mae: 18.3017\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 511.1472 - mae: 20.6838 - val_loss: 369.1981 - val_mae: 18.1957\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 506.6641 - mae: 20.5763 - val_loss: 365.1864 - val_mae: 18.0852\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 502.0024 - mae: 20.4634 - val_loss: 360.9814 - val_mae: 17.9685\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.1148 - mae: 20.3438 - val_loss: 356.5460 - val_mae: 17.8447\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.8964 - mae: 20.2166 - val_loss: 351.8471 - val_mae: 17.7125\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 486.5006 - mae: 20.0797 - val_loss: 346.7870 - val_mae: 17.5691\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.5868 - mae: 19.9327 - val_loss: 341.4519 - val_mae: 17.4166\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.3928 - mae: 19.7756 - val_loss: 335.7783 - val_mae: 17.2530\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.7263 - mae: 19.6080 - val_loss: 329.7918 - val_mae: 17.0786\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 460.7468 - mae: 19.4272 - val_loss: 323.3416 - val_mae: 16.8887\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 453.1697 - mae: 19.2310 - val_loss: 316.4306 - val_mae: 16.6829\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.8930 - mae: 19.0159 - val_loss: 308.8606 - val_mae: 16.4544\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.9075 - mae: 18.7780 - val_loss: 300.6307 - val_mae: 16.2024\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.0841 - mae: 18.5162 - val_loss: 291.7549 - val_mae: 15.9261\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.5471 - mae: 18.2299 - val_loss: 282.2434 - val_mae: 15.6247\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 404.2016 - mae: 17.9176 - val_loss: 272.1021 - val_mae: 15.2967\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.1987 - mae: 17.5789 - val_loss: 261.1533 - val_mae: 14.9345\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.0845 - mae: 17.2088 - val_loss: 249.5551 - val_mae: 14.5411\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.4128 - mae: 16.8075 - val_loss: 237.0383 - val_mae: 14.1041\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.2811 - mae: 16.3623 - val_loss: 224.0742 - val_mae: 13.6368\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.6255 - mae: 15.8851 - val_loss: 210.2760 - val_mae: 13.1327\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.9041 - mae: 15.3606 - val_loss: 195.7233 - val_mae: 12.6079\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.1303 - mae: 14.7912 - val_loss: 180.6966 - val_mae: 12.0399\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.9749 - mae: 14.1765 - val_loss: 164.8947 - val_mae: 11.4092\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.6683 - mae: 13.5311 - val_loss: 148.9239 - val_mae: 10.7305\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 242.7925 - mae: 12.8470 - val_loss: 133.0532 - val_mae: 10.0154\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 223.4953 - mae: 12.1175 - val_loss: 117.2070 - val_mae: 9.2912\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 203.5907 - mae: 11.3518 - val_loss: 102.1515 - val_mae: 8.5673\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 184.3065 - mae: 10.5855 - val_loss: 88.1809 - val_mae: 7.8913\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 166.1186 - mae: 9.8281 - val_loss: 75.4910 - val_mae: 7.3052\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 149.5458 - mae: 9.1399 - val_loss: 64.5962 - val_mae: 6.7676\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 134.7024 - mae: 8.4810 - val_loss: 55.5938 - val_mae: 6.2314\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.8670 - mae: 7.8657 - val_loss: 48.5883 - val_mae: 5.7542\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 111.7725 - mae: 7.3674 - val_loss: 43.3686 - val_mae: 5.3927\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 102.4603 - mae: 6.9445 - val_loss: 40.2700 - val_mae: 5.2317\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.5304 - mae: 6.6356 - val_loss: 38.6112 - val_mae: 5.1286\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.4195 - mae: 6.4220 - val_loss: 38.1247 - val_mae: 5.1632\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 88.8197 - mae: 6.3422 - val_loss: 38.3357 - val_mae: 5.2278\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.3885 - mae: 6.2941 - val_loss: 38.9245 - val_mae: 5.2754\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1678 - mae: 6.2902 - val_loss: 39.7731 - val_mae: 5.3185\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.2339 - mae: 6.2930 - val_loss: 40.5370 - val_mae: 5.3483\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.9540 - mae: 6.3172 - val_loss: 41.3377 - val_mae: 5.3748\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.6790 - mae: 6.3384 - val_loss: 42.0912 - val_mae: 5.4097\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 83.4325 - mae: 6.3557 - val_loss: 42.5700 - val_mae: 5.4313\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 83.4014 - mae: 6.3776 - val_loss: 42.9968 - val_mae: 5.4496\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 83.3810 - mae: 6.3909 - val_loss: 43.4319 - val_mae: 5.4674\n",
      "Epoch 81: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 95.3577 - mae: 7.4423\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 988.7086 - mae: 24.6514 - val_loss: 204.1961 - val_mae: 13.5319\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.0355 - mae: 13.8412 - val_loss: 56.4400 - val_mae: 6.1238\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 154.3934 - mae: 9.6384 - val_loss: 36.0411 - val_mae: 4.6113\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.9332 - mae: 7.2986 - val_loss: 49.2646 - val_mae: 5.5472\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 95.2593 - mae: 7.4144 - val_loss: 44.4300 - val_mae: 5.2884\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.1155 - mae: 7.0342 - val_loss: 22.9421 - val_mae: 3.9062\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.1557 - mae: 7.0432 - val_loss: 20.8342 - val_mae: 3.6765\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1264 - mae: 6.8507 - val_loss: 25.9582 - val_mae: 4.1735\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.9832 - mae: 6.5079 - val_loss: 36.2353 - val_mae: 4.9534\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.6973 - mae: 6.9018 - val_loss: 20.7246 - val_mae: 3.8387\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.0021 - mae: 6.8850 - val_loss: 17.7473 - val_mae: 3.2841\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.8480 - mae: 6.6110 - val_loss: 23.2590 - val_mae: 4.0739\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.8727 - mae: 6.5309 - val_loss: 34.1302 - val_mae: 4.9390\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.2026 - mae: 6.4641 - val_loss: 31.6119 - val_mae: 4.7533\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.5729 - mae: 6.6896 - val_loss: 45.6596 - val_mae: 5.7754\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.7254 - mae: 6.4115 - val_loss: 24.9781 - val_mae: 4.2308\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.3595 - mae: 6.3333 - val_loss: 30.7770 - val_mae: 4.7163\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.6229 - mae: 6.3994 - val_loss: 30.8615 - val_mae: 4.7418\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2203 - mae: 6.6135 - val_loss: 50.4126 - val_mae: 6.2067\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.4469 - mae: 6.7318 - val_loss: 73.0646 - val_mae: 7.4263\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.2408 - mae: 6.6989 - val_loss: 22.2438 - val_mae: 3.9661\n",
      "Epoch 21: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.2835 - mae: 5.0940\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   1.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 1838.7279 - mae: 28.8591 - val_loss: 79.2919 - val_mae: 6.6895\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.3666 - mae: 19.0119 - val_loss: 344.9078 - val_mae: 16.2442\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 781.9823 - mae: 23.7563 - val_loss: 545.5264 - val_mae: 21.7517\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.4711 - mae: 16.0346 - val_loss: 158.0239 - val_mae: 10.2295\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 196.2886 - mae: 11.0570 - val_loss: 100.1827 - val_mae: 7.2935\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127.9615 - mae: 8.2037 - val_loss: 129.4563 - val_mae: 8.3746\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.2848 - mae: 7.2347 - val_loss: 74.1759 - val_mae: 6.0362\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7812 - mae: 6.3640 - val_loss: 76.4621 - val_mae: 6.3619\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.7784 - mae: 6.1976 - val_loss: 58.0023 - val_mae: 6.0556\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 69.7228 - mae: 6.1678 - val_loss: 62.1132 - val_mae: 5.8604\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.1627 - mae: 6.3262 - val_loss: 58.5682 - val_mae: 5.8116\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.2209 - mae: 6.2175 - val_loss: 72.9240 - val_mae: 6.6541\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5419 - mae: 7.0050 - val_loss: 81.0668 - val_mae: 7.5085\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9279 - mae: 7.0531 - val_loss: 81.3852 - val_mae: 7.3095\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7705 - mae: 6.5081 - val_loss: 71.0181 - val_mae: 6.5559\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.7072 - mae: 5.6542 - val_loss: 55.0502 - val_mae: 5.7074\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.7236 - mae: 5.9616 - val_loss: 81.9503 - val_mae: 6.8188\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5892 - mae: 6.7543 - val_loss: 96.3915 - val_mae: 7.6074\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0732 - mae: 6.9439 - val_loss: 72.4440 - val_mae: 6.1670\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.8648 - mae: 6.0860 - val_loss: 59.9508 - val_mae: 5.9356\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.1973 - mae: 5.8953 - val_loss: 56.2505 - val_mae: 6.2777\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2075 - mae: 5.7416 - val_loss: 54.4220 - val_mae: 6.1557\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7242 - mae: 6.2110 - val_loss: 72.1091 - val_mae: 6.8557\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4230 - mae: 5.9314 - val_loss: 65.2318 - val_mae: 6.5840\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9174 - mae: 6.0554 - val_loss: 53.4418 - val_mae: 5.4054\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5302 - mae: 5.7413 - val_loss: 50.4529 - val_mae: 5.4692\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.6783 - mae: 5.8222 - val_loss: 61.0418 - val_mae: 5.5449\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2497 - mae: 6.2756 - val_loss: 55.2272 - val_mae: 5.3613\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7755 - mae: 5.7032 - val_loss: 49.4851 - val_mae: 5.5823\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3171 - mae: 5.6105 - val_loss: 50.3552 - val_mae: 5.6903\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.1273 - mae: 5.6001 - val_loss: 51.6585 - val_mae: 5.2675\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.5771 - mae: 5.4528 - val_loss: 48.4089 - val_mae: 5.6087\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.9315 - mae: 5.7428 - val_loss: 50.1740 - val_mae: 5.2633\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9840 - mae: 5.5065 - val_loss: 52.1508 - val_mae: 5.2670\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.0622 - mae: 5.4359 - val_loss: 48.3367 - val_mae: 5.5011\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.7683 - mae: 5.4067 - val_loss: 47.9403 - val_mae: 5.5705\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.2399 - mae: 5.4805 - val_loss: 53.3453 - val_mae: 5.2630\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.3833 - mae: 5.5805 - val_loss: 54.1397 - val_mae: 5.2356\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7260 - mae: 5.8220 - val_loss: 63.7345 - val_mae: 5.7462\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.6172 - mae: 5.9211 - val_loss: 54.1386 - val_mae: 5.2403\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8184 - mae: 5.7560 - val_loss: 48.7038 - val_mae: 5.3768\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.7291 - mae: 5.5393 - val_loss: 96.1395 - val_mae: 8.1582\n",
      "Epoch 42: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 116.9610 - mae: 9.3453\n",
      "[CV] END learning_rate=1e-05, momentum=0.9, n_hidden=3, n_neurons=25, optimizer=momentum; total time=   2.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 584649.2500 - mae: 460.5175 - val_loss: 434.1258 - val_mae: 19.9001\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.1747 - mae: 22.1125 - val_loss: 413.7722 - val_mae: 19.3819\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.7568 - mae: 21.5949 - val_loss: 394.5007 - val_mae: 18.8782\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.4360 - mae: 21.0974 - val_loss: 375.8514 - val_mae: 18.3777\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.7736 - mae: 20.6021 - val_loss: 358.3291 - val_mae: 17.8946\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.3029 - mae: 20.1180 - val_loss: 341.7496 - val_mae: 17.4252\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.7928 - mae: 19.6569 - val_loss: 325.9286 - val_mae: 16.9651\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.0778 - mae: 19.2069 - val_loss: 310.7873 - val_mae: 16.5129\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.0612 - mae: 18.7549 - val_loss: 296.2824 - val_mae: 16.0677\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.7272 - mae: 18.3127 - val_loss: 282.6955 - val_mae: 15.6391\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.3518 - mae: 17.8921 - val_loss: 269.6740 - val_mae: 15.2171\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.5727 - mae: 17.4791 - val_loss: 257.3153 - val_mae: 14.8055\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.4832 - mae: 17.0794 - val_loss: 245.4723 - val_mae: 14.4000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.9579 - mae: 16.6793 - val_loss: 234.3406 - val_mae: 14.0081\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.1583 - mae: 16.2972 - val_loss: 223.7368 - val_mae: 13.6244\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 335.9494 - mae: 15.9212 - val_loss: 213.7782 - val_mae: 13.2557\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.3990 - mae: 15.5676 - val_loss: 204.1936 - val_mae: 12.9162\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 313.2508 - mae: 15.2119 - val_loss: 195.0785 - val_mae: 12.5841\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.6040 - mae: 14.8752 - val_loss: 186.4109 - val_mae: 12.2593\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.4274 - mae: 14.5336 - val_loss: 178.1496 - val_mae: 11.9407\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.6856 - mae: 14.2055 - val_loss: 170.3063 - val_mae: 11.6294\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.4052 - mae: 13.9031 - val_loss: 162.9731 - val_mae: 11.3299\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.6599 - mae: 13.6102 - val_loss: 155.9125 - val_mae: 11.0331\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.2053 - mae: 13.3160 - val_loss: 149.2053 - val_mae: 10.7428\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.1383 - mae: 13.0296 - val_loss: 142.8501 - val_mae: 10.4596\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 240.4443 - mae: 12.7526 - val_loss: 136.8207 - val_mae: 10.1828\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.1166 - mae: 12.4854 - val_loss: 131.1246 - val_mae: 9.9307\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.1497 - mae: 12.2226 - val_loss: 125.7301 - val_mae: 9.6889\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.4939 - mae: 11.9760 - val_loss: 120.5633 - val_mae: 9.4502\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.1082 - mae: 11.7294 - val_loss: 115.7649 - val_mae: 9.2218\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.1243 - mae: 11.4915 - val_loss: 111.2391 - val_mae: 8.9997\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.4335 - mae: 11.2688 - val_loss: 106.8105 - val_mae: 8.7897\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 195.8393 - mae: 11.0419 - val_loss: 102.6481 - val_mae: 8.5914\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.5391 - mae: 10.8374 - val_loss: 98.6972 - val_mae: 8.3971\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.4837 - mae: 10.6292 - val_loss: 94.9777 - val_mae: 8.2185\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 180.6864 - mae: 10.4276 - val_loss: 91.5170 - val_mae: 8.0545\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.1774 - mae: 10.2446 - val_loss: 88.2333 - val_mae: 7.8939\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.8793 - mae: 10.0642 - val_loss: 85.1689 - val_mae: 7.7479\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 167.8161 - mae: 9.8928 - val_loss: 82.1674 - val_mae: 7.6079\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.8226 - mae: 9.7281 - val_loss: 79.3356 - val_mae: 7.4756\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.0079 - mae: 9.5618 - val_loss: 76.6912 - val_mae: 7.3593\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.4180 - mae: 9.4145 - val_loss: 74.2019 - val_mae: 7.2461\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.0145 - mae: 9.2744 - val_loss: 71.8720 - val_mae: 7.1366\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.7831 - mae: 9.1354 - val_loss: 69.6322 - val_mae: 7.0276\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 146.6608 - mae: 8.9969 - val_loss: 67.5213 - val_mae: 6.9214\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 143.6762 - mae: 8.8667 - val_loss: 65.5604 - val_mae: 6.8192\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 140.8923 - mae: 8.7484 - val_loss: 63.7131 - val_mae: 6.7196\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 138.2095 - mae: 8.6291 - val_loss: 61.9133 - val_mae: 6.6190\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.5827 - mae: 8.5137 - val_loss: 60.2430 - val_mae: 6.5221\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.1175 - mae: 8.4043 - val_loss: 58.6836 - val_mae: 6.4284\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.7825 - mae: 8.2969 - val_loss: 57.1900 - val_mae: 6.3352\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.5303 - mae: 8.1896 - val_loss: 55.7980 - val_mae: 6.2450\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.3890 - mae: 8.0914 - val_loss: 54.4762 - val_mae: 6.1560\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.3435 - mae: 7.9896 - val_loss: 53.2955 - val_mae: 6.0734\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.4636 - mae: 7.9026 - val_loss: 52.1417 - val_mae: 5.9993\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.6114 - mae: 7.8142 - val_loss: 51.0530 - val_mae: 5.9279\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.8441 - mae: 7.7252 - val_loss: 50.0605 - val_mae: 5.8601\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.1999 - mae: 7.6452 - val_loss: 49.0919 - val_mae: 5.7913\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5730 - mae: 7.5659 - val_loss: 48.2131 - val_mae: 5.7261\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0673 - mae: 7.4884 - val_loss: 47.3830 - val_mae: 5.6618\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6258 - mae: 7.4227 - val_loss: 46.6191 - val_mae: 5.6002\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.2579 - mae: 7.3571 - val_loss: 45.8981 - val_mae: 5.5458\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.9517 - mae: 7.2961 - val_loss: 45.2265 - val_mae: 5.5039\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.7047 - mae: 7.2422 - val_loss: 44.5772 - val_mae: 5.4623\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4858 - mae: 7.1844 - val_loss: 44.0129 - val_mae: 5.4281\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3851 - mae: 7.1299 - val_loss: 43.4687 - val_mae: 5.3984\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3052 - mae: 7.0777 - val_loss: 42.9566 - val_mae: 5.3689\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.2634 - mae: 7.0230 - val_loss: 42.4669 - val_mae: 5.3461\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2531 - mae: 6.9713 - val_loss: 42.0252 - val_mae: 5.3260\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2881 - mae: 6.9282 - val_loss: 41.6245 - val_mae: 5.3067\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.4103 - mae: 6.8814 - val_loss: 41.2699 - val_mae: 5.2887\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.5930 - mae: 6.8444 - val_loss: 40.9156 - val_mae: 5.2697\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7592 - mae: 6.8035 - val_loss: 40.6100 - val_mae: 5.2523\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0095 - mae: 6.7662 - val_loss: 40.3051 - val_mae: 5.2339\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.2390 - mae: 6.7279 - val_loss: 40.0403 - val_mae: 5.2168\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5528 - mae: 6.6955 - val_loss: 39.8074 - val_mae: 5.2007\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9019 - mae: 6.6602 - val_loss: 39.5777 - val_mae: 5.1838\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2384 - mae: 6.6287 - val_loss: 39.3741 - val_mae: 5.1676\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6208 - mae: 6.6032 - val_loss: 39.1912 - val_mae: 5.1520\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0508 - mae: 6.5738 - val_loss: 39.0197 - val_mae: 5.1360\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4796 - mae: 6.5478 - val_loss: 38.8837 - val_mae: 5.1223\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9731 - mae: 6.5251 - val_loss: 38.7498 - val_mae: 5.1252\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4657 - mae: 6.5032 - val_loss: 38.6311 - val_mae: 5.1281\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9759 - mae: 6.4816 - val_loss: 38.5277 - val_mae: 5.1309\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5231 - mae: 6.4643 - val_loss: 38.4402 - val_mae: 5.1335\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0859 - mae: 6.4488 - val_loss: 38.3599 - val_mae: 5.1363\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6500 - mae: 6.4319 - val_loss: 38.2970 - val_mae: 5.1388\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2668 - mae: 6.4178 - val_loss: 38.2396 - val_mae: 5.1415\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8707 - mae: 6.4020 - val_loss: 38.1983 - val_mae: 5.1439\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5207 - mae: 6.3902 - val_loss: 38.1648 - val_mae: 5.1500\n",
      "Epoch 90: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 100.1676 - mae: 7.1307\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   3.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 3170.7490 - mae: 40.7465 - val_loss: 124.5496 - val_mae: 9.2862\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 144.1661 - mae: 8.5084 - val_loss: 24.6694 - val_mae: 4.1766\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5711 - mae: 7.2801 - val_loss: 35.3195 - val_mae: 5.2411\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5806 - mae: 7.3574 - val_loss: 28.9427 - val_mae: 4.6553\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.1395 - mae: 7.2833 - val_loss: 27.0831 - val_mae: 4.4359\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.9622 - mae: 7.1712 - val_loss: 20.0444 - val_mae: 3.6967\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2669 - mae: 6.8794 - val_loss: 26.4758 - val_mae: 4.3823\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.7664 - mae: 7.1023 - val_loss: 30.4182 - val_mae: 4.6676\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.2354 - mae: 6.8133 - val_loss: 34.9725 - val_mae: 4.9592\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.0285 - mae: 6.9193 - val_loss: 36.3751 - val_mae: 5.1716\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.4742 - mae: 6.9350 - val_loss: 20.1074 - val_mae: 3.6900\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.7987 - mae: 6.5485 - val_loss: 36.3076 - val_mae: 5.1857\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.0838 - mae: 6.7048 - val_loss: 31.4271 - val_mae: 4.8368\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.7728 - mae: 6.7940 - val_loss: 20.8020 - val_mae: 3.7309\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.1883 - mae: 6.4983 - val_loss: 27.0737 - val_mae: 4.4770\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.7212 - mae: 6.5995 - val_loss: 20.8571 - val_mae: 3.7691\n",
      "Epoch 16: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 41.0059 - mae: 4.6797\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   1.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 11766.0312 - mae: 64.2353 - val_loss: 96.0461 - val_mae: 7.3436\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.2443 - mae: 7.3982 - val_loss: 68.1808 - val_mae: 6.1724\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.3028 - mae: 6.6639 - val_loss: 62.2469 - val_mae: 6.0770\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.7559 - mae: 6.3587 - val_loss: 58.2573 - val_mae: 5.9890\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.3085 - mae: 6.1339 - val_loss: 58.2042 - val_mae: 5.9027\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.2355 - mae: 6.0819 - val_loss: 56.0307 - val_mae: 5.7640\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.0724 - mae: 6.1953 - val_loss: 57.7256 - val_mae: 5.8996\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 71.5392 - mae: 6.1046 - val_loss: 57.8720 - val_mae: 5.8443\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.3392 - mae: 5.8837 - val_loss: 53.5384 - val_mae: 5.6114\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7226 - mae: 5.8879 - val_loss: 52.2713 - val_mae: 5.7127\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.8350 - mae: 5.8834 - val_loss: 50.5946 - val_mae: 5.6250\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.4740 - mae: 5.8544 - val_loss: 54.1823 - val_mae: 5.8310\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.1266 - mae: 5.7775 - val_loss: 50.5466 - val_mae: 5.4149\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.4983 - mae: 5.7199 - val_loss: 51.3788 - val_mae: 5.5737\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.7454 - mae: 5.7881 - val_loss: 48.2995 - val_mae: 5.3556\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.4443 - mae: 5.6557 - val_loss: 48.3809 - val_mae: 5.2413\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.2556 - mae: 5.6859 - val_loss: 50.3277 - val_mae: 5.6137\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.2744 - mae: 5.6681 - val_loss: 46.2967 - val_mae: 5.2229\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.8006 - mae: 5.6699 - val_loss: 46.4494 - val_mae: 5.1859\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.8324 - mae: 5.5591 - val_loss: 45.3811 - val_mae: 5.1907\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.6509 - mae: 5.7251 - val_loss: 45.4199 - val_mae: 5.2637\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.2916 - mae: 5.4649 - val_loss: 46.4771 - val_mae: 5.2016\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.8675 - mae: 5.6236 - val_loss: 45.2070 - val_mae: 5.0163\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.1477 - mae: 5.3979 - val_loss: 51.5785 - val_mae: 5.6646\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.2515 - mae: 5.5704 - val_loss: 44.0955 - val_mae: 5.0368\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.9513 - mae: 5.4621 - val_loss: 49.4745 - val_mae: 5.4738\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.7683 - mae: 5.5746 - val_loss: 43.7094 - val_mae: 5.0189\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.6376 - mae: 5.5499 - val_loss: 43.7491 - val_mae: 4.9587\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.1818 - mae: 5.4266 - val_loss: 43.5597 - val_mae: 4.9644\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.9471 - mae: 5.4240 - val_loss: 45.5992 - val_mae: 5.1313\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59.4915 - mae: 5.3822 - val_loss: 43.4345 - val_mae: 4.9261\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.7920 - mae: 5.3821 - val_loss: 50.5133 - val_mae: 5.5205\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.2448 - mae: 5.6284 - val_loss: 44.5942 - val_mae: 5.1332\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 61.0242 - mae: 5.3993 - val_loss: 45.1980 - val_mae: 5.0720\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58.8881 - mae: 5.3771 - val_loss: 44.0369 - val_mae: 4.9620\n",
      "Epoch 35: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 87.1363 - mae: 6.1718\n",
      "[CV] END learning_rate=1e-05, momentum=0.1, n_hidden=2, n_neurons=25, optimizer=sgd; total time=   3.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: inf - mae: 119821188389075419136.0000 - val_loss: inf - val_mae: 1043581167298507050057728.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: inf - mae: 687272595191060496384.0000 - val_loss: inf - val_mae: 5663115266522941837279232.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: inf - mae: 317408740740608032768.0000 - val_loss: inf - val_mae: 2381853106399790311145472.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: inf - mae: 1141700082447811608576.0000 - val_loss: inf - val_mae: 9943624006291260643999744.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 995us/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: inf - mae: 123883523213893828608.0000 - val_loss: inf - val_mae: 1020798069273189033181184.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: inf - mae: 58974672304788733952.0000 - val_loss: inf - val_mae: 442549207773714363449344.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.6s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   0.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 20ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   0.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 349335731054111883494726716882944.0000 - mae: 6787355071479808.0000 - val_loss: 372587779522643292569206784.0000 - val_mae: 19302533038080.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409343728746248817384357888.0000 - mae: 20228150919168.0000 - val_loss: 421188530689930310153404416.0000 - val_mae: 20522878369792.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420226569879974504455733248.0000 - mae: 20499421724672.0000 - val_loss: 418705562044120857086787584.0000 - val_mae: 20462295842816.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417597908849470893350453248.0000 - mae: 20435204833280.0000 - val_loss: 416033661845508470792519680.0000 - val_mae: 20396902449152.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414932501904772452818354176.0000 - mae: 20369882742784.0000 - val_loss: 413377920994704654065467392.0000 - val_mae: 20331695702016.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412283807710204793140019200.0000 - mae: 20304764076032.0000 - val_loss: 410739151148448650125901824.0000 - val_mae: 20266700767232.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409652047626696798830067712.0000 - mae: 20239855124480.0000 - val_loss: 408117278519764164135616512.0000 - val_mae: 20201913450496.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407037147867272175050293248.0000 - mae: 20175153790976.0000 - val_loss: 405512007960746016741785600.0000 - val_mae: 20137329557504.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404438813284025742447869952.0000 - mae: 20110657978368.0000 - val_loss: 402923487045346797620822016.0000 - val_mae: 20072955379712.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401857080770445648441901056.0000 - mae: 20046365589504.0000 - val_loss: 400351568199613917096312832.0000 - val_mae: 20008786722816.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 399291913433043745613283328.0000 - mae: 19982282915840.0000 - val_loss: 397795956275642195815432192.0000 - val_mae: 19944823586816.0000\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 397795993169130343234535424.0000 - mae: 19944823586816.0000\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=2, n_neurons=25, optimizer=momentum; total time=   1.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 248729303820045123584.0000 - mae: 5517445120.0000 - val_loss: 6703117877903360.0000 - val_mae: 81872576.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6615451152941056.0000 - mae: 81334632.0000 - val_loss: 6491806560681984.0000 - val_mae: 80571744.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6406903647174656.0000 - mae: 80042360.0000 - val_loss: 6287157811478528.0000 - val_mae: 79291592.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6204929588854784.0000 - mae: 78770624.0000 - val_loss: 6088958492540928.0000 - val_mae: 78031776.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6009323893293056.0000 - mae: 77519088.0000 - val_loss: 5897008351019008.0000 - val_mae: 76791976.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5819883623284736.0000 - mae: 76287424.0000 - val_loss: 5711107670933504.0000 - val_mae: 75571872.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5636413894688768.0000 - mae: 75075336.0000 - val_loss: 5531069084336128.0000 - val_mae: 74371160.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5458730023911424.0000 - mae: 73882504.0000 - val_loss: 5356705223278592.0000 - val_mae: 73189512.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5286647864229888.0000 - mae: 72708640.0000 - val_loss: 5187838920359936.0000 - val_mae: 72026656.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5119988100759552.0000 - mae: 71553408.0000 - val_loss: 5024293545050112.0000 - val_mae: 70882248.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4958582692904960.0000 - mae: 70416536.0000 - val_loss: 4865905888591872.0000 - val_mae: 69756040.0000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4802266821296128.0000 - mae: 69297720.0000 - val_loss: 4712511131615232.0000 - val_mae: 68647736.0000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4650878350917632.0000 - mae: 68196696.0000 - val_loss: 4563951970942976.0000 - val_mae: 67557024.0000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4504263199817728.0000 - mae: 67113152.0000 - val_loss: 4420076740542464.0000 - val_mae: 66483660.0000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4362268628221952.0000 - mae: 66046836.0000 - val_loss: 4280736190300160.0000 - val_mae: 65427336.0000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4224750486290432.0000 - mae: 64997452.0000 - val_loss: 4145788317859840.0000 - val_mae: 64387796.0000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4091567040102400.0000 - mae: 63964744.0000 - val_loss: 4015095147397120.0000 - val_mae: 63364780.0000\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3962582729752576.0000 - mae: 62948444.0000 - val_loss: 3888521119006720.0000 - val_mae: 62358008.0000\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3837664679690240.0000 - mae: 61948292.0000 - val_loss: 3765938457411584.0000 - val_mae: 61367244.0000\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3716684577767424.0000 - mae: 60964032.0000 - val_loss: 3647218850463744.0000 - val_mae: 60392208.0000\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3599518406803456.0000 - mae: 59995408.0000 - val_loss: 3532242575949824.0000 - val_mae: 59432672.0000\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3486046176149504.0000 - mae: 59042176.0000 - val_loss: 3420890448527360.0000 - val_mae: 58488380.0000\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3376150042640384.0000 - mae: 58104084.0000 - val_loss: 3313048919998464.0000 - val_mae: 57559092.0000\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3269718337126400.0000 - mae: 57180904.0000 - val_loss: 3208606858084352.0000 - val_mae: 56644564.0000\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3166642611683328.0000 - mae: 56272392.0000 - val_loss: 3107457425473536.0000 - val_mae: 55744572.0000\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3066816028999680.0000 - mae: 55378308.0000 - val_loss: 3009496200773632.0000 - val_mae: 54858880.0000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2970136315166720.0000 - mae: 54498444.0000 - val_loss: 2914623594430464.0000 - val_mae: 53987252.0000\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2876504417501184.0000 - mae: 53632532.0000 - val_loss: 2822741627502592.0000 - val_mae: 53129480.0000\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2785823699238912.0000 - mae: 52780396.0000 - val_loss: 2733755542274048.0000 - val_mae: 52285328.0000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2698002087018496.0000 - mae: 51941796.0000 - val_loss: 2647575412867072.0000 - val_mae: 51454592.0000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2612949118091264.0000 - mae: 51116524.0000 - val_loss: 2564112387145728.0000 - val_mae: 50637064.0000\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2530577282498560.0000 - mae: 50304364.0000 - val_loss: 2483280297328640.0000 - val_mae: 49832524.0000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2450802559942656.0000 - mae: 49505104.0000 - val_loss: 2404995928424448.0000 - val_mae: 49040760.0000\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2373542272303104.0000 - mae: 48718544.0000 - val_loss: 2329180091973632.0000 - val_mae: 48261580.0000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2298717499555840.0000 - mae: 47944484.0000 - val_loss: 2255754136387584.0000 - val_mae: 47494784.0000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2226252408684544.0000 - mae: 47182720.0000 - val_loss: 2184642899738624.0000 - val_mae: 46740156.0000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2156070898237440.0000 - mae: 46433064.0000 - val_loss: 2115773099147264.0000 - val_mae: 45997536.0000\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2088101832818688.0000 - mae: 45695316.0000 - val_loss: 2049074538741760.0000 - val_mae: 45266704.0000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2022275419209728.0000 - mae: 44969280.0000 - val_loss: 1984478633263104.0000 - val_mae: 44547488.0000\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1958524548546560.0000 - mae: 44254792.0000 - val_loss: 1921918944935936.0000 - val_mae: 43839696.0000\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1896782783053824.0000 - mae: 43551648.0000 - val_loss: 1861331183468544.0000 - val_mae: 43143148.0000\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1836987577270272.0000 - mae: 42859680.0000 - val_loss: 1802653877141504.0000 - val_mae: 42457676.0000\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1779077727911936.0000 - mae: 42178704.0000 - val_loss: 1745826627977216.0000 - val_mae: 41783088.0000\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1722993373872128.0000 - mae: 41508556.0000 - val_loss: 1690790245957632.0000 - val_mae: 41119224.0000\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1668677204180992.0000 - mae: 40849052.0000 - val_loss: 1637489433378816.0000 - val_mae: 40465904.0000\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1616073384263680.0000 - mae: 40200024.0000 - val_loss: 1585868624101376.0000 - val_mae: 39822968.0000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1565127824375808.0000 - mae: 39561316.0000 - val_loss: 1535875204775936.0000 - val_mae: 39190244.0000\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1515787911168000.0000 - mae: 38932748.0000 - val_loss: 1487457635794944.0000 - val_mae: 38567572.0000\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1468003581427712.0000 - mae: 38314164.0000 - val_loss: 1440566256599040.0000 - val_mae: 37954796.0000\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1421725711466496.0000 - mae: 37705416.0000 - val_loss: 1395153285677056.0000 - val_mae: 37351752.0000\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1376906519773184.0000 - mae: 37106336.0000 - val_loss: 1351171746824192.0000 - val_mae: 36758288.0000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1333500372320256.0000 - mae: 36516776.0000 - val_loss: 1308576811319296.0000 - val_mae: 36174256.0000\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1291462306168832.0000 - mae: 35936576.0000 - val_loss: 1267324724183040.0000 - val_mae: 35599504.0000\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1250749774299136.0000 - mae: 35365600.0000 - val_loss: 1227373072613376.0000 - val_mae: 35033884.0000\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1211320632344576.0000 - mae: 34803700.0000 - val_loss: 1188680920203264.0000 - val_mae: 34477252.0000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1173134614986752.0000 - mae: 34250720.0000 - val_loss: 1151208270069760.0000 - val_mae: 33929460.0000\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1136151859560448.0000 - mae: 33706528.0000 - val_loss: 1114917071486976.0000 - val_mae: 33390374.0000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1100335389081600.0000 - mae: 33170982.0000 - val_loss: 1079769877708800.0000 - val_mae: 32859850.0000\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1065647823912960.0000 - mae: 32643948.0000 - val_loss: 1045730449948672.0000 - val_mae: 32337754.0000\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1032053663465472.0000 - mae: 32125282.0000 - val_loss: 1012764160032768.0000 - val_mae: 31823958.0000\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 999518682218496.0000 - mae: 31614860.0000 - val_loss: 980837386420224.0000 - val_mae: 31318324.0000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 968009325740032.0000 - mae: 31112548.0000 - val_loss: 949917178658816.0000 - val_mae: 30820724.0000\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 937493381775360.0000 - mae: 30618220.0000 - val_loss: 919971391602688.0000 - val_mae: 30331030.0000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 907939376267264.0000 - mae: 30131742.0000 - val_loss: 890969826263040.0000 - val_mae: 29849116.0000\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 879317177335808.0000 - mae: 29652998.0000 - val_loss: 862882552086528.0000 - val_mae: 29374862.0000\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 851597189971968.0000 - mae: 29181854.0000 - val_loss: 835680712261632.0000 - val_mae: 28908144.0000\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 824751027126272.0000 - mae: 28718204.0000 - val_loss: 809336322392064.0000 - val_mae: 28448836.0000\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 798751174164480.0000 - mae: 28261914.0000 - val_loss: 783822538932224.0000 - val_mae: 27996828.0000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 773571055976448.0000 - mae: 27812878.0000 - val_loss: 759112786771968.0000 - val_mae: 27552002.0000\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 749184567214080.0000 - mae: 27370970.0000 - val_loss: 735182101413888.0000 - val_mae: 27114242.0000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 725566944706560.0000 - mae: 26936092.0000 - val_loss: 712005988122624.0000 - val_mae: 26683440.0000\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 702693827936256.0000 - mae: 26508118.0000 - val_loss: 689560287707136.0000 - val_mae: 26259480.0000\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 680541728800768.0000 - mae: 26086944.0000 - val_loss: 667822317371392.0000 - val_mae: 25842256.0000\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659088031612928.0000 - mae: 25672462.0000 - val_loss: 646769394319360.0000 - val_mae: 25431664.0000\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 638310523338752.0000 - mae: 25264566.0000 - val_loss: 626380312150016.0000 - val_mae: 25027592.0000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 618187997577216.0000 - mae: 24863150.0000 - val_loss: 606633931571200.0000 - val_mae: 24629940.0000\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598699919015936.0000 - mae: 24468110.0000 - val_loss: 587510119923712.0000 - val_mae: 24238608.0000\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 579826222104576.0000 - mae: 24079352.0000 - val_loss: 568989214310400.0000 - val_mae: 23853496.0000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561547613044736.0000 - mae: 23696766.0000 - val_loss: 551052088705024.0000 - val_mae: 23474500.0000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543845100027904.0000 - mae: 23320260.0000 - val_loss: 533680523051008.0000 - val_mae: 23101526.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 526700597215232.0000 - mae: 22949740.0000 - val_loss: 516856565727232.0000 - val_mae: 22734480.0000\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 510096824074240.0000 - mae: 22585104.0000 - val_loss: 500563003310080.0000 - val_mae: 22373264.0000\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 494016298745856.0000 - mae: 22226262.0000 - val_loss: 484783092137984.0000 - val_mae: 22017790.0000\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 478442680221696.0000 - mae: 21873122.0000 - val_loss: 469500524756992.0000 - val_mae: 21667960.0000\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 463360097255424.0000 - mae: 21525592.0000 - val_loss: 454699899682816.0000 - val_mae: 21323696.0000\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448753014145024.0000 - mae: 21183586.0000 - val_loss: 440365748322304.0000 - val_mae: 20984894.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 434606297841664.0000 - mae: 20847014.0000 - val_loss: 426483440943104.0000 - val_mae: 20651474.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420905620602880.0000 - mae: 20515790.0000 - val_loss: 413038784020480.0000 - val_mae: 20323356.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407636721795072.0000 - mae: 20189820.0000 - val_loss: 400017919574016.0000 - val_mae: 20000448.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394786179645440.0000 - mae: 19869036.0000 - val_loss: 387407560048640.0000 - val_mae: 19682672.0000\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382340706598912.0000 - mae: 19553346.0000 - val_loss: 375194619215872.0000 - val_mae: 19369942.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370287551971328.0000 - mae: 19242674.0000 - val_loss: 363366849708032.0000 - val_mae: 19062182.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358614468395008.0000 - mae: 18936938.0000 - val_loss: 351911937048576.0000 - val_mae: 18759314.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347309342720000.0000 - mae: 18636060.0000 - val_loss: 340818170740736.0000 - val_mae: 18461262.0000\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336360732884992.0000 - mae: 18339964.0000 - val_loss: 330074175832064.0000 - val_mae: 18167944.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325757230383104.0000 - mae: 18048570.0000 - val_loss: 319668778696704.0000 - val_mae: 17879284.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315487930023936.0000 - mae: 17761806.0000 - val_loss: 309591409688576.0000 - val_mae: 17595210.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305542329270272.0000 - mae: 17479600.0000 - val_loss: 299831734042624.0000 - val_mae: 17315650.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295910294683648.0000 - mae: 17201876.0000 - val_loss: 290379651874816.0000 - val_mae: 17040528.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286581894152192.0000 - mae: 16928566.0000 - val_loss: 281225616949248.0000 - val_mae: 16769783.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281225549840384.0000 - mae: 16769781.0000\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=125, optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 43336085504.0000 - mae: 74916.7578 - val_loss: 1182436.2500 - val_mae: 1087.3812\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1160937.3750 - mae: 1077.4132 - val_loss: 1145255.8750 - val_mae: 1070.1486\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1124340.6250 - mae: 1060.2909 - val_loss: 1109253.3750 - val_mae: 1053.1929\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1088904.3750 - mae: 1043.4489 - val_loss: 1074383.1250 - val_mae: 1036.5061\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1054583.7500 - mae: 1026.8693 - val_loss: 1040606.9375 - val_mae: 1020.0828\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1021340.9375 - mae: 1010.5598 - val_loss: 1007889.7500 - val_mae: 1003.9181\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 989142.5000 - mae: 994.4979 - val_loss: 976202.5000 - val_mae: 988.0104\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 957959.5625 - mae: 978.6868 - val_loss: 945517.9375 - val_mae: 972.3579\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 927764.3750 - mae: 963.1433 - val_loss: 915803.8750 - val_mae: 956.9565\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 898525.1875 - mae: 947.8441 - val_loss: 887023.5625 - val_mae: 941.7991\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 870206.0000 - mae: 932.7857 - val_loss: 859142.3125 - val_mae: 926.8788\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 842773.5625 - mae: 917.9600 - val_loss: 832144.7500 - val_mae: 912.1988\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 816211.5000 - mae: 903.3771 - val_loss: 805995.8750 - val_mae: 897.7515\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 790485.5625 - mae: 889.0251 - val_loss: 780666.3750 - val_mae: 883.5317\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 765567.6250 - mae: 874.8964 - val_loss: 756139.1875 - val_mae: 869.5408\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 741439.5625 - mae: 861.0030 - val_loss: 732381.1250 - val_mae: 855.7703\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 718069.8125 - mae: 847.3173 - val_loss: 709375.6875 - val_mae: 842.2218\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 695440.9375 - mae: 833.8600 - val_loss: 687088.5000 - val_mae: 828.8851\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673520.5000 - mae: 820.6056 - val_loss: 665506.5625 - val_mae: 815.7625\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652294.2500 - mae: 807.5740 - val_loss: 644601.5000 - val_mae: 802.8470\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631735.0000 - mae: 794.7477 - val_loss: 624353.5000 - val_mae: 790.1363\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611823.0625 - mae: 782.1160 - val_loss: 604740.8125 - val_mae: 777.6263\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592537.4375 - mae: 769.6880 - val_loss: 585748.7500 - val_mae: 765.3173\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573863.3125 - mae: 757.4620 - val_loss: 567358.7500 - val_mae: 753.2069\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555781.2500 - mae: 745.4330 - val_loss: 549540.6875 - val_mae: 741.2844\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538263.5000 - mae: 733.5875 - val_loss: 532285.7500 - val_mae: 729.5530\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521299.3438 - mae: 721.9329 - val_loss: 515565.4062 - val_mae: 718.0023\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504863.0000 - mae: 710.4557 - val_loss: 499375.5625 - val_mae: 706.6382\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488948.7188 - mae: 699.1683 - val_loss: 483695.7500 - val_mae: 695.4551\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473536.9062 - mae: 688.0580 - val_loss: 468510.4688 - val_mae: 684.4504\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458611.6250 - mae: 677.1268 - val_loss: 453797.8438 - val_mae: 673.6169\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444153.0625 - mae: 666.3632 - val_loss: 439558.1562 - val_mae: 662.9631\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430159.0938 - mae: 655.7814 - val_loss: 425762.4062 - val_mae: 652.4755\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416602.5938 - mae: 645.3609 - val_loss: 412399.7812 - val_mae: 642.1539\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403473.0000 - mae: 635.1047 - val_loss: 399460.7812 - val_mae: 631.9990\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390760.0000 - mae: 625.0231 - val_loss: 386926.3438 - val_mae: 622.0034\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378445.3750 - mae: 615.0898 - val_loss: 374782.2812 - val_mae: 612.1635\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366515.4375 - mae: 605.3147 - val_loss: 363020.5938 - val_mae: 602.4803\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 354962.1562 - mae: 595.6976 - val_loss: 351631.4375 - val_mae: 592.9531\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343775.5312 - mae: 586.2278 - val_loss: 340601.3750 - val_mae: 583.5779\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332942.3125 - mae: 576.9199 - val_loss: 329917.1250 - val_mae: 574.3509\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322449.5938 - mae: 567.7535 - val_loss: 319568.2188 - val_mae: 565.2700\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312287.0938 - mae: 558.7285 - val_loss: 309545.6562 - val_mae: 556.3340\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302445.8125 - mae: 549.8506 - val_loss: 299839.1875 - val_mae: 547.5410\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292915.5000 - mae: 541.1249 - val_loss: 290436.0000 - val_mae: 538.8858\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283683.8438 - mae: 532.5189 - val_loss: 281326.7812 - val_mae: 530.3665\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 274741.5312 - mae: 524.0573 - val_loss: 272503.2500 - val_mae: 521.9819\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266080.8125 - mae: 515.7256 - val_loss: 263961.9375 - val_mae: 513.7352\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257697.7500 - mae: 507.5302 - val_loss: 255691.1094 - val_mae: 505.6214\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249580.2656 - mae: 499.4701 - val_loss: 247674.3281 - val_mae: 497.6306\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241713.3281 - mae: 491.5345 - val_loss: 239912.2969 - val_mae: 489.7695\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 234096.9688 - mae: 483.7262 - val_loss: 232394.0938 - val_mae: 482.0332\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226720.5781 - mae: 476.0390 - val_loss: 225112.4219 - val_mae: 474.4200\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219576.6250 - mae: 468.4778 - val_loss: 218056.5156 - val_mae: 466.9244\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212655.4531 - mae: 461.0299 - val_loss: 211227.0781 - val_mae: 459.5530\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205956.6562 - mae: 453.7065 - val_loss: 204611.5625 - val_mae: 452.2980\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199468.3438 - mae: 446.4977 - val_loss: 198202.1875 - val_mae: 445.1562\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193182.8750 - mae: 439.4048 - val_loss: 191994.2188 - val_mae: 438.1280\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 187095.8281 - mae: 432.4179 - val_loss: 185984.4844 - val_mae: 431.2150\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181203.4219 - mae: 425.5563 - val_loss: 180162.6094 - val_mae: 424.4108\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175495.6562 - mae: 418.7979 - val_loss: 174520.7344 - val_mae: 417.7112\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169965.2188 - mae: 412.1417 - val_loss: 169056.2031 - val_mae: 411.1180\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 164609.2188 - mae: 405.5919 - val_loss: 163763.9375 - val_mae: 404.6305\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 159422.6250 - mae: 399.1469 - val_loss: 158638.2188 - val_mae: 398.2463\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154399.7500 - mae: 392.7995 - val_loss: 153672.0156 - val_mae: 391.9616\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149533.9844 - mae: 386.5570 - val_loss: 148864.7656 - val_mae: 385.7806\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144824.0312 - mae: 380.4223 - val_loss: 144205.0312 - val_mae: 379.6932\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140259.7656 - mae: 374.3718 - val_loss: 139695.8750 - val_mae: 373.7081\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135843.0000 - mae: 368.4306 - val_loss: 135326.2344 - val_mae: 367.8153\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131563.6719 - mae: 362.5706 - val_loss: 131094.2188 - val_mae: 362.0167\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127419.3359 - mae: 356.8171 - val_loss: 126992.5078 - val_mae: 356.3066\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123403.6016 - mae: 351.1364 - val_loss: 123022.7031 - val_mae: 350.6916\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119517.2422 - mae: 345.5612 - val_loss: 119177.5156 - val_mae: 345.1658\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115753.4531 - mae: 340.0703 - val_loss: 115453.8516 - val_mae: 339.7289\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112108.9766 - mae: 334.6711 - val_loss: 111846.4062 - val_mae: 334.3775\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108578.6484 - mae: 329.3465 - val_loss: 108350.0312 - val_mae: 329.1078\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105157.8359 - mae: 324.1178 - val_loss: 104967.4297 - val_mae: 323.9279\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101848.1953 - mae: 318.9796 - val_loss: 101686.3984 - val_mae: 318.8233\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98638.9062 - mae: 313.9041 - val_loss: 98510.3359 - val_mae: 313.8029\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95532.6016 - mae: 308.9185 - val_loss: 95434.4922 - val_mae: 308.8630\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92524.5938 - mae: 304.0082 - val_loss: 92452.8438 - val_mae: 303.9979\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89609.3984 - mae: 299.1712 - val_loss: 89566.3594 - val_mae: 299.2127\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86787.6328 - mae: 294.4178 - val_loss: 86772.0469 - val_mae: 294.5063\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84056.1484 - mae: 289.7465 - val_loss: 84063.1484 - val_mae: 289.8707\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81408.7578 - mae: 285.1382 - val_loss: 81440.0078 - val_mae: 285.3102\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78845.4922 - mae: 280.6084 - val_loss: 78898.4453 - val_mae: 280.8208\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76362.5312 - mae: 276.1469 - val_loss: 76438.5078 - val_mae: 276.4062\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73959.6094 - mae: 271.7607 - val_loss: 74056.2500 - val_mae: 272.0627\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71632.8047 - mae: 267.4493 - val_loss: 71747.6875 - val_mae: 267.7864\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69378.3125 - mae: 263.2027 - val_loss: 69509.6406 - val_mae: 263.5745\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67193.3281 - mae: 259.0160 - val_loss: 67343.4688 - val_mae: 259.4328\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65078.6953 - mae: 254.9022 - val_loss: 65244.5430 - val_mae: 255.3555\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63030.2812 - mae: 250.8456 - val_loss: 63213.2656 - val_mae: 251.3467\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61047.9258 - mae: 246.8661 - val_loss: 61243.6758 - val_mae: 247.3976\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59126.2305 - mae: 242.9500 - val_loss: 59335.6797 - val_mae: 243.5109\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57265.0430 - mae: 239.0820 - val_loss: 57487.7422 - val_mae: 239.6865\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55462.8867 - mae: 235.2844 - val_loss: 55699.4297 - val_mae: 235.9265\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53718.9336 - mae: 231.5537 - val_loss: 53965.3438 - val_mae: 232.2224\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52028.3828 - mae: 227.8718 - val_loss: 52286.2539 - val_mae: 228.5785\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 50391.6250 - mae: 224.2483 - val_loss: 50658.3008 - val_mae: 224.9893\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 50124.6953 - mae: 223.7537\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=125, optimizer=sgd; total time=   3.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 4438330967878270976.0000 - mae: 1026000448.0000 - val_loss: 236599933665280.0000 - val_mae: 15381806.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233491350421504.0000 - mae: 15280275.0000 - val_loss: 229141253193728.0000 - val_mae: 15137413.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226130699223040.0000 - mae: 15037497.0000 - val_loss: 221917705404416.0000 - val_mae: 14896902.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219002043367424.0000 - mae: 14798575.0000 - val_loss: 214921874767872.0000 - val_mae: 14660215.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212098168651776.0000 - mae: 14563448.0000 - val_loss: 208146597412864.0000 - val_mae: 14427288.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205411877650432.0000 - mae: 14332059.0000 - val_loss: 201584927571968.0000 - val_mae: 14198061.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198936392368128.0000 - mae: 14104344.0000 - val_loss: 195230070472704.0000 - val_mae: 13972475.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 192665035472896.0000 - mae: 13880248.0000 - val_loss: 189075533332480.0000 - val_mae: 13750473.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 186591364513792.0000 - mae: 13659712.0000 - val_loss: 183115041472512.0000 - val_mae: 13532001.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 180709171920896.0000 - mae: 13442681.0000 - val_loss: 177342437654528.0000 - val_mae: 13316998.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175012417896448.0000 - mae: 13229098.0000 - val_loss: 171751782744064.0000 - val_mae: 13105410.0000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 169495230414848.0000 - mae: 13018906.0000 - val_loss: 166337389264896.0000 - val_mae: 12897185.0000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 164151989108736.0000 - mae: 12812056.0000 - val_loss: 161093720735744.0000 - val_mae: 12692270.0000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 158977174274048.0000 - mae: 12608493.0000 - val_loss: 156015324561408.0000 - val_mae: 12490609.0000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153965534642176.0000 - mae: 12408165.0000 - val_loss: 151097033359360.0000 - val_mae: 12292153.0000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 149111869276160.0000 - mae: 12211019.0000 - val_loss: 146333813964800.0000 - val_mae: 12096851.0000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 144411212120064.0000 - mae: 12017006.0000 - val_loss: 141720700321792.0000 - val_mae: 11904649.0000\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 139858706169856.0000 - mae: 11826074.0000 - val_loss: 137253045141504.0000 - val_mae: 11715505.0000\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 135449746079744.0000 - mae: 11638175.0000 - val_loss: 132926217912320.0000 - val_mae: 11529363.0000\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131179751669760.0000 - mae: 11453262.0000 - val_loss: 128735772672000.0000 - val_mae: 11346178.0000\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 127044394418176.0000 - mae: 11271287.0000 - val_loss: 124677456396288.0000 - val_mae: 11165906.0000\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123039387746304.0000 - mae: 11092204.0000 - val_loss: 120747058003968.0000 - val_mae: 10988497.0000\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119160654790656.0000 - mae: 10915966.0000 - val_loss: 116940584517632.0000 - val_mae: 10813907.0000\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115404169019392.0000 - mae: 10742529.0000 - val_loss: 113254101680128.0000 - val_mae: 10642092.0000\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111766130393088.0000 - mae: 10571848.0000 - val_loss: 109683834617856.0000 - val_mae: 10473005.0000\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108242764038144.0000 - mae: 10403878.0000 - val_loss: 106226117509120.0000 - val_mae: 10306605.0000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 104830462853120.0000 - mae: 10238576.0000 - val_loss: 102877385195520.0000 - val_mae: 10142849.0000\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101525737177088.0000 - mae: 10075900.0000 - val_loss: 99634231902208.0000 - val_mae: 9981696.0000\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98325206401024.0000 - mae: 9915810.0000 - val_loss: 96493318963200.0000 - val_mae: 9823101.0000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95225540247552.0000 - mae: 9758263.0000 - val_loss: 93451399987200.0000 - val_mae: 9667026.0000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92223592988672.0000 - mae: 9603218.0000 - val_loss: 90505413132288.0000 - val_mae: 9513433.0000\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 89316302782464.0000 - mae: 9450639.0000 - val_loss: 87652271390720.0000 - val_mae: 9362279.0000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86500649730048.0000 - mae: 9300483.0000 - val_loss: 84889080692736.0000 - val_mae: 9213528.0000\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83773773316096.0000 - mae: 9152713.0000 - val_loss: 82212997300224.0000 - val_mae: 9067138.0000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81132829802496.0000 - mae: 9007289.0000 - val_loss: 79621252972544.0000 - val_mae: 8923074.0000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78575160000512.0000 - mae: 8864177.0000 - val_loss: 77111247241216.0000 - val_mae: 8781301.0000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76098129887232.0000 - mae: 8723340.0000 - val_loss: 74680362860544.0000 - val_mae: 8641780.0000\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 73699172548608.0000 - mae: 8584740.0000 - val_loss: 72326116802560.0000 - val_mae: 8504476.0000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71375855288320.0000 - mae: 8448342.0000 - val_loss: 70046063788032.0000 - val_mae: 8369353.0000\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69125774770176.0000 - mae: 8314110.0000 - val_loss: 67837905338368.0000 - val_mae: 8236377.0000\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66946607349760.0000 - mae: 8182012.0000 - val_loss: 65699342974976.0000 - val_mae: 8105513.0000\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64836163600384.0000 - mae: 8052013.0000 - val_loss: 63628216631296.0000 - val_mae: 7976730.0000\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62792241512448.0000 - mae: 7924078.5000 - val_loss: 61622383017984.0000 - val_mae: 7849992.5000\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60812748128256.0000 - mae: 7798177.5000 - val_loss: 59679757565952.0000 - val_mae: 7725267.5000\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58895670181888.0000 - mae: 7674277.0000 - val_loss: 57798385729536.0000 - val_mae: 7602525.0000\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57039006990336.0000 - mae: 7552344.5000 - val_loss: 55976325545984.0000 - val_mae: 7481732.5000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55240879505408.0000 - mae: 7432348.5000 - val_loss: 54211693772800.0000 - val_mae: 7362859.5000\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 53499442233344.0000 - mae: 7314260.5000 - val_loss: 52502699442176.0000 - val_mae: 7245875.0000\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51812891623424.0000 - mae: 7198047.5000 - val_loss: 50847572557824.0000 - val_mae: 7130748.5000\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50179516399616.0000 - mae: 7083681.5000 - val_loss: 49244643786752.0000 - val_mae: 7017453.0000\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48597634646016.0000 - mae: 6971133.5000 - val_loss: 47692227018752.0000 - val_mae: 6905955.5000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47065627361280.0000 - mae: 6860372.5000 - val_loss: 46188757778432.0000 - val_mae: 6796231.0000\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 45581909098496.0000 - mae: 6751372.0000 - val_loss: 44732684173312.0000 - val_mae: 6688249.5000\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44144965713920.0000 - mae: 6644103.5000 - val_loss: 43322500448256.0000 - val_mae: 6581983.5000\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 42753312423936.0000 - mae: 6538538.5000 - val_loss: 41956780539904.0000 - val_mae: 6477405.0000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41405531553792.0000 - mae: 6434650.5000 - val_loss: 40634115162112.0000 - val_mae: 6374489.0000\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40100238983168.0000 - mae: 6332413.5000 - val_loss: 39353141166080.0000 - val_mae: 6273208.5000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38836096729088.0000 - mae: 6231801.0000 - val_loss: 38112541540352.0000 - val_mae: 6173535.5000\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37611804557312.0000 - mae: 6132787.0000 - val_loss: 36911074770944.0000 - val_mae: 6075449.0000\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36426120953856.0000 - mae: 6035347.5000 - val_loss: 35747469983744.0000 - val_mae: 5978918.5000\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35277804404736.0000 - mae: 5939454.5000 - val_loss: 34620550676480.0000 - val_mae: 5883923.5000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34165684699136.0000 - mae: 5845085.0000 - val_loss: 33529155026944.0000 - val_mae: 5790436.0000\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33088631472128.0000 - mae: 5752217.0000 - val_loss: 32472171544576.0000 - val_mae: 5698435.5000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32045533233152.0000 - mae: 5660822.0000 - val_loss: 31448492933120.0000 - val_mae: 5607895.5000\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31035305754624.0000 - mae: 5570879.5000 - val_loss: 30457093685248.0000 - val_mae: 5518794.5000\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30056936112128.0000 - mae: 5482367.5000 - val_loss: 29496950390784.0000 - val_mae: 5431110.0000\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29109411381248.0000 - mae: 5395261.5000 - val_loss: 28567083679744.0000 - val_mae: 5344818.5000\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28191752192000.0000 - mae: 5309539.0000 - val_loss: 27666518376448.0000 - val_mae: 5259897.0000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27303016923136.0000 - mae: 5225178.5000 - val_loss: 26794338025472.0000 - val_mae: 5176324.5000\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26442303799296.0000 - mae: 5142158.0000 - val_loss: 25949663920128.0000 - val_mae: 5094081.0000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25608725725184.0000 - mae: 5060457.5000 - val_loss: 25131615256576.0000 - val_mae: 5013144.5000\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24801422868480.0000 - mae: 4980055.0000 - val_loss: 24339351076864.0000 - val_mae: 4933492.5000\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24019564756992.0000 - mae: 4900928.5000 - val_loss: 23572068171776.0000 - val_mae: 4855107.0000\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23262362861568.0000 - mae: 4823060.5000 - val_loss: 22828963332096.0000 - val_mae: 4777966.5000\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22529030750208.0000 - mae: 4746429.5000 - val_loss: 22109294166016.0000 - val_mae: 4702052.0000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21818809253888.0000 - mae: 4671016.0000 - val_loss: 21412307795968.0000 - val_mae: 4627343.5000\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21130987438080.0000 - mae: 4596801.5000 - val_loss: 20737301676032.0000 - val_mae: 4553822.5000\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20464848076800.0000 - mae: 4523765.0000 - val_loss: 20083571163136.0000 - val_mae: 4481469.5000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19819705401344.0000 - mae: 4451889.5000 - val_loss: 19450447265792.0000 - val_mae: 4410266.0000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19194900905984.0000 - mae: 4381156.0000 - val_loss: 18837286158336.0000 - val_mae: 4340194.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18589792862208.0000 - mae: 4311546.0000 - val_loss: 18243452403712.0000 - val_mae: 4271235.5000\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18003760513024.0000 - mae: 4243043.0000 - val_loss: 17668331536384.0000 - val_mae: 4203372.0000\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17436198830080.0000 - mae: 4175627.0000 - val_loss: 17111349985280.0000 - val_mae: 4136586.7500\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16886533193728.0000 - mae: 4109282.7500 - val_loss: 16571922644992.0000 - val_mae: 4070862.7500\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16354192130048.0000 - mae: 4043993.0000 - val_loss: 16049500061696.0000 - val_mae: 4006182.7500\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15838634573824.0000 - mae: 3979740.0000 - val_loss: 15543549558784.0000 - val_mae: 3942531.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15339333091328.0000 - mae: 3916508.0000 - val_loss: 15053549993984.0000 - val_mae: 3879890.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14855769686016.0000 - mae: 3854281.0000 - val_loss: 14578992807936.0000 - val_mae: 3818245.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14387447332864.0000 - mae: 3793042.5000 - val_loss: 14119398801408.0000 - val_mae: 3757579.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13933889978368.0000 - mae: 3732776.2500 - val_loss: 13674291920896.0000 - val_mae: 3697876.7500\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13494631006208.0000 - mae: 3673468.5000 - val_loss: 13243217084416.0000 - val_mae: 3639123.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13069220577280.0000 - mae: 3615102.5000 - val_loss: 12825730744320.0000 - val_mae: 3581303.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12657221435392.0000 - mae: 3557664.2500 - val_loss: 12421407178752.0000 - val_mae: 3524401.5000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12258208907264.0000 - mae: 3501138.5000 - val_loss: 12029829054464.0000 - val_mae: 3468404.2500\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11871776145408.0000 - mae: 3445510.7500 - val_loss: 11650595815424.0000 - val_mae: 3413297.2500\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11497525739520.0000 - mae: 3390767.2500 - val_loss: 11283319488512.0000 - val_mae: 3359065.2500\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11135071813632.0000 - mae: 3336893.2500 - val_loss: 10927614197760.0000 - val_mae: 3305694.5000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10784042123264.0000 - mae: 3283875.0000 - val_loss: 10583125524480.0000 - val_mae: 3253171.5000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10444080152576.0000 - mae: 3231699.0000 - val_loss: 10249499049984.0000 - val_mae: 3201484.2500\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10114833580032.0000 - mae: 3180352.0000 - val_loss: 9926386647040.0000 - val_mae: 3150617.2500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9926376161280.0000 - mae: 3150615.7500\n",
      "[CV] END learning_rate=0.001, momentum=0.1, n_hidden=1, n_neurons=125, optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 18692.0820 - mae: 105.3149 - val_loss: 25733.2578 - val_mae: 124.4705\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18629.2637 - mae: 105.2454 - val_loss: 25638.7773 - val_mae: 124.3847\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18563.7129 - mae: 105.1894 - val_loss: 25547.8516 - val_mae: 124.3006\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18503.6426 - mae: 105.1370 - val_loss: 25456.6738 - val_mae: 124.2161\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18445.6367 - mae: 105.0872 - val_loss: 25368.3398 - val_mae: 124.1303\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18383.5254 - mae: 105.0137 - val_loss: 25283.1641 - val_mae: 124.0400\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18326.9453 - mae: 104.9586 - val_loss: 25195.4668 - val_mae: 123.9543\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18270.8457 - mae: 104.8941 - val_loss: 25105.8164 - val_mae: 123.8593\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18208.3516 - mae: 104.8299 - val_loss: 25020.4258 - val_mae: 123.7711\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18150.7891 - mae: 104.7708 - val_loss: 24937.5352 - val_mae: 123.6817\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18099.2227 - mae: 104.7174 - val_loss: 24849.5273 - val_mae: 123.5893\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18041.7051 - mae: 104.6548 - val_loss: 24768.9219 - val_mae: 123.4917\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17986.0449 - mae: 104.5814 - val_loss: 24690.0879 - val_mae: 123.3901\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17938.7109 - mae: 104.5407 - val_loss: 24605.2168 - val_mae: 123.2945\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17879.9023 - mae: 104.4646 - val_loss: 24529.3848 - val_mae: 123.1964\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17827.6348 - mae: 104.4038 - val_loss: 24453.0137 - val_mae: 123.0987\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17781.1758 - mae: 104.3636 - val_loss: 24369.3672 - val_mae: 123.0039\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17726.7754 - mae: 104.3056 - val_loss: 24289.5605 - val_mae: 122.9065\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17672.4355 - mae: 104.2404 - val_loss: 24215.2129 - val_mae: 122.8006\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17622.9688 - mae: 104.1614 - val_loss: 24139.1602 - val_mae: 122.6897\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17572.7871 - mae: 104.0981 - val_loss: 24063.2793 - val_mae: 122.5838\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17521.4531 - mae: 104.0321 - val_loss: 23990.2051 - val_mae: 122.4811\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17475.0273 - mae: 103.9768 - val_loss: 23913.7598 - val_mae: 122.3751\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17425.8867 - mae: 103.9105 - val_loss: 23837.8223 - val_mae: 122.2647\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17374.9004 - mae: 103.8357 - val_loss: 23766.2168 - val_mae: 122.1550\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17325.8008 - mae: 103.7569 - val_loss: 23695.6016 - val_mae: 122.0409\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17280.8535 - mae: 103.6928 - val_loss: 23621.0449 - val_mae: 121.9298\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17233.1484 - mae: 103.6203 - val_loss: 23549.9160 - val_mae: 121.8161\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17184.7910 - mae: 103.5591 - val_loss: 23480.5996 - val_mae: 121.7114\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17137.0938 - mae: 103.4706 - val_loss: 23411.7129 - val_mae: 121.5918\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17092.7461 - mae: 103.3991 - val_loss: 23339.9961 - val_mae: 121.4771\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17044.5117 - mae: 103.3232 - val_loss: 23271.0234 - val_mae: 121.3660\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16999.8145 - mae: 103.2592 - val_loss: 23201.6211 - val_mae: 121.2550\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16953.7109 - mae: 103.1792 - val_loss: 23134.7578 - val_mae: 121.1345\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16910.5605 - mae: 103.0915 - val_loss: 23067.1074 - val_mae: 121.0120\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16860.3730 - mae: 102.9894 - val_loss: 23007.2031 - val_mae: 120.8918\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16819.4844 - mae: 102.9285 - val_loss: 22936.2207 - val_mae: 120.7842\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16775.3008 - mae: 102.8542 - val_loss: 22865.1855 - val_mae: 120.6633\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16728.7168 - mae: 102.7804 - val_loss: 22796.6504 - val_mae: 120.5501\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16684.4297 - mae: 102.7028 - val_loss: 22729.3242 - val_mae: 120.4291\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16638.6504 - mae: 102.6144 - val_loss: 22663.7520 - val_mae: 120.3032\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16593.8848 - mae: 102.5239 - val_loss: 22599.1836 - val_mae: 120.1779\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16549.6094 - mae: 102.4318 - val_loss: 22534.3027 - val_mae: 120.0506\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16509.1699 - mae: 102.3693 - val_loss: 22463.3672 - val_mae: 119.9334\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16461.0215 - mae: 102.2710 - val_loss: 22399.1797 - val_mae: 119.8041\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16417.2598 - mae: 102.1828 - val_loss: 22335.7773 - val_mae: 119.6806\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16373.3037 - mae: 102.0985 - val_loss: 22273.1641 - val_mae: 119.5584\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16331.6807 - mae: 102.0067 - val_loss: 22207.4023 - val_mae: 119.4265\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16287.1113 - mae: 101.9123 - val_loss: 22144.4746 - val_mae: 119.2980\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16245.2393 - mae: 101.8278 - val_loss: 22078.3574 - val_mae: 119.1714\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16201.1670 - mae: 101.7415 - val_loss: 22014.6016 - val_mae: 119.0443\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16157.7705 - mae: 101.6527 - val_loss: 21950.7578 - val_mae: 118.9140\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16114.2988 - mae: 101.5627 - val_loss: 21888.5176 - val_mae: 118.7828\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16071.8877 - mae: 101.4716 - val_loss: 21825.3887 - val_mae: 118.6543\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16029.1074 - mae: 101.3852 - val_loss: 21760.6660 - val_mae: 118.5245\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15985.1895 - mae: 101.2912 - val_loss: 21697.8672 - val_mae: 118.3931\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15942.6758 - mae: 101.2034 - val_loss: 21635.7324 - val_mae: 118.2632\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15903.5332 - mae: 101.1188 - val_loss: 21567.4785 - val_mae: 118.1273\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15856.2705 - mae: 101.0179 - val_loss: 21507.8516 - val_mae: 117.9964\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15815.0127 - mae: 100.9397 - val_loss: 21447.1621 - val_mae: 117.8699\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15774.2119 - mae: 100.8451 - val_loss: 21385.5410 - val_mae: 117.7354\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15731.4863 - mae: 100.7451 - val_loss: 21326.7266 - val_mae: 117.6033\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15691.2119 - mae: 100.6483 - val_loss: 21267.1738 - val_mae: 117.4691\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15650.4238 - mae: 100.5532 - val_loss: 21205.0156 - val_mae: 117.3338\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15607.3047 - mae: 100.4637 - val_loss: 21145.4902 - val_mae: 117.2040\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15568.5020 - mae: 100.3824 - val_loss: 21080.5703 - val_mae: 117.0728\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15524.4639 - mae: 100.2893 - val_loss: 21019.1523 - val_mae: 116.9407\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15485.3750 - mae: 100.2020 - val_loss: 20955.9707 - val_mae: 116.8033\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15439.8799 - mae: 100.0987 - val_loss: 20901.2754 - val_mae: 116.6716\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15402.6914 - mae: 99.9975 - val_loss: 20841.4590 - val_mae: 116.5336\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15361.6143 - mae: 99.8946 - val_loss: 20783.6484 - val_mae: 116.3902\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15322.6084 - mae: 99.7941 - val_loss: 20721.4082 - val_mae: 116.2561\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15279.2520 - mae: 99.6889 - val_loss: 20667.2109 - val_mae: 116.1194\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15242.5791 - mae: 99.5910 - val_loss: 20607.0352 - val_mae: 115.9826\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15200.7305 - mae: 99.4944 - val_loss: 20548.6602 - val_mae: 115.8504\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15161.3271 - mae: 99.4003 - val_loss: 20490.1621 - val_mae: 115.7143\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15121.9746 - mae: 99.2982 - val_loss: 20430.3574 - val_mae: 115.5754\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15079.0146 - mae: 99.1933 - val_loss: 20375.3027 - val_mae: 115.4424\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15041.6973 - mae: 99.0976 - val_loss: 20316.7656 - val_mae: 115.3072\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15000.8584 - mae: 98.9930 - val_loss: 20260.8730 - val_mae: 115.1714\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14962.2959 - mae: 98.8956 - val_loss: 20202.6094 - val_mae: 115.0343\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14921.5488 - mae: 98.7992 - val_loss: 20141.2207 - val_mae: 114.8969\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14880.4727 - mae: 98.7049 - val_loss: 20083.0234 - val_mae: 114.7608\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14841.4365 - mae: 98.6017 - val_loss: 20025.9531 - val_mae: 114.6207\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14802.2207 - mae: 98.4961 - val_loss: 19969.9258 - val_mae: 114.4816\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14762.8604 - mae: 98.3900 - val_loss: 19914.9707 - val_mae: 114.3434\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14724.4102 - mae: 98.2801 - val_loss: 19860.5527 - val_mae: 114.2063\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14687.6016 - mae: 98.1889 - val_loss: 19802.0039 - val_mae: 114.0710\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14649.5244 - mae: 98.0958 - val_loss: 19743.4922 - val_mae: 113.9305\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14607.5137 - mae: 97.9827 - val_loss: 19689.5469 - val_mae: 113.7919\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14570.6982 - mae: 97.8815 - val_loss: 19633.6211 - val_mae: 113.6561\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14532.1826 - mae: 97.7741 - val_loss: 19577.6348 - val_mae: 113.5091\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14492.7686 - mae: 97.6616 - val_loss: 19521.5957 - val_mae: 113.3709\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14453.9795 - mae: 97.5588 - val_loss: 19466.5859 - val_mae: 113.2332\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14413.7002 - mae: 97.4500 - val_loss: 19414.0566 - val_mae: 113.0970\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14377.4717 - mae: 97.3438 - val_loss: 19357.9766 - val_mae: 112.9534\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14339.4863 - mae: 97.2418 - val_loss: 19300.6836 - val_mae: 112.8155\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14297.4043 - mae: 97.1301 - val_loss: 19250.4473 - val_mae: 112.6806\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14263.1318 - mae: 97.0300 - val_loss: 19192.6211 - val_mae: 112.5385\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14224.5039 - mae: 96.9221 - val_loss: 19138.1289 - val_mae: 112.3957\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19212.4570 - mae: 107.7641\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=0, n_neurons=25, optimizer=adam; total time=   4.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 81111.7344 - mae: 277.0627 - val_loss: 83947.1484 - val_mae: 281.6153\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80694.5703 - mae: 276.3412 - val_loss: 83518.3594 - val_mae: 280.8861\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80282.0234 - mae: 275.6217 - val_loss: 83090.0000 - val_mae: 280.1559\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79868.6250 - mae: 274.9020 - val_loss: 82664.5156 - val_mae: 279.4286\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79455.3359 - mae: 274.1818 - val_loss: 82242.3828 - val_mae: 278.7051\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79044.7422 - mae: 273.4657 - val_loss: 81821.7500 - val_mae: 277.9825\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78636.8672 - mae: 272.7504 - val_loss: 81400.8984 - val_mae: 277.2577\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78232.0469 - mae: 272.0338 - val_loss: 80978.8438 - val_mae: 276.5291\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77820.7031 - mae: 271.3146 - val_loss: 80562.1953 - val_mae: 275.8076\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77420.0312 - mae: 270.6021 - val_loss: 80145.4531 - val_mae: 275.0842\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77016.8438 - mae: 269.8875 - val_loss: 79730.3672 - val_mae: 274.3618\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76615.0469 - mae: 269.1742 - val_loss: 79319.3672 - val_mae: 273.6445\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76215.6875 - mae: 268.4632 - val_loss: 78908.7969 - val_mae: 272.9261\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75823.4375 - mae: 267.7549 - val_loss: 78495.7969 - val_mae: 272.2020\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75424.4609 - mae: 267.0411 - val_loss: 78087.7578 - val_mae: 271.4843\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75025.9375 - mae: 266.3313 - val_loss: 77684.7422 - val_mae: 270.7734\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74638.5938 - mae: 265.6279 - val_loss: 77279.5312 - val_mae: 270.0569\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74248.0547 - mae: 264.9211 - val_loss: 76875.4688 - val_mae: 269.3406\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73856.0156 - mae: 264.2134 - val_loss: 76475.8516 - val_mae: 268.6304\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73466.2812 - mae: 263.5097 - val_loss: 76077.7422 - val_mae: 267.9209\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73081.5234 - mae: 262.8070 - val_loss: 75677.3906 - val_mae: 267.2057\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72696.0547 - mae: 262.1006 - val_loss: 75277.6719 - val_mae: 266.4896\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72308.7188 - mae: 261.3934 - val_loss: 74881.0859 - val_mae: 265.7771\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71926.3672 - mae: 260.6904 - val_loss: 74486.8672 - val_mae: 265.0673\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71546.8906 - mae: 259.9914 - val_loss: 74095.5156 - val_mae: 264.3604\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 71168.2188 - mae: 259.2917 - val_loss: 73704.5859 - val_mae: 263.6526\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70787.7734 - mae: 258.5920 - val_loss: 73317.1406 - val_mae: 262.9492\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70416.5234 - mae: 257.8963 - val_loss: 72926.8438 - val_mae: 262.2392\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70039.7812 - mae: 257.1969 - val_loss: 72540.5859 - val_mae: 261.5341\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 69668.2578 - mae: 256.5010 - val_loss: 72155.1797 - val_mae: 260.8289\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69293.1562 - mae: 255.8047 - val_loss: 71775.5703 - val_mae: 260.1324\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68926.2656 - mae: 255.1154 - val_loss: 71395.0938 - val_mae: 259.4323\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68559.1328 - mae: 254.4246 - val_loss: 71016.7656 - val_mae: 258.7342\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68190.9688 - mae: 253.7337 - val_loss: 70641.6953 - val_mae: 258.0405\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67831.1172 - mae: 253.0475 - val_loss: 70263.4453 - val_mae: 257.3394\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67462.8281 - mae: 252.3560 - val_loss: 69891.3047 - val_mae: 256.6472\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67104.6562 - mae: 251.6704 - val_loss: 69515.6562 - val_mae: 255.9468\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66741.7734 - mae: 250.9792 - val_loss: 69143.5625 - val_mae: 255.2511\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66384.5234 - mae: 250.2931 - val_loss: 68771.9609 - val_mae: 254.5546\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66023.9609 - mae: 249.6044 - val_loss: 68403.1562 - val_mae: 253.8614\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65663.7500 - mae: 248.9181 - val_loss: 68037.6172 - val_mae: 253.1725\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65310.9453 - mae: 248.2361 - val_loss: 67671.4062 - val_mae: 252.4805\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64955.9844 - mae: 247.5518 - val_loss: 67306.8438 - val_mae: 251.7897\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64606.9180 - mae: 246.8694 - val_loss: 66940.6328 - val_mae: 251.0939\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64249.0156 - mae: 246.1828 - val_loss: 66581.3828 - val_mae: 250.4092\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63904.9922 - mae: 245.5055 - val_loss: 66219.6172 - val_mae: 249.7179\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63554.6172 - mae: 244.8233 - val_loss: 65860.3125 - val_mae: 249.0294\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63207.4727 - mae: 244.1434 - val_loss: 65502.7188 - val_mae: 248.3428\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62864.3906 - mae: 243.4660 - val_loss: 65145.6094 - val_mae: 247.6548\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62517.1758 - mae: 242.7851 - val_loss: 64791.2031 - val_mae: 246.9704\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62172.5898 - mae: 242.1060 - val_loss: 64436.6992 - val_mae: 246.2840\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61829.9609 - mae: 241.4278 - val_loss: 64082.0781 - val_mae: 245.5955\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61486.8984 - mae: 240.7470 - val_loss: 63730.6172 - val_mae: 244.9112\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61145.3477 - mae: 240.0701 - val_loss: 63380.8555 - val_mae: 244.2281\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60808.6875 - mae: 239.3954 - val_loss: 63030.5312 - val_mae: 243.5422\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60473.8438 - mae: 238.7200 - val_loss: 62681.7578 - val_mae: 242.8574\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60137.0117 - mae: 238.0453 - val_loss: 62337.5234 - val_mae: 242.1794\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59805.0156 - mae: 237.3748 - val_loss: 61992.9961 - val_mae: 241.4991\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59469.9258 - mae: 236.7015 - val_loss: 61650.8828 - val_mae: 240.8217\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 59140.9180 - mae: 236.0336 - val_loss: 61309.3906 - val_mae: 240.1433\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58809.1445 - mae: 235.3631 - val_loss: 60972.0156 - val_mae: 239.4714\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58484.0781 - mae: 234.6992 - val_loss: 60635.0195 - val_mae: 238.7984\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58156.0977 - mae: 234.0332 - val_loss: 60299.7812 - val_mae: 238.1272\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57831.3867 - mae: 233.3680 - val_loss: 59965.0078 - val_mae: 237.4548\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57509.6133 - mae: 232.7027 - val_loss: 59628.0547 - val_mae: 236.7764\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57187.3555 - mae: 232.0351 - val_loss: 59293.4570 - val_mae: 236.1010\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56861.1875 - mae: 231.3685 - val_loss: 58964.1250 - val_mae: 235.4339\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56545.8516 - mae: 230.7092 - val_loss: 58631.9922 - val_mae: 234.7596\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56225.0234 - mae: 230.0441 - val_loss: 58303.4766 - val_mae: 234.0904\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55907.1875 - mae: 229.3837 - val_loss: 57977.3438 - val_mae: 233.4244\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55592.8477 - mae: 228.7246 - val_loss: 57652.0156 - val_mae: 232.7581\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55278.6445 - mae: 228.0660 - val_loss: 57327.2305 - val_mae: 232.0911\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54963.0234 - mae: 227.4079 - val_loss: 57006.7695 - val_mae: 231.4308\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54650.7773 - mae: 226.7522 - val_loss: 56686.9648 - val_mae: 230.7701\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54343.5078 - mae: 226.0981 - val_loss: 56364.4844 - val_mae: 230.1020\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54032.9805 - mae: 225.4389 - val_loss: 56044.6602 - val_mae: 229.4378\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53726.4453 - mae: 224.7851 - val_loss: 55726.0273 - val_mae: 228.7742\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53415.3555 - mae: 224.1290 - val_loss: 55412.3203 - val_mae: 228.1184\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53114.4961 - mae: 223.4786 - val_loss: 55094.0273 - val_mae: 227.4517\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52808.2227 - mae: 222.8228 - val_loss: 54778.9648 - val_mae: 226.7896\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 52504.8750 - mae: 222.1688 - val_loss: 54466.4414 - val_mae: 226.1311\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52202.1289 - mae: 221.5184 - val_loss: 54156.1758 - val_mae: 225.4754\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 51902.2578 - mae: 220.8694 - val_loss: 53846.0273 - val_mae: 224.8180\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 51601.1016 - mae: 220.2210 - val_loss: 53540.1094 - val_mae: 224.1677\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51306.7656 - mae: 219.5774 - val_loss: 53231.9688 - val_mae: 223.5108\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51011.8359 - mae: 218.9301 - val_loss: 52925.6953 - val_mae: 222.8562\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50714.3984 - mae: 218.2824 - val_loss: 52621.2734 - val_mae: 222.2038\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50419.8750 - mae: 217.6372 - val_loss: 52318.6289 - val_mae: 221.5529\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50128.2656 - mae: 216.9942 - val_loss: 52016.7266 - val_mae: 220.9020\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49836.5000 - mae: 216.3514 - val_loss: 51716.6406 - val_mae: 220.2527\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49550.1445 - mae: 215.7097 - val_loss: 51413.5195 - val_mae: 219.5953\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49252.7852 - mae: 215.0616 - val_loss: 51119.1523 - val_mae: 218.9547\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48969.2852 - mae: 214.4266 - val_loss: 50822.5938 - val_mae: 218.3077\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48683.3281 - mae: 213.7878 - val_loss: 50526.7695 - val_mae: 217.6600\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 48395.9258 - mae: 213.1476 - val_loss: 50233.8438 - val_mae: 217.0169\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48115.0000 - mae: 212.5119 - val_loss: 49940.3438 - val_mae: 216.3710\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47829.2148 - mae: 211.8723 - val_loss: 49649.7227 - val_mae: 215.7292\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 47550.6836 - mae: 211.2386 - val_loss: 49357.0195 - val_mae: 215.0812\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47266.8125 - mae: 210.5977 - val_loss: 49067.1719 - val_mae: 214.4376\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46989.4844 - mae: 209.9626 - val_loss: 48777.5469 - val_mae: 213.7925\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47960.4023 - mae: 212.0356\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=0, n_neurons=25, optimizer=adam; total time=   4.2s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 36358.4453 - mae: 166.4695 - val_loss: 34208.1523 - val_mae: 165.5136\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36098.6406 - mae: 165.7559 - val_loss: 33942.7695 - val_mae: 164.7776\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35848.8281 - mae: 165.0475 - val_loss: 33675.9922 - val_mae: 164.0345\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35596.0898 - mae: 164.3315 - val_loss: 33411.8984 - val_mae: 163.2959\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35347.4492 - mae: 163.6185 - val_loss: 33148.1758 - val_mae: 162.5552\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35092.6836 - mae: 162.9072 - val_loss: 32889.5195 - val_mae: 161.8253\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34844.0664 - mae: 162.2043 - val_loss: 32632.2227 - val_mae: 161.0963\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34601.3398 - mae: 161.4973 - val_loss: 32373.9375 - val_mae: 160.3616\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34351.8281 - mae: 160.7931 - val_loss: 32120.6855 - val_mae: 159.6375\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34111.5195 - mae: 160.0912 - val_loss: 31865.0898 - val_mae: 158.9045\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33867.0352 - mae: 159.3888 - val_loss: 31613.8477 - val_mae: 158.1801\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33627.6133 - mae: 158.6890 - val_loss: 31364.1328 - val_mae: 157.4570\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 33393.7070 - mae: 157.9907 - val_loss: 31112.0293 - val_mae: 156.7245\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 33152.2070 - mae: 157.2881 - val_loss: 30864.6113 - val_mae: 156.0024\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32915.0000 - mae: 156.5942 - val_loss: 30619.9902 - val_mae: 155.2848\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32679.8027 - mae: 155.9023 - val_loss: 30378.5586 - val_mae: 154.5731\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32447.8711 - mae: 155.2116 - val_loss: 30137.2031 - val_mae: 153.8593\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32218.5762 - mae: 154.5241 - val_loss: 29894.8203 - val_mae: 153.1393\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31987.0000 - mae: 153.8315 - val_loss: 29653.3965 - val_mae: 152.4192\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31758.1328 - mae: 153.1346 - val_loss: 29412.6230 - val_mae: 151.6988\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 31526.8398 - mae: 152.4463 - val_loss: 29177.0840 - val_mae: 150.9892\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31303.8594 - mae: 151.7593 - val_loss: 28941.4199 - val_mae: 150.2773\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 31077.0176 - mae: 151.0759 - val_loss: 28709.7246 - val_mae: 149.5739\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30856.7832 - mae: 150.3980 - val_loss: 28478.9766 - val_mae: 148.8696\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30634.6582 - mae: 149.7194 - val_loss: 28251.2988 - val_mae: 148.1717\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30414.4863 - mae: 149.0479 - val_loss: 28026.7734 - val_mae: 147.4801\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30201.4648 - mae: 148.3746 - val_loss: 27798.4395 - val_mae: 146.7748\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 29985.6465 - mae: 147.6972 - val_loss: 27571.0723 - val_mae: 146.0687\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 29766.5098 - mae: 147.0213 - val_loss: 27350.8711 - val_mae: 145.3812\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29554.0801 - mae: 146.3564 - val_loss: 27130.8008 - val_mae: 144.6919\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29344.2031 - mae: 145.6918 - val_loss: 26909.2871 - val_mae: 143.9944\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29134.8223 - mae: 145.0201 - val_loss: 26689.1230 - val_mae: 143.2986\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28922.6660 - mae: 144.3500 - val_loss: 26472.0957 - val_mae: 142.6092\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28715.1699 - mae: 143.6833 - val_loss: 26255.7773 - val_mae: 141.9196\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28508.6133 - mae: 143.0213 - val_loss: 26041.6406 - val_mae: 141.2335\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28300.8242 - mae: 142.3600 - val_loss: 25831.1289 - val_mae: 140.5548\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28095.9629 - mae: 141.7008 - val_loss: 25620.2598 - val_mae: 139.8731\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27894.2070 - mae: 141.0415 - val_loss: 25407.8145 - val_mae: 139.1830\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27694.0039 - mae: 140.3773 - val_loss: 25194.6602 - val_mae: 138.4875\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27491.1875 - mae: 139.7096 - val_loss: 24985.1660 - val_mae: 137.8013\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27287.6133 - mae: 139.0517 - val_loss: 24781.1953 - val_mae: 137.1295\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27089.9902 - mae: 138.4017 - val_loss: 24577.9922 - val_mae: 136.4574\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26897.8867 - mae: 137.7485 - val_loss: 24372.0742 - val_mae: 135.7734\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26700.3613 - mae: 137.0913 - val_loss: 24169.7715 - val_mae: 135.0977\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26507.5137 - mae: 136.4409 - val_loss: 23968.4883 - val_mae: 134.4227\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26310.6211 - mae: 135.7926 - val_loss: 23772.0645 - val_mae: 133.7599\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 26124.1641 - mae: 135.1462 - val_loss: 23571.7344 - val_mae: 133.0816\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25932.9727 - mae: 134.4959 - val_loss: 23373.5664 - val_mae: 132.4080\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25746.0215 - mae: 133.8481 - val_loss: 23176.3125 - val_mae: 131.7333\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25551.4316 - mae: 133.2029 - val_loss: 22985.3613 - val_mae: 131.0773\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25367.5977 - mae: 132.5647 - val_loss: 22792.6895 - val_mae: 130.4125\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25180.8984 - mae: 131.9244 - val_loss: 22601.2148 - val_mae: 129.7490\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25000.2773 - mae: 131.2847 - val_loss: 22408.5645 - val_mae: 129.0780\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24816.0156 - mae: 130.6394 - val_loss: 22219.4102 - val_mae: 128.4170\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24632.8301 - mae: 130.0033 - val_loss: 22033.9004 - val_mae: 127.7652\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24457.3945 - mae: 129.3695 - val_loss: 21846.2480 - val_mae: 127.1029\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24276.4297 - mae: 128.7357 - val_loss: 21662.0801 - val_mae: 126.4489\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24099.7168 - mae: 128.1042 - val_loss: 21479.7578 - val_mae: 125.7981\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23923.5820 - mae: 127.4792 - val_loss: 21300.2969 - val_mae: 125.1549\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23750.3613 - mae: 126.8583 - val_loss: 21120.9531 - val_mae: 124.5085\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23581.7305 - mae: 126.2325 - val_loss: 20939.7754 - val_mae: 123.8533\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23404.2773 - mae: 125.6065 - val_loss: 20765.8008 - val_mae: 123.2195\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23234.6406 - mae: 124.9926 - val_loss: 20591.5215 - val_mae: 122.5827\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23069.8047 - mae: 124.3746 - val_loss: 20413.3262 - val_mae: 121.9291\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22894.5762 - mae: 123.7473 - val_loss: 20241.2715 - val_mae: 121.2947\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22729.2773 - mae: 123.1329 - val_loss: 20067.8301 - val_mae: 120.6523\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22562.6484 - mae: 122.5145 - val_loss: 19896.6348 - val_mae: 120.0146\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22398.5742 - mae: 121.8979 - val_loss: 19725.2363 - val_mae: 119.3734\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22232.0078 - mae: 121.2829 - val_loss: 19556.4277 - val_mae: 118.7385\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22071.3477 - mae: 120.6704 - val_loss: 19389.1094 - val_mae: 118.1060\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21910.9141 - mae: 120.0607 - val_loss: 19222.3262 - val_mae: 117.4726\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21748.7578 - mae: 119.4521 - val_loss: 19059.0195 - val_mae: 116.8492\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21591.1992 - mae: 118.8508 - val_loss: 18895.7402 - val_mae: 116.2225\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21430.7734 - mae: 118.2441 - val_loss: 18733.1289 - val_mae: 115.5959\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21275.9590 - mae: 117.6360 - val_loss: 18568.9395 - val_mae: 114.9606\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21116.2051 - mae: 117.0293 - val_loss: 18409.2324 - val_mae: 114.3379\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20961.0918 - mae: 116.4273 - val_loss: 18250.4180 - val_mae: 113.7167\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20807.7148 - mae: 115.8274 - val_loss: 18092.3652 - val_mae: 113.0953\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20654.7051 - mae: 115.2284 - val_loss: 17935.8516 - val_mae: 112.4768\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20504.6973 - mae: 114.6289 - val_loss: 17777.6191 - val_mae: 111.8491\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20354.9316 - mae: 114.0241 - val_loss: 17619.7207 - val_mae: 111.2197\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20200.3555 - mae: 113.4238 - val_loss: 17468.3223 - val_mae: 110.6112\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20053.5938 - mae: 112.8362 - val_loss: 17317.6445 - val_mae: 110.0037\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19908.5664 - mae: 112.2486 - val_loss: 17168.0137 - val_mae: 109.3974\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19760.3223 - mae: 111.6651 - val_loss: 17021.3145 - val_mae: 108.7989\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19618.3164 - mae: 111.0837 - val_loss: 16873.0273 - val_mae: 108.1915\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19476.0547 - mae: 110.4969 - val_loss: 16724.0098 - val_mae: 107.5777\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19331.2676 - mae: 109.9067 - val_loss: 16577.2246 - val_mae: 106.9709\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19188.9629 - mae: 109.3210 - val_loss: 16432.2949 - val_mae: 106.3690\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19046.7578 - mae: 108.7399 - val_loss: 16287.8320 - val_mae: 105.7657\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18907.7520 - mae: 108.1550 - val_loss: 16141.7646 - val_mae: 105.1537\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18768.4941 - mae: 107.5668 - val_loss: 15998.6240 - val_mae: 104.5499\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18630.4121 - mae: 106.9873 - val_loss: 15858.0391 - val_mae: 103.9529\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18490.2227 - mae: 106.4129 - val_loss: 15721.4561 - val_mae: 103.3693\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18359.6777 - mae: 105.8413 - val_loss: 15579.5449 - val_mae: 102.7609\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18219.8105 - mae: 105.2623 - val_loss: 15442.7148 - val_mae: 102.1703\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18091.4453 - mae: 104.6875 - val_loss: 15302.7002 - val_mae: 101.5651\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17952.2363 - mae: 104.1106 - val_loss: 15169.5117 - val_mae: 100.9845\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17823.8809 - mae: 103.5505 - val_loss: 15035.3867 - val_mae: 100.3967\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17691.6504 - mae: 102.9851 - val_loss: 14905.1572 - val_mae: 99.8223\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17358.7305 - mae: 104.2630\n",
      "[CV] END learning_rate=0.0001, momentum=0.9, n_hidden=0, n_neurons=25, optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1858652317012344132079714304.0000 - mae: 11770739556352.0000 - val_loss: 101918191409008048145568840548352.0000 - val_mae: 9881561180667904.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 2550929992751861207004086272.0000 - val_loss: inf - val_mae: 2105622065565933168803694247936.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 356995705987828441484886016.0000 - mae: 5177042010112.0000 - val_loss: 17348662169085884835149960445952.0000 - val_mae: 4088889664864256.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 880604839419619282826297344.0000 - val_loss: inf - val_mae: 726268835225496357165196115968.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 45ms/step - loss: 10991525217737311238557270016.0000 - mae: 29790379704320.0000 - val_loss: 480032063099816687048007159382016.0000 - val_mae: 21422897440489472.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 4246371126010221634089123840.0000 - val_loss: inf - val_mae: 3348844808451574469538990784512.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=0.0001, momentum=0.5, n_hidden=0, n_neurons=5, optimizer=nesterov; total time=   0.9s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 138041230360576.0000 - mae: 4142733.5000 - val_loss: 53655815248150528.0000 - val_mae: 226719872.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51476925998085645025673216.0000 - mae: 2643988316160.0000 - val_loss: 19328610596636836337318625280.0000 - val_mae: 136356361666560.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 1551716433585504256.0000 - val_loss: inf - val_mae: 85549076699762655232.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 1004184902737368595824640.0000 - val_loss: inf - val_mae: 47423830448640274481545216.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 568909761493995409782800908288.0000 - val_loss: inf - val_mae: 28732049130898128055796754284544.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: inf - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 78884733190144.0000 - mae: 3274221.2500 - val_loss: 25575808693174272.0000 - val_mae: 157041600.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16561731248735412092403712.0000 - mae: 1480730738688.0000 - val_loss: 6091947800527310077277765632.0000 - val_mae: 76642877702144.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 723839978085285888.0000 - val_loss: inf - val_mae: 34592397227460657152.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 336837150469169203904512.0000 - val_loss: inf - val_mae: 15290190262205585058430976.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 147342443295220211441043767296.0000 - val_loss: inf - val_mae: 7045368220143578987319254843392.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: inf - mae: 62318882026137157059599633542545408.0000 - val_loss: inf - val_mae: inf\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.7s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 74941080797184.0000 - mae: 3271856.5000 - val_loss: 21204040939470848.0000 - val_mae: 142425248.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10655335133221617957601280.0000 - mae: 1173033058304.0000 - val_loss: 3702212836189152416114933760.0000 - val_mae: 59447850303488.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: inf - mae: 533760771562143744.0000 - val_loss: inf - val_mae: 24285665388641910784.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: inf - mae: 217096884728523214815232.0000 - val_loss: inf - val_mae: 10237684706491769213157376.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: inf - mae: 96418502095740488621859274752.0000 - val_loss: inf - val_mae: 4275917129009425443594763763712.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: inf - mae: 38790625825920240974754025918431232.0000 - val_loss: inf - val_mae: 1717631227548769477133466122682630144.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan    \n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "[CV] END learning_rate=1e-05, momentum=0.5, n_hidden=0, n_neurons=25, optimizer=sgd; total time=   0.8s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 21ms/step - loss: 640.7100 - mae: 23.2366 - val_loss: 381.8331 - val_mae: 18.5397\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488.3607 - mae: 20.1261 - val_loss: 305.8228 - val_mae: 16.3618\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.2238 - mae: 17.6357 - val_loss: 218.7058 - val_mae: 13.4385\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.2447 - mae: 14.4523 - val_loss: 131.5193 - val_mae: 9.9481\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 194.1373 - mae: 10.9256 - val_loss: 71.7712 - val_mae: 7.1317\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.0760 - mae: 8.2147 - val_loss: 45.2768 - val_mae: 5.5070\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.5772 - mae: 6.8257 - val_loss: 38.3370 - val_mae: 5.1372\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.7052 - mae: 6.3510 - val_loss: 39.0630 - val_mae: 5.2836\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.7314 - mae: 6.3026 - val_loss: 41.4117 - val_mae: 5.3771\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5592 - mae: 6.3647 - val_loss: 42.2201 - val_mae: 5.4156\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4814 - mae: 6.3751 - val_loss: 43.3259 - val_mae: 5.4631\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.4297 - mae: 6.3965 - val_loss: 43.7828 - val_mae: 5.4813\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4684 - mae: 6.4094 - val_loss: 44.5719 - val_mae: 5.5110\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.7994 - mae: 6.4607 - val_loss: 44.1134 - val_mae: 5.4940\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.3831 - mae: 6.4409 - val_loss: 43.9017 - val_mae: 5.4859\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.6207 - mae: 6.4486 - val_loss: 42.9911 - val_mae: 5.4493\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4894 - mae: 6.3877 - val_loss: 43.6997 - val_mae: 5.4780\n",
      "Epoch 17: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 95.3975 - mae: 7.4580\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=2, n_neurons=5, optimizer=nesterov; total time=   1.2s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 21ms/step - loss: 1736.2197 - mae: 31.3371 - val_loss: 429.5647 - val_mae: 19.7851\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 608.1123 - mae: 22.4787 - val_loss: 415.5169 - val_mae: 19.4269\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.2255 - mae: 22.1255 - val_loss: 401.8046 - val_mae: 19.0707\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 576.6943 - mae: 21.7697 - val_loss: 388.5852 - val_mae: 18.7209\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 561.6883 - mae: 21.4247 - val_loss: 375.8817 - val_mae: 18.3785\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.2470 - mae: 21.0784 - val_loss: 363.6791 - val_mae: 18.0435\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.3110 - mae: 20.7490 - val_loss: 351.8934 - val_mae: 17.7139\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.8279 - mae: 20.4295 - val_loss: 340.4186 - val_mae: 17.3869\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 506.6515 - mae: 20.0985 - val_loss: 329.2537 - val_mae: 17.0628\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 493.8150 - mae: 19.7756 - val_loss: 318.4917 - val_mae: 16.7445\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 481.4177 - mae: 19.4599 - val_loss: 308.2245 - val_mae: 16.4351\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.5369 - mae: 19.1559 - val_loss: 298.1982 - val_mae: 16.1272\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.9135 - mae: 18.8494 - val_loss: 288.5354 - val_mae: 15.8247\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 446.6893 - mae: 18.5487 - val_loss: 279.2691 - val_mae: 15.5292\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.8716 - mae: 18.2574 - val_loss: 270.2331 - val_mae: 15.2355\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 425.3077 - mae: 17.9600 - val_loss: 261.5619 - val_mae: 14.9482\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.1300 - mae: 17.6804 - val_loss: 253.1001 - val_mae: 14.6624\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.1847 - mae: 17.3942 - val_loss: 245.0289 - val_mae: 14.3846\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.6532 - mae: 17.1235 - val_loss: 237.1741 - val_mae: 14.1089\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.3528 - mae: 16.8449 - val_loss: 229.6309 - val_mae: 13.8390\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 377.3935 - mae: 16.5747 - val_loss: 222.3618 - val_mae: 13.5738\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.7340 - mae: 16.3181 - val_loss: 215.3764 - val_mae: 13.3140\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.3751 - mae: 16.0618 - val_loss: 208.5765 - val_mae: 13.0726\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 352.2142 - mae: 15.8070 - val_loss: 201.9414 - val_mae: 12.8350\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 344.2284 - mae: 15.5555 - val_loss: 195.6471 - val_mae: 12.6051\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.6190 - mae: 15.3154 - val_loss: 189.5345 - val_mae: 12.3774\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 329.2233 - mae: 15.0774 - val_loss: 183.7740 - val_mae: 12.1586\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.2044 - mae: 14.8512 - val_loss: 178.1451 - val_mae: 11.9405\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.3176 - mae: 14.6253 - val_loss: 172.7032 - val_mae: 11.7255\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 308.6440 - mae: 14.4104 - val_loss: 167.4319 - val_mae: 11.5130\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.1641 - mae: 14.1982 - val_loss: 162.4299 - val_mae: 11.3074\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.9646 - mae: 13.9954 - val_loss: 157.4405 - val_mae: 11.0981\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 289.7716 - mae: 13.7865 - val_loss: 152.6952 - val_mae: 10.8949\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 283.8594 - mae: 13.5868 - val_loss: 148.1314 - val_mae: 10.6956\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.1394 - mae: 13.3886 - val_loss: 143.6776 - val_mae: 10.4969\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.5458 - mae: 13.1917 - val_loss: 139.4219 - val_mae: 10.3032\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.1746 - mae: 13.0017 - val_loss: 135.3830 - val_mae: 10.1167\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.0514 - mae: 12.8178 - val_loss: 131.4806 - val_mae: 9.9464\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.0711 - mae: 12.6390 - val_loss: 127.6791 - val_mae: 9.7771\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.2030 - mae: 12.4669 - val_loss: 124.0013 - val_mae: 9.6099\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 247.4756 - mae: 12.2886 - val_loss: 120.4724 - val_mae: 9.4460\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 242.9111 - mae: 12.1192 - val_loss: 117.0835 - val_mae: 9.2852\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 238.5036 - mae: 11.9613 - val_loss: 113.8026 - val_mae: 9.1263\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 234.2168 - mae: 11.7989 - val_loss: 110.6263 - val_mae: 8.9692\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 230.0593 - mae: 11.6376 - val_loss: 107.5964 - val_mae: 8.8265\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226.0517 - mae: 11.4908 - val_loss: 104.7041 - val_mae: 8.6901\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.2158 - mae: 11.3465 - val_loss: 101.9312 - val_mae: 8.5566\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 218.5127 - mae: 11.2047 - val_loss: 99.1859 - val_mae: 8.4215\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.8182 - mae: 11.0616 - val_loss: 96.5156 - val_mae: 8.2898\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 211.2250 - mae: 10.9193 - val_loss: 94.0349 - val_mae: 8.1743\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 207.8483 - mae: 10.7845 - val_loss: 91.6040 - val_mae: 8.0587\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 204.5371 - mae: 10.6506 - val_loss: 89.2675 - val_mae: 7.9450\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 201.3087 - mae: 10.5229 - val_loss: 87.0157 - val_mae: 7.8330\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 198.2047 - mae: 10.3997 - val_loss: 84.8946 - val_mae: 7.7353\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 195.2363 - mae: 10.2846 - val_loss: 82.7850 - val_mae: 7.6371\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 192.2845 - mae: 10.1675 - val_loss: 80.7660 - val_mae: 7.5409\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 189.4366 - mae: 10.0558 - val_loss: 78.8500 - val_mae: 7.4545\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.7070 - mae: 9.9474 - val_loss: 77.0081 - val_mae: 7.3734\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 184.0707 - mae: 9.8488 - val_loss: 75.1925 - val_mae: 7.2916\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 181.4506 - mae: 9.7426 - val_loss: 73.4610 - val_mae: 7.2117\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 178.9436 - mae: 9.6450 - val_loss: 71.8377 - val_mae: 7.1349\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.5576 - mae: 9.5546 - val_loss: 70.2773 - val_mae: 7.0594\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 174.2516 - mae: 9.4631 - val_loss: 68.7696 - val_mae: 6.9847\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 172.0080 - mae: 9.3804 - val_loss: 67.3172 - val_mae: 6.9109\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 169.8400 - mae: 9.2983 - val_loss: 65.9431 - val_mae: 6.8394\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 167.7486 - mae: 9.2153 - val_loss: 64.5838 - val_mae: 6.7670\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 165.6814 - mae: 9.1364 - val_loss: 63.3253 - val_mae: 6.6982\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 163.7400 - mae: 9.0645 - val_loss: 62.0623 - val_mae: 6.6274\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 161.7847 - mae: 8.9906 - val_loss: 60.8768 - val_mae: 6.5593\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 159.9172 - mae: 8.9215 - val_loss: 59.7350 - val_mae: 6.4920\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.1182 - mae: 8.8539 - val_loss: 58.6727 - val_mae: 6.4277\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 156.4130 - mae: 8.7927 - val_loss: 57.6147 - val_mae: 6.3620\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 154.7053 - mae: 8.7318 - val_loss: 56.6012 - val_mae: 6.2974\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 153.0490 - mae: 8.6699 - val_loss: 55.6201 - val_mae: 6.2332\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 151.4335 - mae: 8.6133 - val_loss: 54.6889 - val_mae: 6.1705\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.8954 - mae: 8.5593 - val_loss: 53.8234 - val_mae: 6.1107\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.4202 - mae: 8.5012 - val_loss: 52.9467 - val_mae: 6.0503\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 146.9332 - mae: 8.4465 - val_loss: 52.1625 - val_mae: 6.0006\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.5744 - mae: 8.3963 - val_loss: 51.3884 - val_mae: 5.9502\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.2310 - mae: 8.3487 - val_loss: 50.6417 - val_mae: 5.9001\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.9097 - mae: 8.3023 - val_loss: 49.9539 - val_mae: 5.8527\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 141.6711 - mae: 8.2561 - val_loss: 49.2788 - val_mae: 5.8048\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.4449 - mae: 8.2149 - val_loss: 48.6160 - val_mae: 5.7563\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.2280 - mae: 8.1691 - val_loss: 48.0082 - val_mae: 5.7105\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.0901 - mae: 8.1282 - val_loss: 47.4194 - val_mae: 5.6647\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.9751 - mae: 8.0880 - val_loss: 46.8650 - val_mae: 5.6203\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.9083 - mae: 8.0475 - val_loss: 46.3163 - val_mae: 5.5759\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.8386 - mae: 8.0129 - val_loss: 45.7884 - val_mae: 5.5383\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.7927 - mae: 7.9722 - val_loss: 45.2960 - val_mae: 5.5082\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.8035 - mae: 7.9370 - val_loss: 44.8457 - val_mae: 5.4797\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.8763 - mae: 7.9070 - val_loss: 44.4006 - val_mae: 5.4507\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.9557 - mae: 7.8744 - val_loss: 43.9835 - val_mae: 5.4265\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.0587 - mae: 7.8435 - val_loss: 43.5701 - val_mae: 5.4040\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.1672 - mae: 7.8115 - val_loss: 43.1958 - val_mae: 5.3829\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3373 - mae: 7.7832 - val_loss: 42.8418 - val_mae: 5.3624\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.5366 - mae: 7.7513 - val_loss: 42.5035 - val_mae: 5.3477\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.7583 - mae: 7.7251 - val_loss: 42.1685 - val_mae: 5.3326\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.9721 - mae: 7.6955 - val_loss: 41.8668 - val_mae: 5.3185\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.2493 - mae: 7.6718 - val_loss: 41.5758 - val_mae: 5.3043\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5293 - mae: 7.6470 - val_loss: 41.3125 - val_mae: 5.2909\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 68.1064 - mae: 5.9345\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=2, n_neurons=5, optimizer=nesterov; total time=   4.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2684123136.0000 - mae: 18638.9258 - val_loss: 88602.1094 - val_mae: 297.5404\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87479.3281 - mae: 295.6366 - val_loss: 85810.5469 - val_mae: 292.8118\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84723.8672 - mae: 290.9373 - val_loss: 83106.6641 - val_mae: 288.1577\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82055.0391 - mae: 286.3178 - val_loss: 80488.7891 - val_mae: 283.5789\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79471.0469 - mae: 281.7656 - val_loss: 77953.8047 - val_mae: 279.0735\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76968.8672 - mae: 277.2894 - val_loss: 75498.7266 - val_mae: 274.6396\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74545.4141 - mae: 272.8867 - val_loss: 73119.5000 - val_mae: 270.2734\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72197.0312 - mae: 268.5440 - val_loss: 70816.3828 - val_mae: 265.9785\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69923.7109 - mae: 264.2818 - val_loss: 68586.3672 - val_mae: 261.7529\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67722.4219 - mae: 260.0852 - val_loss: 66425.8203 - val_mae: 257.5927\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65589.8125 - mae: 255.9523 - val_loss: 64333.6094 - val_mae: 253.4991\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63524.7227 - mae: 251.8857 - val_loss: 62308.6797 - val_mae: 249.4732\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61525.8281 - mae: 247.8865 - val_loss: 60346.4062 - val_mae: 245.5089\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59588.8789 - mae: 243.9486 - val_loss: 58445.8672 - val_mae: 241.6073\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57712.9062 - mae: 240.0683 - val_loss: 56605.7695 - val_mae: 237.7687\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55896.4258 - mae: 236.2563 - val_loss: 54822.1953 - val_mae: 233.9880\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54135.9648 - mae: 232.4970 - val_loss: 53096.2969 - val_mae: 230.2705\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52432.3047 - mae: 228.8060 - val_loss: 51424.7539 - val_mae: 226.6119\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50782.3359 - mae: 225.1750 - val_loss: 49806.4336 - val_mae: 223.0127\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49184.7969 - mae: 221.5993 - val_loss: 48238.1992 - val_mae: 219.4685\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47636.8164 - mae: 218.0771 - val_loss: 46720.1406 - val_mae: 215.9823\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46138.2461 - mae: 214.6169 - val_loss: 45249.3789 - val_mae: 212.5502\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44686.3711 - mae: 211.2106 - val_loss: 43824.5312 - val_mae: 209.1716\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43279.8125 - mae: 207.8506 - val_loss: 42443.9414 - val_mae: 205.8449\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 41917.0078 - mae: 204.5445 - val_loss: 41107.2695 - val_mae: 202.5721\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40597.5234 - mae: 201.2949 - val_loss: 39812.9688 - val_mae: 199.3519\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39319.8906 - mae: 198.0942 - val_loss: 38559.8398 - val_mae: 196.1837\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38082.8125 - mae: 194.9462 - val_loss: 37345.4961 - val_mae: 193.0640\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36884.1289 - mae: 191.8487 - val_loss: 36170.3008 - val_mae: 189.9961\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35723.9805 - mae: 188.7986 - val_loss: 35031.5156 - val_mae: 186.9752\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34599.8242 - mae: 185.7963 - val_loss: 33928.7539 - val_mae: 184.0026\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33511.1719 - mae: 182.8485 - val_loss: 32860.5195 - val_mae: 181.0766\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32456.7559 - mae: 179.9375 - val_loss: 31827.3418 - val_mae: 178.2009\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31436.7578 - mae: 177.0809 - val_loss: 30826.0371 - val_mae: 175.3689\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30448.2344 - mae: 174.2708 - val_loss: 29855.7969 - val_mae: 172.5804\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29490.5508 - mae: 171.4987 - val_loss: 28917.7402 - val_mae: 169.8409\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 28564.5000 - mae: 168.7708 - val_loss: 28008.9766 - val_mae: 167.1442\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27667.3574 - mae: 166.0949 - val_loss: 27128.8457 - val_mae: 164.4903\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 26798.4219 - mae: 163.4600 - val_loss: 26275.7266 - val_mae: 161.8763\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25956.1973 - mae: 160.8663 - val_loss: 25449.4824 - val_mae: 159.3038\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25140.5352 - mae: 158.3103 - val_loss: 24649.5977 - val_mae: 156.7731\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24350.7188 - mae: 155.7995 - val_loss: 23872.9961 - val_mae: 154.2764\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23584.1523 - mae: 153.3177 - val_loss: 23122.4512 - val_mae: 151.8244\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22843.2148 - mae: 150.8800 - val_loss: 22395.9023 - val_mae: 149.4125\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22125.8555 - mae: 148.4859 - val_loss: 21691.3457 - val_mae: 147.0359\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21430.3516 - mae: 146.1235 - val_loss: 21009.8711 - val_mae: 144.7000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20757.5918 - mae: 143.7986 - val_loss: 20350.1660 - val_mae: 142.4022\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20106.2480 - mae: 141.5214 - val_loss: 19710.8594 - val_mae: 140.1395\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19475.0684 - mae: 139.2717 - val_loss: 19091.5000 - val_mae: 137.9120\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18863.6016 - mae: 137.0576 - val_loss: 18491.7988 - val_mae: 135.7203\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18271.5508 - mae: 134.8792 - val_loss: 17911.2969 - val_mae: 133.5646\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17698.3984 - mae: 132.7392 - val_loss: 17348.7188 - val_mae: 131.4417\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17142.9277 - mae: 130.6337 - val_loss: 16803.5098 - val_mae: 129.3511\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16604.6523 - mae: 128.5540 - val_loss: 16275.5771 - val_mae: 127.2941\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16083.4443 - mae: 126.5136 - val_loss: 15764.6494 - val_mae: 125.2711\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15579.0137 - mae: 124.5026 - val_loss: 15270.0322 - val_mae: 123.2811\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15090.6143 - mae: 122.5273 - val_loss: 14790.3955 - val_mae: 121.3203\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14617.0615 - mae: 120.5775 - val_loss: 14325.9912 - val_mae: 119.3910\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14158.5039 - mae: 118.6646 - val_loss: 13875.8506 - val_mae: 117.4907\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13714.1436 - mae: 116.7738 - val_loss: 13440.9180 - val_mae: 115.6249\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13284.6318 - mae: 114.9217 - val_loss: 13018.7109 - val_mae: 113.7845\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12867.8076 - mae: 113.0894 - val_loss: 12610.4062 - val_mae: 111.9760\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12464.6875 - mae: 111.2930 - val_loss: 12215.3496 - val_mae: 110.1978\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12074.5850 - mae: 109.5316 - val_loss: 11832.3730 - val_mae: 108.4462\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11696.4668 - mae: 107.7860 - val_loss: 11461.7900 - val_mae: 106.7239\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11330.4893 - mae: 106.0777 - val_loss: 11102.0273 - val_mae: 105.0249\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10975.2822 - mae: 104.3909 - val_loss: 10754.0254 - val_mae: 103.3549\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10631.7090 - mae: 102.7296 - val_loss: 10417.5605 - val_mae: 101.7141\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10299.3789 - mae: 101.1040 - val_loss: 10090.5400 - val_mae: 100.0937\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9976.5547 - mae: 99.4923 - val_loss: 9774.8838 - val_mae: 98.5043\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9664.8213 - mae: 97.9145 - val_loss: 9468.7305 - val_mae: 96.9378\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9362.5254 - mae: 96.3572 - val_loss: 9172.4395 - val_mae: 95.3973\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9069.9619 - mae: 94.8305 - val_loss: 8885.6055 - val_mae: 93.8819\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8786.7061 - mae: 93.3214 - val_loss: 8607.6182 - val_mae: 92.3895\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8512.1973 - mae: 91.8401 - val_loss: 8338.4102 - val_mae: 90.9209\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8246.3467 - mae: 90.3796 - val_loss: 8077.5352 - val_mae: 89.4748\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7988.7476 - mae: 88.9409 - val_loss: 7825.0293 - val_mae: 88.0525\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7739.3662 - mae: 87.5282 - val_loss: 7580.1113 - val_mae: 86.6506\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7497.5928 - mae: 86.1287 - val_loss: 7343.9414 - val_mae: 85.2769\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7264.3271 - mae: 84.7703 - val_loss: 7114.8467 - val_mae: 83.9229\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7038.0122 - mae: 83.4279 - val_loss: 6891.9956 - val_mae: 82.5845\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6817.9678 - mae: 82.0947 - val_loss: 6676.5811 - val_mae: 81.2699\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6605.2041 - mae: 80.7932 - val_loss: 6467.6587 - val_mae: 79.9742\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6398.9136 - mae: 79.5059 - val_loss: 6265.8208 - val_mae: 78.7021\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6199.6128 - mae: 78.2366 - val_loss: 6070.6587 - val_mae: 77.4523\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6006.8589 - mae: 76.9967 - val_loss: 5881.5342 - val_mae: 76.2217\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5820.0825 - mae: 75.7757 - val_loss: 5698.4868 - val_mae: 75.0113\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5639.2881 - mae: 74.5726 - val_loss: 5521.0571 - val_mae: 73.8191\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5464.0518 - mae: 73.3900 - val_loss: 5349.2339 - val_mae: 72.6460\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5294.3652 - mae: 72.2249 - val_loss: 5182.9375 - val_mae: 71.4923\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5130.0781 - mae: 71.0808 - val_loss: 5021.4365 - val_mae: 70.3537\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4970.5420 - mae: 69.9500 - val_loss: 4864.6836 - val_mae: 69.2307\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4815.7642 - mae: 68.8305 - val_loss: 4713.4375 - val_mae: 68.1296\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4666.4102 - mae: 67.7331 - val_loss: 4567.2715 - val_mae: 67.0483\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4521.9941 - mae: 66.6627 - val_loss: 4425.1655 - val_mae: 65.9801\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4381.6812 - mae: 65.5986 - val_loss: 4288.1558 - val_mae: 64.9335\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4246.3140 - mae: 64.5617 - val_loss: 4155.0537 - val_mae: 63.9004\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4114.8457 - mae: 63.5320 - val_loss: 4026.1426 - val_mae: 62.8836\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3987.5132 - mae: 62.5228 - val_loss: 3901.2939 - val_mae: 61.8830\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3864.2109 - mae: 61.5258 - val_loss: 3780.6631 - val_mae: 60.9005\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4001.2874 - mae: 62.4769\n",
      "[CV] END learning_rate=0.001, momentum=0.9, n_hidden=2, n_neurons=5, optimizer=nesterov; total time=   3.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [            nan -5.18409805e+01             nan -6.67791176e+01\n",
      " -8.01099080e+03 -2.56524972e+02 -5.72521642e+01 -5.51805585e+01\n",
      " -6.09553363e+01 -4.73256772e+04 -6.04231962e+01 -1.36446545e+06\n",
      " -6.71445612e+04 -6.76066775e+25 -2.46250505e+02 -9.42294617e+01\n",
      " -4.17691355e+02 -7.20970245e+02 -3.00464732e+02 -2.46198772e+02\n",
      " -8.62007243e+01 -7.61032842e+01             nan             nan\n",
      "             nan -9.70506420e+13 -2.81771966e+04             nan\n",
      "             nan -1.38826374e+03]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 13ms/step - loss: 3550.7024 - mae: 57.3489 - val_loss: 1080.1235 - val_mae: 31.8331\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 572.4300 - mae: 20.2508 - val_loss: 111.1474 - val_mae: 8.9311\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 193.0645 - mae: 10.8997 - val_loss: 163.4747 - val_mae: 10.3957\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 182.0846 - mae: 11.1496 - val_loss: 70.5926 - val_mae: 6.9998\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 104.3986 - mae: 7.6499 - val_loss: 40.3460 - val_mae: 4.9520\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 95.2306 - mae: 6.6114 - val_loss: 38.0113 - val_mae: 4.9032\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 89.0306 - mae: 6.5991 - val_loss: 37.4515 - val_mae: 4.9935\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 84.6955 - mae: 6.7561 - val_loss: 37.0811 - val_mae: 5.0228\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 82.3991 - mae: 6.7006 - val_loss: 34.9281 - val_mae: 4.8979\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 80.0217 - mae: 6.4876 - val_loss: 32.4408 - val_mae: 4.7300\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 78.2508 - mae: 6.3909 - val_loss: 32.0334 - val_mae: 4.7497\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 76.4689 - mae: 6.3038 - val_loss: 30.3315 - val_mae: 4.6334\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 75.1105 - mae: 6.2360 - val_loss: 29.8733 - val_mae: 4.5997\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 73.9203 - mae: 6.2264 - val_loss: 29.6083 - val_mae: 4.6133\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 72.9439 - mae: 6.1477 - val_loss: 28.2567 - val_mae: 4.5097\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 72.0018 - mae: 5.9762 - val_loss: 27.0809 - val_mae: 4.4470\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 71.4409 - mae: 5.8697 - val_loss: 26.6223 - val_mae: 4.4152\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 70.4382 - mae: 6.0655 - val_loss: 28.7233 - val_mae: 4.6113\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 69.7394 - mae: 5.9555 - val_loss: 25.5404 - val_mae: 4.2969\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 69.0247 - mae: 5.8010 - val_loss: 25.7915 - val_mae: 4.3273\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 68.9326 - mae: 5.7850 - val_loss: 25.2843 - val_mae: 4.2928\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 67.6440 - mae: 5.8218 - val_loss: 26.3727 - val_mae: 4.4089\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 67.7156 - mae: 5.9012 - val_loss: 25.5287 - val_mae: 4.3028\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 66.9907 - mae: 5.6145 - val_loss: 23.9436 - val_mae: 4.1208\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 66.6400 - mae: 5.6238 - val_loss: 25.1383 - val_mae: 4.2474\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 66.2575 - mae: 5.7825 - val_loss: 24.2843 - val_mae: 4.1577\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 66.2952 - mae: 5.4772 - val_loss: 23.5501 - val_mae: 4.0734\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 65.5973 - mae: 5.5643 - val_loss: 24.1780 - val_mae: 4.1574\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 65.0722 - mae: 5.5954 - val_loss: 23.7062 - val_mae: 4.0912\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 65.5513 - mae: 5.3861 - val_loss: 23.1479 - val_mae: 4.0332\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 64.2913 - mae: 5.5602 - val_loss: 24.8788 - val_mae: 4.2353\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 64.6936 - mae: 5.5119 - val_loss: 23.1776 - val_mae: 4.0073\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 63.9214 - mae: 5.5103 - val_loss: 24.0405 - val_mae: 4.1217\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 63.5711 - mae: 5.4216 - val_loss: 22.9046 - val_mae: 3.9723\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 63.5552 - mae: 5.5026 - val_loss: 22.9298 - val_mae: 3.9991\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 63.3753 - mae: 5.4310 - val_loss: 23.4691 - val_mae: 4.0847\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 62.9904 - mae: 5.3616 - val_loss: 22.3738 - val_mae: 3.9316\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 62.5299 - mae: 5.3595 - val_loss: 22.7388 - val_mae: 3.9905\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 62.4664 - mae: 5.2821 - val_loss: 22.1997 - val_mae: 3.8813\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 62.1428 - mae: 5.4537 - val_loss: 23.0908 - val_mae: 4.0034\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 61.4904 - mae: 5.2320 - val_loss: 21.9347 - val_mae: 3.8358\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 62.0483 - mae: 5.4307 - val_loss: 23.2812 - val_mae: 4.0376\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 61.4148 - mae: 5.3315 - val_loss: 21.9840 - val_mae: 3.8673\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 61.3518 - mae: 5.1847 - val_loss: 21.9950 - val_mae: 3.8661\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3,\n                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000245E213ABF0>,\n                   n_iter=30,\n                   param_distributions={'learning_rate': [1e-05, 0.0001, 0.001],\n                                        'momentum': [0.1, 0.5, 0.9],\n                                        'n_hidden': [0, 1, 2, 3],\n                                        'n_neurons': [5, 25, 125],\n                                        'optimizer': ['sgd', 'adam', 'nesterov',\n                                                      'momentum']},\n                   verbose=2)"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=30, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zapisz najlepsze znalezione parametry w postaci słownika do pliku rnd_search.pkl."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "{'optimizer': 'adam',\n 'n_neurons': 125,\n 'n_hidden': 2,\n 'momentum': 0.5,\n 'learning_rate': 0.0001}"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('lr.pkl', 'wb') as file:\n",
    "    pickle.dump(results_lr, file)\n",
    "\n",
    "with open('hl.pkl', 'wb') as file:\n",
    "    pickle.dump(results_hl, file)\n",
    "\n",
    "with open('nn.pkl', 'wb') as file:\n",
    "    pickle.dump(results_nn, file)\n",
    "\n",
    "with open('opt.pkl', 'wb') as file:\n",
    "    pickle.dump(results_alg, file)\n",
    "\n",
    "with open('mom.pkl', 'wb') as file:\n",
    "    pickle.dump(results_mom, file)\n",
    "\n",
    "with open('rnd_search.pkl', 'wb') as file:\n",
    "    pickle.dump(rnd_search_cv.best_params_, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.1, 493.1888427734375, 20.24709701538086),\n (0.5, 254.59796142578125, 13.4472017288208),\n (0.9, 171.73822021484375, 11.43071174621582)]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}