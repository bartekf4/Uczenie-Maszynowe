{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Podziel zbiór data_breast_cancer na uczący i testujący w proporcjach 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data_breast_cancer = load_breast_cancer(as_frame=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dzielimy na zbiór uczący i testowy (pod uwagę bierzemy cechy 'mean texture', 'mean symmetry' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_breast_cancer['data'][['mean texture', 'mean symmetry']],\n",
    "                                                    data_breast_cancer['target'],\n",
    "                                                    test_size=.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree_clf = DecisionTreeClassifier()\n",
    "dec_tree_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_reg = KNeighborsClassifier()\n",
    "knn_reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('dec_tree', DecisionTreeClassifier()),\n                             ('log_reg', LogisticRegression()),\n                             ('knn_clf', KNeighborsClassifier())],\n                 voting='soft')"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_hard_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dec_tree', dec_tree_clf),\n",
    "        ('log_reg', log_reg),\n",
    "        ('knn_clf', knn_reg)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_hard_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_soft_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dec_tree', dec_tree_clf),\n",
    "        ('log_reg', log_reg),\n",
    "        ('knn_clf', knn_reg)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_soft_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "acc_vote = [(dec_tree_clf.score(X_train, y_train), dec_tree_clf.score(X_test, y_test)),\n",
    "            (log_reg.score(X_train, y_train), log_reg.score(X_test, y_test)),\n",
    "            (knn_reg.score(X_train, y_train), knn_reg.score(X_test, y_test)),\n",
    "            (voting_hard_clf.score(X_train, y_train), voting_hard_clf.score(X_test, y_test)),\n",
    "            (voting_soft_clf.score(X_train, y_train), voting_soft_clf.score(X_test, y_test))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "piklowanie acc_vote"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_vote, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 0.6842105263157895), (0.7186813186813187, 0.7280701754385965), (0.7692307692307693, 0.6754385964912281), (0.832967032967033, 0.7105263157894737), (0.9648351648351648, 0.6929824561403509)]\n"
     ]
    }
   ],
   "source": [
    "with open('acc_vote.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "piklowanie klasyfikatorów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "vote = [dec_tree_clf,\n",
    "        log_reg,\n",
    "        knn_reg,\n",
    "        voting_hard_clf,\n",
    "        voting_soft_clf]\n",
    "\n",
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(vote, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), VotingClassifier(estimators=[('dec_tree', DecisionTreeClassifier()),\n",
      "                             ('log_reg', LogisticRegression()),\n",
      "                             ('knn_clf', KNeighborsClassifier())]), VotingClassifier(estimators=[('dec_tree', DecisionTreeClassifier()),\n",
      "                             ('log_reg', LogisticRegression()),\n",
      "                             ('knn_clf', KNeighborsClassifier())],\n",
      "                 voting='soft')]\n"
     ]
    }
   ],
   "source": [
    "with open('vote.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wykonaj na zbiorze uczącym wykorzystując 30 drzew decyzyjnych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                n_estimators=30)\n",
    "bagging_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=0.5,\n                  n_estimators=30)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_50_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                   n_estimators=30,\n",
    "                                   max_samples=0.5)\n",
    "bagging_50_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pasting_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                n_estimators=30,\n",
    "                                bootstrap=False)\n",
    "pasting_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n                  n_estimators=30)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n                  max_samples=0.5, n_estimators=30)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasting_50_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                   n_estimators=30,\n",
    "                                   max_samples=0.5,\n",
    "                                   bootstrap=False)\n",
    "pasting_50_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=30)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ran_for_clf = RandomForestClassifier(n_estimators=30)\n",
    "ran_for_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "AdaBoostClassifier(n_estimators=30)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30)\n",
    "ada_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=30)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad_clf = GradientBoostingClassifier(n_estimators=30)\n",
    "grad_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9978021978021978, 0.7192982456140351),\n (0.9362637362637363, 0.7456140350877193),\n (1.0, 0.6754385964912281),\n (0.9560439560439561, 0.7456140350877193),\n (0.9978021978021978, 0.7543859649122807),\n (0.7978021978021979, 0.7456140350877193),\n (0.8307692307692308, 0.7719298245614035)]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_bag = [(bagging_clf.score(X_train, y_train), bagging_clf.score(X_test, y_test)),\n",
    "           (bagging_50_clf.score(X_train, y_train), bagging_50_clf.score(X_test, y_test)),\n",
    "           (pasting_clf.score(X_train, y_train), pasting_clf.score(X_test, y_test)),\n",
    "           (pasting_50_clf.score(X_train, y_train), pasting_50_clf.score(X_test, y_test)),\n",
    "           (ran_for_clf.score(X_train, y_train), ran_for_clf.score(X_test, y_test)),\n",
    "           (ada_clf.score(X_train, y_train), ada_clf.score(X_test, y_test)),\n",
    "           (grad_clf.score(X_train, y_train), grad_clf.score(X_test, y_test))]\n",
    "\n",
    "acc_bag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9978021978021978, 0.7192982456140351), (0.9362637362637363, 0.7456140350877193), (1.0, 0.6754385964912281), (0.9560439560439561, 0.7456140350877193), (0.9978021978021978, 0.7543859649122807), (0.7978021978021979, 0.7456140350877193), (0.8307692307692308, 0.7719298245614035)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"acc_bag.pkl\", 'wb') as f:\n",
    "    pickle.dump(acc_bag,f)\n",
    "with open(\"acc_bag.pkl\", 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30),\n BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=0.5,\n                   n_estimators=30),\n BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n                   n_estimators=30),\n BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n                   max_samples=0.5, n_estimators=30),\n RandomForestClassifier(n_estimators=30),\n AdaBoostClassifier(n_estimators=30),\n GradientBoostingClassifier(n_estimators=30)]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = [bagging_clf, bagging_50_clf, pasting_clf, pasting_50_clf, ran_for_clf, ada_clf, grad_clf]\n",
    "bag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30), BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=0.5,\n",
      "                  n_estimators=30), BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
      "                  n_estimators=30), BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
      "                  max_samples=0.5, n_estimators=30), RandomForestClassifier(n_estimators=30), AdaBoostClassifier(n_estimators=30), GradientBoostingClassifier(n_estimators=30)]\n"
     ]
    }
   ],
   "source": [
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag, f)\n",
    "\n",
    "with open('bag.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przeprowadź sampling 2 cech z wszystkich dostepnych bez powtórzeń z wykorzystaniem 30 drzew decyzyjnych, wybierz połowę instancji dla każdego z drzew z powtórzeniami."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_breast_cancer['data'],\n",
    "                                                    data_breast_cancer['target'], test_size=.2, random_state=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bag_2_features = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=30, max_features=2,\n",
    "                                   bootstrap_features=False,\n",
    "                                   bootstrap=True, max_samples=.5,random_state=25)\n",
    "bag_2_features.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n                  max_samples=0.5, n_estimators=30, random_state=25)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zapisz dokładności ww estymatora listę : dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego w pliku Pickle acc_fea.pkl.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9956043956043956, 0.9473684210526315]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fea = [bag_2_features.score(X_train, y_train), bag_2_features.score(X_test, y_test)]\n",
    "acc_fea"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9956043956043956, 0.9473684210526315]\n"
     ]
    }
   ],
   "source": [
    "with open('acc_fea.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea, f)\n",
    "\n",
    "with open('acc_fea.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zapisz klasyfikator jako jednoelementową listę w pliku Pickle o nazwie fea.pkl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n",
      "                  max_samples=0.5, n_estimators=30, random_state=25)\n"
     ]
    }
   ],
   "source": [
    "with open('fea.pkl', 'wb') as f:\n",
    "    pickle.dump(bag_2_features, f)\n",
    "\n",
    "with open('fea.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sprawdź, które cechy dają najwięszą dokładność. Dostęp do poszczególnych estymatorów,\n",
    "aby obliczyć dokładność, możesz uzyskać za pmocą: BaggingClasifier.estimators_,\n",
    "cechy wybrane przez sampling dla każdego z estymatorów znajdziesz w:\n",
    "BaggingClassifier.estimators_features_. Zbuduj ranking estymatorów jako DataFrame,\n",
    "który będzie mieć w kolejnych kolumnach: dokładność dla zb. uczącego, dokładnośc dla zb.\n",
    "testującego, lista nazw cech. Każdy wiersz to informacje o jednym estymatorze. DataFrame\n",
    "posortuj malejąco po wartościach dokładności dla zbioru testującego i uczącego oraz zapisz\n",
    "w pliku Pickle o nazwie acc_fea_rank.pkl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "features_array = []\n",
    "for features in bag_2_features.estimators_features_:\n",
    "    features_array.append([data_breast_cancer[\"feature_names\"][features[0]],\n",
    "                           data_breast_cancer[\"feature_names\"][features[1]]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "acc_fea_rank = []\n",
    "for estimator, features in zip(bag_2_features.estimators_, features_array):\n",
    "    acc_fea_rank.append(\n",
    "        [estimator.score(X_train[features], y_train), estimator.score(X_test[features], y_test), features])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1                                                  2\n6   0.960440  0.956140                     [worst area, worst smoothness]\n19  0.956044  0.894737             [worst concave points, mean perimeter]\n17  0.947253  0.912281                 [mean perimeter, worst smoothness]\n14  0.931868  0.912281                  [worst perimeter, mean perimeter]\n8   0.931868  0.859649             [perimeter error, mean concave points]\n28  0.929670  0.912281                      [area error, worst perimeter]\n25  0.925275  0.885965                    [area error, worst compactness]\n4   0.923077  0.912281              [mean concave points, worst symmetry]\n10  0.923077  0.894737                      [worst area, mean smoothness]\n9   0.920879  0.824561            [worst smoothness, mean concave points]\n11  0.905495  0.824561                 [smoothness error, mean concavity]\n26  0.896703  0.833333                       [mean area, concavity error]\n2   0.894505  0.754386                 [worst texture, worst compactness]\n18  0.890110  0.868421                        [mean radius, radius error]\n24  0.881319  0.780702                  [worst concavity, worst symmetry]\n21  0.872527  0.877193                     [mean radius, perimeter error]\n20  0.865934  0.833333                 [perimeter error, mean smoothness]\n1   0.861538  0.763158               [perimeter error, compactness error]\n29  0.857143  0.780702                    [radius error, mean smoothness]\n0   0.854945  0.728070          [mean fractal dimension, perimeter error]\n22  0.852747  0.807018            [concave points error, perimeter error]\n23  0.837363  0.771930              [worst compactness, mean compactness]\n27  0.826374  0.675439                [concavity error, smoothness error]\n3   0.806593  0.728070                    [radius error, perimeter error]\n12  0.800000  0.692982                 [worst symmetry, mean compactness]\n5   0.797802  0.649123                  [smoothness error, worst texture]\n13  0.786813  0.596491        [fractal dimension error, worst smoothness]\n7   0.773626  0.500000  [mean fractal dimension, fractal dimension error]\n15  0.753846  0.570175         [smoothness error, mean fractal dimension]\n16  0.723077  0.552632            [mean fractal dimension, texture error]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>0.960440</td>\n      <td>0.956140</td>\n      <td>[worst area, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.956044</td>\n      <td>0.894737</td>\n      <td>[worst concave points, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.947253</td>\n      <td>0.912281</td>\n      <td>[mean perimeter, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.931868</td>\n      <td>0.912281</td>\n      <td>[worst perimeter, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.931868</td>\n      <td>0.859649</td>\n      <td>[perimeter error, mean concave points]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.929670</td>\n      <td>0.912281</td>\n      <td>[area error, worst perimeter]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.925275</td>\n      <td>0.885965</td>\n      <td>[area error, worst compactness]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.923077</td>\n      <td>0.912281</td>\n      <td>[mean concave points, worst symmetry]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.923077</td>\n      <td>0.894737</td>\n      <td>[worst area, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.920879</td>\n      <td>0.824561</td>\n      <td>[worst smoothness, mean concave points]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.905495</td>\n      <td>0.824561</td>\n      <td>[smoothness error, mean concavity]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.896703</td>\n      <td>0.833333</td>\n      <td>[mean area, concavity error]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.894505</td>\n      <td>0.754386</td>\n      <td>[worst texture, worst compactness]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.890110</td>\n      <td>0.868421</td>\n      <td>[mean radius, radius error]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.881319</td>\n      <td>0.780702</td>\n      <td>[worst concavity, worst symmetry]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.872527</td>\n      <td>0.877193</td>\n      <td>[mean radius, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.865934</td>\n      <td>0.833333</td>\n      <td>[perimeter error, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.861538</td>\n      <td>0.763158</td>\n      <td>[perimeter error, compactness error]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.857143</td>\n      <td>0.780702</td>\n      <td>[radius error, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.854945</td>\n      <td>0.728070</td>\n      <td>[mean fractal dimension, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.852747</td>\n      <td>0.807018</td>\n      <td>[concave points error, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.837363</td>\n      <td>0.771930</td>\n      <td>[worst compactness, mean compactness]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.826374</td>\n      <td>0.675439</td>\n      <td>[concavity error, smoothness error]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.806593</td>\n      <td>0.728070</td>\n      <td>[radius error, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.800000</td>\n      <td>0.692982</td>\n      <td>[worst symmetry, mean compactness]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.797802</td>\n      <td>0.649123</td>\n      <td>[smoothness error, worst texture]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.786813</td>\n      <td>0.596491</td>\n      <td>[fractal dimension error, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.773626</td>\n      <td>0.500000</td>\n      <td>[mean fractal dimension, fractal dimension error]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.753846</td>\n      <td>0.570175</td>\n      <td>[smoothness error, mean fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.723077</td>\n      <td>0.552632</td>\n      <td>[mean fractal dimension, texture error]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank = pd.DataFrame(acc_fea_rank)\n",
    "df_rank.sort_values(inplace=True, by=[0, 1], ascending=False)\n",
    "df_rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "df_rank.to_pickle(\"acc_fea_rank.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}