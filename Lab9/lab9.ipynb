{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# pd.concat([iris.data, iris.target], axis=1).plot.scatter(x='petal length (cm)', y='petal width (cm)', c='target',\n",
    "#                                                          colormap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perceptrony i irysy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pobierz zbiór danych,\n",
    "Zwróć uwagę, jak długość i szerokość płatka jest powiązana z gatunkiem irysów.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podziel zbiór danych na zbiór uczący oraz zbiór testowy (8/2), a następnie kolejno dla każdego z gatunków (0, 1, 2) zbuduj perceptron, przeprowadź jego uczenie i oceń jego dokładność dla zbioru uczącego i dla zbioru testowego.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data[:, (2, 3)]\n",
    "rnd_state = 20\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X, (iris.target == 0).astype(int), train_size=.8,\n",
    "                                                        random_state=rnd_state)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, (iris.target == 1).astype(int), train_size=.8,\n",
    "                                                        random_state=rnd_state)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, (iris.target == 2).astype(int), train_size=.8,\n",
    "                                                        random_state=rnd_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "per_clf0 = Perceptron()\n",
    "per_clf1 = Perceptron()\n",
    "per_clf2 = Perceptron()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 137,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.2, 1.2],\n       [4.1, 1.3],\n       [1.4, 0.2],\n       [1.6, 0.2],\n       [1.6, 0.2],\n       [4.5, 1.7],\n       [4.5, 1.6],\n       [1.4, 0.2],\n       [4.5, 1.5],\n       [6.1, 1.9],\n       [4.5, 1.3],\n       [5.6, 1.4],\n       [1.4, 0.1],\n       [4.4, 1.4],\n       [4.7, 1.6],\n       [1.3, 0.2],\n       [1.7, 0.4],\n       [1.4, 0.2],\n       [5. , 2. ],\n       [1.9, 0.4],\n       [5.6, 2.2],\n       [5.4, 2.3],\n       [1.5, 0.4],\n       [6. , 2.5],\n       [4. , 1. ],\n       [3.6, 1.3],\n       [4.5, 1.5],\n       [1.3, 0.3],\n       [1.5, 0.2],\n       [3.8, 1.1],\n       [4.3, 1.3],\n       [4. , 1.2],\n       [3.9, 1.1],\n       [4.7, 1.5],\n       [4.6, 1.5],\n       [4.2, 1.3],\n       [1.7, 0.5],\n       [4.5, 1.5],\n       [4.4, 1.3],\n       [1.5, 0.1],\n       [1.3, 0.2],\n       [4.5, 1.5],\n       [4. , 1.3],\n       [4.6, 1.4],\n       [1.5, 0.3],\n       [1.5, 0.2],\n       [5.3, 2.3],\n       [1.3, 0.2],\n       [1.6, 0.2],\n       [3.5, 1. ],\n       [4.8, 1.8],\n       [5.1, 1.9],\n       [4.9, 2. ],\n       [5.6, 1.8],\n       [5.6, 2.1],\n       [5.9, 2.1],\n       [3.9, 1.2],\n       [5.5, 1.8],\n       [6.1, 2.3],\n       [6.1, 2.5],\n       [1.4, 0.2],\n       [5.5, 2.1],\n       [1.5, 0.2],\n       [1.4, 0.2],\n       [1.2, 0.2],\n       [5.2, 2.3],\n       [4.9, 1.5],\n       [4.8, 1.8],\n       [5.4, 2.1],\n       [4.9, 1.8],\n       [4.2, 1.3],\n       [1.3, 0.2],\n       [4.9, 1.8],\n       [1.4, 0.2],\n       [3.3, 1. ],\n       [6.7, 2.2],\n       [1.9, 0.2],\n       [4.5, 1.5],\n       [4.7, 1.4],\n       [4.8, 1.8],\n       [1.4, 0.3],\n       [1.6, 0.2],\n       [6. , 1.8],\n       [5.7, 2.5],\n       [3.9, 1.4],\n       [4.4, 1.2],\n       [3.5, 1. ],\n       [5.7, 2.1],\n       [5.6, 2.4],\n       [1.6, 0.6],\n       [5.7, 2.3],\n       [1.4, 0.3],\n       [5. , 1.7],\n       [1.5, 0.2],\n       [1.7, 0.3],\n       [5. , 1.9],\n       [5.6, 2.4],\n       [6.3, 1.8],\n       [1.5, 0.2],\n       [1.5, 0.1],\n       [5.1, 2. ],\n       [5.1, 1.6],\n       [4.2, 1.5],\n       [6.4, 2. ],\n       [1.6, 0.2],\n       [5.1, 2.3],\n       [1.4, 0.3],\n       [1.5, 0.2],\n       [5.1, 1.9],\n       [6.6, 2.1],\n       [1.3, 0.4],\n       [1.6, 0.4],\n       [1.3, 0.3],\n       [6.9, 2.3],\n       [4. , 1.3],\n       [1. , 0.2],\n       [4.4, 1.4],\n       [5.5, 1.8],\n       [1.5, 0.4],\n       [4.1, 1.3]])"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf0.fit(X_train0, y_train0)\n",
    "per_clf1.fit(X_train1, y_train1)\n",
    "per_clf2.fit(X_train2, y_train2)\n",
    "\n",
    "X_train2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dokładność dla każdej z klas zapisz jako krotkę (a_tr, a_te), a wszystkie krotki zapisz w pliku per_acc.pkl jako listę krotek: [(a_tr_0, a_te_0), (a_tr_1, a_te_1), (a_tr_2, a_te_2)]."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1.0, 1.0), (0.675, 0.7333333333333333), (0.9583333333333334, 0.9)]"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_acc = [(per_clf0.score(X_train0, y_train0), per_clf0.score(X_test0, y_test0)),\n",
    "           (per_clf1.score(X_train1, y_train1), per_clf1.score(X_test1, y_test0)),\n",
    "           (per_clf2.score(X_train2, y_train2), per_clf2.score(X_test2, y_test2))]\n",
    "per_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podobnie, wagi dla poszczególnych trzech klas zapisz jako listę 3-elementowych krotek (w_0, w_1, w_2) w pliku per_wght.pkl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "[(5.0, -2.0, -2.8000000000000003),\n (-10.0, 2.500000000000008, -16.399999999999984),\n (-47.0, -0.6000000000000068, 28.1)]"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_wght = []\n",
    "for perceptron in [per_clf0, per_clf1, per_clf2]:\n",
    "    w_0 = perceptron.intercept_[0]\n",
    "    w_1 = perceptron.coef_[0, 0]\n",
    "    w_2 = perceptron.coef_[0, 1]\n",
    "    per_wght.append((w_0, w_1, w_2))\n",
    "per_wght"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('per_acc.pkl', 'wb') as fp:\n",
    "    pickle.dump(per_acc, fp)\n",
    "\n",
    "with open('per_wght.pkl', 'wb') as fp:\n",
    "    pickle.dump(per_wght, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perceptron i XOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przygotuj prosty zbiór danych modelujący operację XOR.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "Perceptron()"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([0,\n",
    "              1,\n",
    "              1,\n",
    "              0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utwórz i przeprowadź uczenie perceptronu dla tych danych. Czy jest zdolny do poprawnego przeprowadzenia predykcji? Jak wyglądają jego wagi?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Perceptron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2300/3224364130.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mper_clf_xor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPerceptron\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mper_clf_xor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Perceptron' is not defined"
     ]
    }
   ],
   "source": [
    "per_clf_xor = Perceptron()\n",
    "per_clf_xor.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XOR, drugie podejście"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem klasyfikacji XOR teoretycznie da się rozwiązać przy pomocy sieci przedstawionej na poniższym rysunku. Zamodeluj sieć neuronową (perceptron wielowarstwowy, MLP) zgodnie z nim przy pomocy Tensorflow/Keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sieć powinna posiadać dwie warstwy gęste:\n",
    "• warstwę ukrytą, składającą się z dwóch neuronów, o dwóch wejściach (input_dim) i funkcji aktywacji tanh,\n",
    "• warstwę wyjściową, zawierającą jeden neuron i sigmoidalnej funkcji aktywacji."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Dense(2, activation=\"tanh\", use_bias=True, input_dim=2))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\", use_bias=True))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "              metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Skompiluj model z entropią krzyżową jako funkcją straty oraz stochastycznym optymalizatorem gradientowym o domyślnych parametrach.\n",
    "Przeprowadź uczenie przez 100 epok i wyświetl historię wartości funkcji straty. Jaka byłaby jej pożądana wartość dla rozważanego problemu?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01612172]\n",
      " [0.9919772 ]\n",
      " [0.991591  ]\n",
      " [0.01536733]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "found = False\n",
    "while not found:\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Dense(2, activation=\"tanh\", use_bias=True, input_dim=2))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\", use_bias=True))\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.09),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    history = model.fit(X, y, epochs=100, verbose=False)\n",
    "    results = model.predict(X)\n",
    "    if 0.1 > results[0] > 0 and 1 > results[1] > 0.9 and 1 > results[2] > 0.9 and 0 < results[3] < 0.1:\n",
    "        found = True\n",
    "mlp_xor_weights = model.get_weights()\n",
    "print(results)\n",
    "with open('mlp_xor_weights.pkl', 'wb') as file:\n",
    "    pickle.dump(mlp_xor_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}